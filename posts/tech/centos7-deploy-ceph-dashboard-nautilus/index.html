<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>centos7部署ceph+dashboard（nautilus） | lvbibir's Blog</title><meta name=keywords content="linux,ceph"><meta name=description content="前言 ceph测试环境的搭建 基本环境 物理环境：Vmware Workstaion 系统版本：Centos-7.9-Minimal 两个osd节点添加一块虚拟磁盘，建议"><meta name=author content="
作者:&nbsp;lvbibir"><link rel=canonical href=https://www.lvbibir.cn/posts/tech/centos7-deploy-ceph-dashboard-nautilus/><link crossorigin=anonymous href=/assets/css/stylesheet.f64373979972a5dede3be9585f88811a5d3e48b2c2ca9832247cf5534646878a.css integrity="sha256-9kNzl5lypd7eO+lYX4iBGl0+SLLCypgyJHz1U0ZGh4o=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://www.lvbibir.cn/img/avatar.gif><link rel=icon type=image/png sizes=16x16 href=https://www.lvbibir.cn/img/avatar.gif><link rel=icon type=image/png sizes=32x32 href=https://www.lvbibir.cn/img/avatar.gif><link rel=apple-touch-icon href=https://www.lvbibir.cn/img/avatar.gif><link rel=mask-icon href=https://www.lvbibir.cn/img/avatar.gif><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><script src=https://kit.fontawesome.com/2e34783cd8.js crossorigin=anonymous></script><meta property="og:title" content="centos7部署ceph+dashboard（nautilus）"><meta property="og:description" content="前言 ceph测试环境的搭建 基本环境 物理环境：Vmware Workstaion 系统版本：Centos-7.9-Minimal 两个osd节点添加一块虚拟磁盘，建议"><meta property="og:type" content="article"><meta property="og:url" content="https://www.lvbibir.cn/posts/tech/centos7-deploy-ceph-dashboard-nautilus/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-12-01T00:00:00+00:00"><meta property="article:modified_time" content="2021-12-01T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="centos7部署ceph+dashboard（nautilus）"><meta name=twitter:description content="前言 ceph测试环境的搭建 基本环境 物理环境：Vmware Workstaion 系统版本：Centos-7.9-Minimal 两个osd节点添加一块虚拟磁盘，建议"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"📚 文章","item":"https://www.lvbibir.cn/posts/"},{"@type":"ListItem","position":3,"name":"👨🏻‍💻 技术","item":"https://www.lvbibir.cn/posts/tech/"},{"@type":"ListItem","position":4,"name":"centos7部署ceph+dashboard（nautilus）","item":"https://www.lvbibir.cn/posts/tech/centos7-deploy-ceph-dashboard-nautilus/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"centos7部署ceph+dashboard（nautilus）","name":"centos7部署ceph\u002bdashboard（nautilus）","description":"前言 ceph测试环境的搭建 基本环境 物理环境：Vmware Workstaion 系统版本：Centos-7.9-Minimal 两个osd节点添加一块虚拟磁盘，建议","keywords":["linux","ceph"],"articleBody":"前言 ceph测试环境的搭建\n基本环境 物理环境：Vmware Workstaion 系统版本：Centos-7.9-Minimal 两个osd节点添加一块虚拟磁盘，建议不小于20G ip hostname services 192.168.150.101 ceph-admin(ceph-deploy) mds1、mon1、mon_mgr、ntp-server 192.168.150.102 ceph-node1 osd1 192.168.150.103 ceph-node2 osd2 前期配置 以下操作所有节点都需执行\n修改主机名\nhostnamectl set-hostname ceph-admin bash hostnamectl set-hostname ceph-node1 bash hostnamectl set-hostname ceph-node2 bash 修改hosts文件\nvim /etc/hosts 192.168.150.101 ceph-admin 192.168.150.102 ceph-node1 192.168.150.103 ceph-node2 关闭防火墙和selinux、修改yum源及安装一些常用工具\n这里提供了一个简单的系统初始化脚本用来做上述操作，适用于Centos7\nchmod 777 init.sh ./init.sh #!/bin/bash echo \"========start=============\" sed -i '/SELINUX/s/enforcing/disabled/' /etc/sysconfig/selinux setenforce 0 iptables -F systemctl disable firewalld systemctl stop firewalld echo \"====dowload wget=========\" yum install -y wget echo \"====backup repo===========\" mkdir /etc/yum.repos.d/bak mv /etc/yum.repos.d/*.repo /etc/yum.repos.d/bak/ echo \"====dowload aliyum-repo====\" wget http://mirrors.aliyun.com/repo/Centos-7.repo -O /etc/yum.repos.d/Centos-Base.repo wget http://mirrors.aliyun.com/repo/epel-7.repo -O /etc/yum.repos.d/epel.repo echo \"====upgrade yum============\" yum clean all yum makecache fast echo \"====dowload tools=========\" yum install -y net-tools vim bash-completion echo \"=========finish============\" 每个节点安装和配置NTP（官方推荐的是集群的所有节点全部安装并配置 NTP，需要保证各节点的系统时间一致。没有自己部署ntp服务器，就在线同步NTP）\nyum install chrony -y systemctl start chronyd systemctl enable chronyd ceph-admin\nvim /etc/chrony.conf systemctl restart chronyd chronyc sources 这里使用阿里云的ntp服务器\nceph-node1、ceph-node2\nvim /etc/chrony.conf systemctl restart chronyd chronyc sources 这里指定ceph-admin节点的ip即可\n添加ceph源\nyum -y install epel-release rpm --import http://mirrors.163.com/ceph/keys/release.asc rpm -Uvh --replacepkgs http://mirrors.163.com/ceph/rpm-nautilus/el7/noarch/ceph-release-1-1.el7.noarch.rpm [Ceph] name=Ceph packages for $basearch baseurl=http://download.ceph.com/rpm-nautilus/el7/$basearch enabled=1 gpgcheck=1 type=rpm-md gpgkey=https://download.ceph.com/keys/release.asc [Ceph-noarch] name=Ceph noarch packages baseurl=http://download.ceph.com/rpm-nautilus/el7/noarch enabled=1 gpgcheck=1 type=rpm-md gpgkey=https://download.ceph.com/keys/release.asc [ceph-source] name=Ceph source packages baseurl=http://download.ceph.com/rpm-nautilus/el7/SRPMS enabled=1 gpgcheck=1 type=rpm-md gpgkey=https://download.ceph.com/keys/release.asc 磁盘准备 以下操作在osd节点（ceph-node1、ceph-node2）执行\n# 检查磁盘 [root@ceph-node1 ~]# fdisk -l /dev/sdb Disk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes # 格式化磁盘 [root@ceph-node1 ~]# parted -s /dev/sdb mklabel gpt mkpart primary xfs 0% 100% [root@ceph-node1 ~]# mkfs.xfs /dev/sdb -f meta-data=/dev/sdb isize=512 agcount=4, agsize=1310720 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0, sparse=0 data = bsize=4096 blocks=5242880, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal log bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 查看磁盘格式 [root@ceph-node1 ~]# blkid -o value -s TYPE /dev/sdb xfs 安装ceph集群 配置ssh免密\n[root@ceph-admin ~]# ssh-keygen # 一路回车 [root@ceph-admin ~]# ssh-copy-id root@ceph-node1 [root@ceph-admin ~]# ssh-copy-id root@ceph-node2 安装ceph-deploy\n[root@ceph-admin ~]# yum install -y python2-pip [root@ceph-admin ~]# yum install -y ceph-deploy 创建文件夹用户存放集群文件\n[root@ceph-admin ~]# mkdir /root/my-ceph [root@ceph-admin ~]# cd /root/my-ceph/ 创建集群（后面填写monit节点的主机名，这里monit节点和管理节点是同一台机器，即ceph-admin）\n[root@ceph-admin my-ceph]# ceph-deploy new ceph-admin [ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (2.0.1): /usr/bin/ceph-deploy new ceph-admin [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] func : [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] ssh_copykey : True [ceph_deploy.cli][INFO ] mon : ['ceph-admin'] [ceph_deploy.cli][INFO ] public_network : None [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] cluster_network : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.cli][INFO ] fsid : None [ceph_deploy.new][DEBUG ] Creating new cluster named ceph [ceph_deploy.new][INFO ] making sure passwordless SSH succeeds [ceph-admin][DEBUG ] connected to host: ceph-admin [ceph-admin][DEBUG ] detect platform information from remote host [ceph-admin][DEBUG ] detect machine type [ceph-admin][DEBUG ] find the location of an executable [ceph-admin][INFO ] Running command: /usr/sbin/ip link show [ceph-admin][INFO ] Running command: /usr/sbin/ip addr show [ceph-admin][DEBUG ] IP addresses found: [u'192.168.150.101'] [ceph_deploy.new][DEBUG ] Resolving host ceph-admin [ceph_deploy.new][DEBUG ] Monitor ceph-admin at 192.168.150.101 [ceph_deploy.new][DEBUG ] Monitor initial members are ['ceph-admin'] [ceph_deploy.new][DEBUG ] Monitor addrs are ['192.168.150.101'] [ceph_deploy.new][DEBUG ] Creating a random mon key... [ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring... [ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf... 修改集群配置文件\n注意：mon_host必须和public network 网络是同网段内\n[root@ceph-admin my-ceph]# vim ceph.conf # 添加如下两行内容 ...... public_network = 192.168.150.0/24 osd_pool_default_size = 2 开始安装\n[root@ceph-admin my-ceph]# ceph-deploy install --release nautilus ceph-admin ceph-node1 ceph-node2 # 出现以下提示说明安装成功 [ceph-node2][DEBUG ] Complete! [ceph-node2][INFO ] Running command: ceph --version [ceph-node2][DEBUG ] ceph version 12.2.13 (584a20eb0237c657dc0567da126be145106aa47e) nautilus (stable) 初始化monit监控节点，并收集所有密钥\n[root@ceph-admin my-ceph]# ceph-deploy mon create-initial [root@ceph-admin my-ceph]# ceph-deploy gatherkeys ceph-admin 检查OSD节点上所有可用的磁盘\n[root@ceph-admin my-ceph]# ceph-deploy disk list ceph-node1 ceph-node2 删除所有osd节点上的分区、准备osd及激活osd\n主机上有多块磁盘要作为osd时：ceph-deploy osd create ceph-node21 --data /dev/sdb --data /dev/sdc\n[root@ceph-admin my-ceph]# ceph-deploy osd create ceph-node1 --data /dev/sdb [root@ceph-admin my-ceph]# ceph-deploy osd create ceph-node2 --data /dev/sdb 在两个osd节点上通过命令已显示磁盘已成功mount\n[root@ceph-node1 ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 20G 0 disk ├─sda1 8:1 0 1G 0 part /boot └─sda2 8:2 0 19G 0 part ├─centos-root 253:0 0 17G 0 lvm / └─centos-swap 253:1 0 2G 0 lvm [SWAP] sdb 8:16 0 20G 0 disk └─ceph--2bb0ec8d--547c--42c2--9858--08ccfd043bd4-osd--block--33e8dba4--6dfc--4753--b9ba--0d0c54166f0c 253:2 0 20G 0 lvm sr0 查看osd\n[root@ceph-admin my-ceph]# ceph-deploy disk list ceph-node1 ceph-node2 ...... ...... [ceph-node1][INFO ] Disk /dev/mapper/ceph--2bb0ec8d--547c--42c2--9858--08ccfd043bd4-osd--block--33e8dba4--6dfc--4753--b9ba--0d0c54166f0c: 21.5 GB, 21470642176 bytes, 41934848 sectors ...... ...... [ceph-node2][INFO ] Disk /dev/mapper/ceph--f9a95e6c--fc7b--46b4--a835--dd997c0d6335-osd--block--db903124--4c01--40d7--8a58--b26e17c1db29: 21.5 GB, 21470642176 bytes, 41934848 sectors 同步集群文件，这样就可以在所有节点执行ceph命令了\n[root@ceph-admin my-ceph]# ceph-deploy admin ceph-admin ceph-node1 ceph-node2 在其他节点查看osd的目录树\n[root@ceph-node1 ~]# ceph osd tree ID CLASS WEIGHT TYPE NAME STATUS REWEIGHT PRI-AFF -1 0.03897 root default -3 0.01949 host ceph-node1 0 hdd 0.01949 osd.0 up 1.00000 1.00000 -5 0.01949 host ceph-node2 1 hdd 0.01949 osd.1 up 1.00000 1.00000 配置mgr\n[root@ceph-admin my-ceph]# ceph-deploy mgr create ceph-admin 查看集群状态和集群service状态\n此时是HEALTH_WARN状态，是由于启用了不安全模式\n[root@ceph-admin my-ceph]# ceph health HEALTH_WARN mon is allowing insecure global_id reclaim [root@ceph-admin my-ceph]# ceph -s cluster: id: fd816347-598c-4ed6-b356-591a618a0bdc health: HEALTH_WARN mon is allowing insecure global_id reclaim services: mon: 1 daemons, quorum ceph-admin (age 3h) mgr: mon_mgr(active, since 17s) osd: 2 osds: 2 up (since 3m), 2 in (since 3m) data: pools: 0 pools, 0 pgs objects: 0 objects, 0 B usage: 2.0 GiB used, 38 GiB / 40 GiB avail pgs: 禁用不安全模式\n[root@ceph-admin my-ceph]# ceph config set mon auth_allow_insecure_global_id_reclaim false [root@ceph-admin my-ceph]# ceph health HEALTH_OK 开启dashboard [root@ceph-admin my-ceph]# yum install -y ceph-mgr-dashboard [root@ceph-admin my-ceph]# ceph mgr module enable dashboard # 创建自签证书 [root@ceph-admin my-ceph]# ceph dashboard create-self-signed-cert # 创建密码文件 [root@ceph-admin my-ceph]# echo abc123 \u003e ./dashboard_user_pw # 创建dashboard的登录用户 [root@ceph-admin my-ceph]# ceph dashboard ac-user-create admin -i ./dashboard_user_pw administrator {\"username\": \"admin\", \"lastUpdate\": 1646037503, \"name\": null, \"roles\": [\"administrator\"], \"password\": \"$2b$12$jGsvau8jFMb4pDwLU/t8KO1sKvmBMcNUYycbXusmgkvTQzlzrMyKi\", \"email\": null} [root@ceph-admin my-ceph]# ceph mgr services { \"dashboard\": \"https://ceph-admin:8443/\" } 测试访问\n上图中测试环境是win10+chrome，同事反应mac+chrome会出现无法访问的情况，原因是我们使用的自签证书，浏览器并不信任此证书，可以通过以下两种方式解决\n关闭dashboard的ssl访问\n下载证书配置浏览器信任证书\n关闭dashboard的ssl访问 [root@ceph-admin my-ceph]# ceph config set mgr mgr/dashboard/ssl false [root@ceph-admin my-ceph]# ceph mgr module disable dashboard [root@ceph-admin my-ceph]# ceph mgr module enable dashboard [root@ceph-admin my-ceph]# ceph mgr services { \"dashboard\": \"http://ceph-admin:8080/\" } 如果出现Module 'dashboard' has failed: IOError(\"Port 8443 not free on '::'\",)这种报错，需要重启下mgr：systemctl restart ceph-mgr@ceph-admin\n测试访问\n开启rgw管理功能 默认object gateway功能没有开启\n创建rgw实例\nceph-deploy rgw create ceph-admin 默认运行端口是7480\n创建rgw用户\n[root@ceph-admin my-ceph]# radosgw-admin user create --uid=rgw --display-name=rgw --system 提供dashboard证书\n[root@ceph-admin my-ceph]# echo UI2T50HNZUCVVYYZNDHP \u003e rgw_user_access_key [root@ceph-admin my-ceph]# echo 11rg0WbXuh2Svexck3vJKs19u1UQINixDWIpN5Dq \u003e rgw_user_secret_key [root@ceph-admin my-ceph]# ceph dashboard set-rgw-api-access-key -i rgw_user_access_key Option RGW_API_ACCESS_KEY updated [root@ceph-admin my-ceph]# ceph dashboard set-rgw-api-secret-key -i rgw_user_secret_key Option RGW_API_SECRET_KEY updated 禁用ssl\n[root@ceph-admin my-ceph]# ceph dashboard set-rgw-api-ssl-verify False Option RGW_API_SSL_VERIFY updated 启用rgw\n[root@ceph-admin my-ceph]# ceph dashboard set-rgw-api-host 192.168.150.101 Option RGW_API_HOST updated [root@ceph-admin my-ceph]# ceph dashboard set-rgw-api-port 7480 Option RGW_API_PORT updated [root@ceph-admin my-ceph]# ceph dashboard set-rgw-api-scheme http Option RGW_API_SCHEME updated [root@ceph-admin my-ceph]# ceph dashboard set-rgw-api-user-id rgw Option RGW_API_USER_ID updated [root@ceph-admin my-ceph]# systemctl restart ceph-radosgw.target 验证\n目前object gateway功能已成功开启\n其他 清除ceph集群 清除安装包\n[root@ceph-admin ~]# ceph-deploy purge ceph-admin ceph-node1 ceph-node2 清除配置信息\n[root@ceph-admin ~]# ceph-deploy purgedata ceph-admin ceph-node1 ceph-node2 [root@ceph-admin ~]# ceph-deploy forgetkeys 每个节点删除残留的配置文件\nrm -rf /var/lib/ceph/osd/* rm -rf /var/lib/ceph/mon/* rm -rf /var/lib/ceph/mds/* rm -rf /var/lib/ceph/bootstrap-mds/* rm -rf /var/lib/ceph/bootstrap-osd/* rm -rf /var/lib/ceph/bootstrap-mon/* rm -rf /var/lib/ceph/tmp/* rm -rf /etc/ceph/* rm -rf /var/run/ceph/* 清理磁盘设备(/dev/mapper/ceph*)\nls /dev/mapper/ceph-* | xargs -I% -- dmsetup remove % dashboard无法访问的问题 在关闭dashboard的https后，出现了一个很奇怪的问题，使用chrome浏览器无法访问dashboard了，edge或者使用chrome无痕模式可以正常访问，期间尝试了各种方法包括重新配置dashboard和清理chrome浏览器的缓存和cookie等方式都没有解决问题，结果第二天起来打开环境一看自己好了（淦）\n问题情况见下图\n日志报错：\n同步ceph配置文件 ceph-deploy --overwrite-conf config push ceph-node{1,2,3,4} 添加mon节点和mgr节点 ceph-deploy mon create ceph-node{1,2,3,4} ceph-deploy mgr create ceph-node{1,2,3,4} 记得修改配置文件\n之后同步配置文件\nceph-deploy --overwrite-conf config push ceph-node{1,2,3,4} 参考 https://www.cnblogs.com/kevingrace/p/9141432.html\nhttps://www.cnblogs.com/weijie0717/p/8378485.html\nhttps://www.cnblogs.com/weijie0717/p/8383938.html\nhttps://blog.csdn.net/qq_40017427/article/details/106235456\n","wordCount":"2589","inLanguage":"en","datePublished":"2021-12-01T00:00:00Z","dateModified":"2021-12-01T00:00:00Z","author":[{"@type":"Person","name":"lvbibir"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.lvbibir.cn/posts/tech/centos7-deploy-ceph-dashboard-nautilus/"},"publisher":{"@type":"Organization","name":"lvbibir's Blog","logo":{"@type":"ImageObject","url":"https://www.lvbibir.cn/img/avatar.gif"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://www.lvbibir.cn accesskey=h title="lvbibir's Blog (Alt + H)"><img src=https://www.lvbibir.cn/img/avatar.gif alt aria-label=logo height=35>lvbibir's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://www.lvbibir.cn/search title="🔍 搜索 (Alt + /)" accesskey=/><span>🔍 搜索</span></a></li><li><a href=https://www.lvbibir.cn/ title="🏡 主页"><span>🏡 主页</span></a></li><li><a href=https://www.lvbibir.cn/posts title="📚 文章"><span>📚 文章</span></a></li><li><a href=https://www.lvbibir.cn/tags title="🏷️ 标签"><span>🏷️ 标签</span></a></li><li><a href=https://www.lvbibir.cn/archives title="📈 时间轴"><span>📈 时间轴</span></a></li><li><a href=https://www.lvbibir.cn/shuoshuo title="💬 说说"><span>💬 说说</span></a></li><li><a href=https://www.lvbibir.cn/about title="🙋🏻‍♂️ 关于"><span>🙋🏻‍♂️ 关于</span></a></li><li><a href=https://www.lvbibir.cn/links title="🤝 友链"><span>🤝 友链</span></a></li></ul></nav></header><main class="main page"><article class=post-single><div id=single-content><header class=post-header><div class=breadcrumbs><a href=https://www.lvbibir.cn>主页</a>&nbsp;»&nbsp;<a href=https://www.lvbibir.cn/posts/>📚 文章</a>&nbsp;»&nbsp;<a href=https://www.lvbibir.cn/posts/tech/>👨🏻‍💻 技术</a></div><h1 class=post-title>centos7部署ceph+dashboard（nautilus）</h1><div class=post-meta>创建:&nbsp;<span title='2021-12-01 00:00:00 +0000 UTC'>2021-12-01</span>&nbsp;|&nbsp;更新:&nbsp;2021-12-01&nbsp;|&nbsp;字数:&nbsp;2589字&nbsp;|&nbsp;时长:&nbsp;6分钟&nbsp;|&nbsp;
作者:&nbsp;lvbibir
&nbsp;|&nbsp;标签: &nbsp;<ul class=post-tags-meta><a href=https://www.lvbibir.cn/tags/linux/>linux</a>
<a href=https://www.lvbibir.cn/tags/ceph/>、ceph</a></ul><span id=busuanzi_container_page_pv>&nbsp;| 访问: <span id=busuanzi_value_page_pv></span></span></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>文章目录</span></summary><div class=inner><ul><li><a href=#%e5%89%8d%e8%a8%80 aria-label=前言>前言</a></li><li><a href=#%e5%9f%ba%e6%9c%ac%e7%8e%af%e5%a2%83 aria-label=基本环境>基本环境</a></li><li><a href=#%e5%89%8d%e6%9c%9f%e9%85%8d%e7%bd%ae aria-label=前期配置>前期配置</a></li><li><a href=#%e7%a3%81%e7%9b%98%e5%87%86%e5%a4%87 aria-label=磁盘准备>磁盘准备</a></li><li><a href=#%e5%ae%89%e8%a3%85ceph%e9%9b%86%e7%be%a4 aria-label=安装ceph集群>安装ceph集群</a></li><li><a href=#%e5%bc%80%e5%90%afdashboard aria-label=开启dashboard>开启dashboard</a><ul><li><a href=#%e5%85%b3%e9%97%addashboard%e7%9a%84ssl%e8%ae%bf%e9%97%ae aria-label=关闭dashboard的ssl访问>关闭dashboard的ssl访问</a></li><li><a href=#%e5%bc%80%e5%90%afrgw%e7%ae%a1%e7%90%86%e5%8a%9f%e8%83%bd aria-label=开启rgw管理功能>开启rgw管理功能</a></li></ul></li><li><a href=#%e5%85%b6%e4%bb%96 aria-label=其他>其他</a><ul><li><a href=#%e6%b8%85%e9%99%a4ceph%e9%9b%86%e7%be%a4 aria-label=清除ceph集群><strong>清除ceph集群</strong></a></li><li><a href=#dashboard%e6%97%a0%e6%b3%95%e8%ae%bf%e9%97%ae%e7%9a%84%e9%97%ae%e9%a2%98 aria-label=dashboard无法访问的问题>dashboard无法访问的问题</a></li><li><a href=#%e5%90%8c%e6%ad%a5ceph%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6 aria-label=同步ceph配置文件>同步ceph配置文件</a></li><li><a href=#%e6%b7%bb%e5%8a%a0mon%e8%8a%82%e7%82%b9%e5%92%8cmgr%e8%8a%82%e7%82%b9 aria-label=添加mon节点和mgr节点>添加mon节点和mgr节点</a></li></ul></li><li><a href=#%e5%8f%82%e8%80%83 aria-label=参考>参考</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h1 id=前言>前言<a hidden class=anchor aria-hidden=true href=#前言>#</a></h1><p>ceph测试环境的搭建</p><h1 id=基本环境>基本环境<a hidden class=anchor aria-hidden=true href=#基本环境>#</a></h1><ul><li>物理环境：Vmware Workstaion</li><li>系统版本：Centos-7.9-Minimal</li><li>两个osd节点添加一块虚拟磁盘，建议不小于20G</li></ul><table><thead><tr><th>ip</th><th>hostname</th><th>services</th></tr></thead><tbody><tr><td>192.168.150.101</td><td>ceph-admin(ceph-deploy)</td><td>mds1、mon1、mon_mgr、ntp-server</td></tr><tr><td>192.168.150.102</td><td>ceph-node1</td><td>osd1</td></tr><tr><td>192.168.150.103</td><td>ceph-node2</td><td>osd2</td></tr></tbody></table><h1 id=前期配置>前期配置<a hidden class=anchor aria-hidden=true href=#前期配置>#</a></h1><p><strong>以下操作所有节点都需执行</strong></p><p><strong>修改主机名</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>hostnamectl set-hostname ceph-admin
</span></span><span style=display:flex><span>bash
</span></span><span style=display:flex><span>hostnamectl set-hostname ceph-node1
</span></span><span style=display:flex><span>bash
</span></span><span style=display:flex><span>hostnamectl set-hostname ceph-node2
</span></span><span style=display:flex><span>bash
</span></span></code></pre></div><p><strong>修改hosts文件</strong></p><pre tabindex=0><code>vim /etc/hosts

192.168.150.101 ceph-admin
192.168.150.102 ceph-node1
192.168.150.103 ceph-node2
</code></pre><p><strong>关闭防火墙和selinux、修改yum源及安装一些常用工具</strong></p><p>这里提供了一个简单的系统初始化脚本用来做上述操作，适用于Centos7</p><pre tabindex=0><code>chmod 777 init.sh
./init.sh
</code></pre><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>#!/bin/bash
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;========start=============&#34;</span>
</span></span><span style=display:flex><span>sed -i <span style=color:#e6db74>&#39;/SELINUX/s/enforcing/disabled/&#39;</span> /etc/sysconfig/selinux
</span></span><span style=display:flex><span>setenforce <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>iptables -F
</span></span><span style=display:flex><span>systemctl disable firewalld
</span></span><span style=display:flex><span>systemctl stop firewalld
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;====dowload wget=========&#34;</span>
</span></span><span style=display:flex><span>yum install -y wget
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;====backup repo===========&#34;</span>
</span></span><span style=display:flex><span>mkdir /etc/yum.repos.d/bak
</span></span><span style=display:flex><span>mv /etc/yum.repos.d/*.repo /etc/yum.repos.d/bak/ 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;====dowload aliyum-repo====&#34;</span>
</span></span><span style=display:flex><span>wget http://mirrors.aliyun.com/repo/Centos-7.repo -O /etc/yum.repos.d/Centos-Base.repo
</span></span><span style=display:flex><span>wget http://mirrors.aliyun.com/repo/epel-7.repo -O /etc/yum.repos.d/epel.repo
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;====upgrade yum============&#34;</span>
</span></span><span style=display:flex><span>yum clean all
</span></span><span style=display:flex><span>yum makecache fast
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;====dowload tools=========&#34;</span>
</span></span><span style=display:flex><span>yum install -y net-tools vim bash-completion
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;=========finish============&#34;</span>
</span></span></code></pre></div><p><strong>每个节点安装和配置NTP（官方推荐的是集群的所有节点全部安装并配置 NTP，需要保证各节点的系统时间一致。没有自己部署ntp服务器，就在线同步NTP）</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yum install chrony -y
</span></span><span style=display:flex><span>systemctl start chronyd
</span></span><span style=display:flex><span>systemctl enable chronyd
</span></span></code></pre></div><p>ceph-admin</p><pre tabindex=0><code>vim /etc/chrony.conf
systemctl restart chronyd
chronyc sources
</code></pre><p>这里使用阿里云的ntp服务器</p><p><img loading=lazy src=https://image.lvbibir.cn/blog/image-20211206142640253.png alt=image-20211206142640253></p><p>ceph-node1、ceph-node2</p><pre tabindex=0><code>vim /etc/chrony.conf
systemctl restart chronyd
chronyc sources
</code></pre><p>这里指定ceph-admin节点的ip即可</p><p><img loading=lazy src=https://image.lvbibir.cn/blog/image-20211206142908590.png alt=image-20211206142908590></p><p><strong>添加ceph源</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yum -y install epel-release
</span></span><span style=display:flex><span>rpm --import http://mirrors.163.com/ceph/keys/release.asc
</span></span><span style=display:flex><span>rpm -Uvh --replacepkgs http://mirrors.163.com/ceph/rpm-nautilus/el7/noarch/ceph-release-1-1.el7.noarch.rpm
</span></span></code></pre></div><pre tabindex=0><code>[Ceph]
name=Ceph packages for $basearch
baseurl=http://download.ceph.com/rpm-nautilus/el7/$basearch
enabled=1
gpgcheck=1
type=rpm-md
gpgkey=https://download.ceph.com/keys/release.asc

[Ceph-noarch]
name=Ceph noarch packages
baseurl=http://download.ceph.com/rpm-nautilus/el7/noarch
enabled=1
gpgcheck=1
type=rpm-md
gpgkey=https://download.ceph.com/keys/release.asc

[ceph-source]
name=Ceph source packages
baseurl=http://download.ceph.com/rpm-nautilus/el7/SRPMS
enabled=1
gpgcheck=1
type=rpm-md
gpgkey=https://download.ceph.com/keys/release.asc
</code></pre><h1 id=磁盘准备>磁盘准备<a hidden class=anchor aria-hidden=true href=#磁盘准备>#</a></h1><p>以下操作在osd节点（ceph-node1、ceph-node2）执行</p><pre tabindex=0><code># 检查磁盘
[root@ceph-node1 ~]# fdisk -l /dev/sdb

Disk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes

# 格式化磁盘
[root@ceph-node1 ~]# parted -s /dev/sdb mklabel gpt mkpart primary xfs 0% 100%
[root@ceph-node1 ~]# mkfs.xfs /dev/sdb -f
meta-data=/dev/sdb               isize=512    agcount=4, agsize=1310720 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=0, sparse=0
data     =                       bsize=4096   blocks=5242880, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal log           bsize=4096   blocks=2560, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0

查看磁盘格式
[root@ceph-node1 ~]# blkid -o value -s TYPE /dev/sdb
xfs
</code></pre><h1 id=安装ceph集群>安装ceph集群<a hidden class=anchor aria-hidden=true href=#安装ceph集群>#</a></h1><p><strong>配置ssh免密</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@ceph-admin ~<span style=color:#f92672>]</span><span style=color:#75715e># ssh-keygen</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 一路回车</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@ceph-admin ~<span style=color:#f92672>]</span><span style=color:#75715e># ssh-copy-id root@ceph-node1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@ceph-admin ~<span style=color:#f92672>]</span><span style=color:#75715e># ssh-copy-id root@ceph-node2</span>
</span></span></code></pre></div><p><strong>安装ceph-deploy</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@ceph-admin ~<span style=color:#f92672>]</span><span style=color:#75715e># yum install -y python2-pip</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@ceph-admin ~<span style=color:#f92672>]</span><span style=color:#75715e># yum install -y ceph-deploy</span>
</span></span></code></pre></div><p><strong>创建文件夹用户存放集群文件</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@ceph-admin ~<span style=color:#f92672>]</span><span style=color:#75715e># mkdir /root/my-ceph</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@ceph-admin ~<span style=color:#f92672>]</span><span style=color:#75715e># cd /root/my-ceph/</span>
</span></span></code></pre></div><p><strong>创建集群（后面填写monit节点的主机名，这里monit节点和管理节点是同一台机器，即ceph-admin）</strong></p><pre tabindex=0><code>[root@ceph-admin my-ceph]# ceph-deploy new ceph-admin

[ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[ceph_deploy.cli][INFO  ] Invoked (2.0.1): /usr/bin/ceph-deploy new ceph-admin
[ceph_deploy.cli][INFO  ] ceph-deploy options:
[ceph_deploy.cli][INFO  ]  username                      : None
[ceph_deploy.cli][INFO  ]  func                          : &lt;function new at 0x7f2217df3de8&gt;
[ceph_deploy.cli][INFO  ]  verbose                       : False
[ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[ceph_deploy.cli][INFO  ]  quiet                         : False
[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f221756e4d0&gt;
[ceph_deploy.cli][INFO  ]  cluster                       : ceph
[ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[ceph_deploy.cli][INFO  ]  mon                           : [&#39;ceph-admin&#39;]
[ceph_deploy.cli][INFO  ]  public_network                : None
[ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[ceph_deploy.cli][INFO  ]  cluster_network               : None
[ceph_deploy.cli][INFO  ]  default_release               : False
[ceph_deploy.cli][INFO  ]  fsid                          : None
[ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[ceph-admin][DEBUG ] connected to host: ceph-admin
[ceph-admin][DEBUG ] detect platform information from remote host
[ceph-admin][DEBUG ] detect machine type
[ceph-admin][DEBUG ] find the location of an executable
[ceph-admin][INFO  ] Running command: /usr/sbin/ip link show
[ceph-admin][INFO  ] Running command: /usr/sbin/ip addr show
[ceph-admin][DEBUG ] IP addresses found: [u&#39;192.168.150.101&#39;]
[ceph_deploy.new][DEBUG ] Resolving host ceph-admin
[ceph_deploy.new][DEBUG ] Monitor ceph-admin at 192.168.150.101
[ceph_deploy.new][DEBUG ] Monitor initial members are [&#39;ceph-admin&#39;]
[ceph_deploy.new][DEBUG ] Monitor addrs are [&#39;192.168.150.101&#39;]
[ceph_deploy.new][DEBUG ] Creating a random mon key...
[ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
</code></pre><p><strong>修改集群配置文件</strong></p><p>注意：mon_host必须和public network 网络是同网段内</p><pre tabindex=0><code>[root@ceph-admin my-ceph]# vim ceph.conf
# 添加如下两行内容
......
public_network = 192.168.150.0/24
osd_pool_default_size = 2
</code></pre><p><strong>开始安装</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@ceph-admin my-ceph<span style=color:#f92672>]</span><span style=color:#75715e># ceph-deploy install --release nautilus ceph-admin ceph-node1 ceph-node2</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 出现以下提示说明安装成功</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>ceph-node2<span style=color:#f92672>][</span>DEBUG <span style=color:#f92672>]</span> Complete!
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>ceph-node2<span style=color:#f92672>][</span>INFO  <span style=color:#f92672>]</span> Running command: ceph --version
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>ceph-node2<span style=color:#f92672>][</span>DEBUG <span style=color:#f92672>]</span> ceph version 12.2.13 <span style=color:#f92672>(</span>584a20eb0237c657dc0567da126be145106aa47e<span style=color:#f92672>)</span> nautilus <span style=color:#f92672>(</span>stable<span style=color:#f92672>)</span>
</span></span></code></pre></div><p><strong>初始化monit监控节点，并收集所有密钥</strong></p><pre tabindex=0><code>[root@ceph-admin my-ceph]# ceph-deploy mon create-initial
[root@ceph-admin my-ceph]# ceph-deploy gatherkeys ceph-admin
</code></pre><p><strong>检查OSD节点上所有可用的磁盘</strong></p><pre tabindex=0><code>[root@ceph-admin my-ceph]# ceph-deploy disk list ceph-node1 ceph-node2
</code></pre><p><strong>删除所有osd节点上的分区、准备osd及激活osd</strong></p><p>主机上有多块磁盘要作为osd时：<code>ceph-deploy osd create ceph-node21 --data /dev/sdb --data /dev/sdc</code></p><pre tabindex=0><code>[root@ceph-admin my-ceph]# ceph-deploy osd create ceph-node1 --data /dev/sdb
[root@ceph-admin my-ceph]# ceph-deploy osd create ceph-node2 --data /dev/sdb
</code></pre><p><strong>在两个osd节点上通过命令已显示磁盘已成功mount</strong></p><pre tabindex=0><code>[root@ceph-node1 ~]# lsblk
NAME                                                                                                  MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda                                                                                                     8:0    0   20G  0 disk
├─sda1                                                                                                  8:1    0    1G  0 part /boot
└─sda2                                                                                                  8:2    0   19G  0 part
  ├─centos-root                                                                                       253:0    0   17G  0 lvm  /
  └─centos-swap                                                                                       253:1    0    2G  0 lvm  [SWAP]
sdb                                                                                                     8:16   0   20G  0 disk
└─ceph--2bb0ec8d--547c--42c2--9858--08ccfd043bd4-osd--block--33e8dba4--6dfc--4753--b9ba--0d0c54166f0c 253:2    0   20G  0 lvm
sr0                             
</code></pre><p><strong>查看osd</strong></p><pre tabindex=0><code>[root@ceph-admin my-ceph]# ceph-deploy disk list ceph-node1 ceph-node2
......
......
[ceph-node1][INFO  ] Disk /dev/mapper/ceph--2bb0ec8d--547c--42c2--9858--08ccfd043bd4-osd--block--33e8dba4--6dfc--4753--b9ba--0d0c54166f0c: 21.5 GB, 21470642176 bytes, 41934848 sectors
......
......
[ceph-node2][INFO  ] Disk /dev/mapper/ceph--f9a95e6c--fc7b--46b4--a835--dd997c0d6335-osd--block--db903124--4c01--40d7--8a58--b26e17c1db29: 21.5 GB, 21470642176 bytes, 41934848 sectors
</code></pre><p><strong>同步集群文件，这样就可以在所有节点执行ceph命令了</strong></p><pre tabindex=0><code>[root@ceph-admin my-ceph]# ceph-deploy admin ceph-admin ceph-node1 ceph-node2
</code></pre><p><strong>在其他节点查看osd的目录树</strong></p><pre tabindex=0><code>[root@ceph-node1 ~]# ceph osd tree
ID CLASS WEIGHT  TYPE NAME           STATUS REWEIGHT PRI-AFF
-1       0.03897 root default
-3       0.01949     host ceph-node1
 0   hdd 0.01949         osd.0           up  1.00000 1.00000
-5       0.01949     host ceph-node2
 1   hdd 0.01949         osd.1           up  1.00000 1.00000
</code></pre><p><strong>配置mgr</strong></p><pre tabindex=0><code>[root@ceph-admin my-ceph]# ceph-deploy mgr create ceph-admin
</code></pre><p><strong>查看集群状态和集群service状态</strong></p><p>此时是HEALTH_WARN状态，是由于启用了不安全模式</p><pre tabindex=0><code>[root@ceph-admin my-ceph]# ceph health
HEALTH_WARN mon is allowing insecure global_id reclaim
[root@ceph-admin my-ceph]# ceph -s
  cluster:
    id:     fd816347-598c-4ed6-b356-591a618a0bdc
    health: HEALTH_WARN
            mon is allowing insecure global_id reclaim

  services:
    mon: 1 daemons, quorum ceph-admin (age 3h)
    mgr: mon_mgr(active, since 17s)
    osd: 2 osds: 2 up (since 3m), 2 in (since 3m)

  data:
    pools:   0 pools, 0 pgs
    objects: 0 objects, 0 B
    usage:   2.0 GiB used, 38 GiB / 40 GiB avail
    pgs:
</code></pre><p><strong>禁用不安全模式</strong></p><pre tabindex=0><code>[root@ceph-admin my-ceph]# ceph config set mon auth_allow_insecure_global_id_reclaim false
[root@ceph-admin my-ceph]# ceph health
HEALTH_OK
</code></pre><h1 id=开启dashboard>开启dashboard<a hidden class=anchor aria-hidden=true href=#开启dashboard>#</a></h1><pre tabindex=0><code>[root@ceph-admin my-ceph]# yum install -y ceph-mgr-dashboard
[root@ceph-admin my-ceph]# ceph mgr module enable dashboard
# 创建自签证书
[root@ceph-admin my-ceph]# ceph dashboard create-self-signed-cert
# 创建密码文件
[root@ceph-admin my-ceph]# echo abc123 &gt; ./dashboard_user_pw
# 创建dashboard的登录用户
[root@ceph-admin my-ceph]# ceph dashboard ac-user-create admin -i ./dashboard_user_pw administrator
{&#34;username&#34;: &#34;admin&#34;, &#34;lastUpdate&#34;: 1646037503, &#34;name&#34;: null, &#34;roles&#34;: [&#34;administrator&#34;], &#34;password&#34;: &#34;$2b$12$jGsvau8jFMb4pDwLU/t8KO1sKvmBMcNUYycbXusmgkvTQzlzrMyKi&#34;, &#34;email&#34;: null}
[root@ceph-admin my-ceph]# ceph mgr services
{
    &#34;dashboard&#34;: &#34;https://ceph-admin:8443/&#34;
}
</code></pre><p>测试访问</p><p><img loading=lazy src=https://image.lvbibir.cn/blog/image-20220228164616847.png alt=image-20220228164616847></p><p><img loading=lazy src=https://image.lvbibir.cn/blog/image-20220228164746181.png alt=image-20220228164746181></p><p>上图中测试环境是win10+chrome，同事反应mac+chrome会出现无法访问的情况，原因是我们使用的自签证书，浏览器并不信任此证书，可以通过以下两种方式解决</p><ol><li><p>关闭dashboard的ssl访问</p></li><li><p>下载证书配置浏览器信任证书</p></li></ol><h2 id=关闭dashboard的ssl访问>关闭dashboard的ssl访问<a hidden class=anchor aria-hidden=true href=#关闭dashboard的ssl访问>#</a></h2><pre tabindex=0><code>[root@ceph-admin my-ceph]# ceph config set mgr mgr/dashboard/ssl false
[root@ceph-admin my-ceph]# ceph mgr module disable dashboard
[root@ceph-admin my-ceph]# ceph mgr module enable dashboard
[root@ceph-admin my-ceph]# ceph mgr services
{
    &#34;dashboard&#34;: &#34;http://ceph-admin:8080/&#34;
}
</code></pre><p>如果出现<code>Module 'dashboard' has failed: IOError("Port 8443 not free on '::'",)</code>这种报错，需要重启下mgr：<code>systemctl restart ceph-mgr@ceph-admin</code></p><p>测试访问</p><p><img loading=lazy src=https://image.lvbibir.cn/blog/image-20220228171237208.png alt=image-20220228171237208></p><h2 id=开启rgw管理功能>开启rgw管理功能<a hidden class=anchor aria-hidden=true href=#开启rgw管理功能>#</a></h2><p>默认object gateway功能没有开启</p><p><img loading=lazy src=https://image.lvbibir.cn/blog/image-20220302111303281.png alt></p><p>创建rgw实例</p><pre tabindex=0><code>ceph-deploy rgw create ceph-admin
</code></pre><p>默认运行端口是7480</p><p><img loading=lazy src=https://image.lvbibir.cn/blog/image-20220302112418486.png alt=image-20220302112418486></p><p><img loading=lazy src=https://image.lvbibir.cn/blog/image-20220302112515398.png alt=image-20220302112515398></p><p>创建rgw用户</p><pre tabindex=0><code>[root@ceph-admin my-ceph]# radosgw-admin user create --uid=rgw --display-name=rgw --system
</code></pre><p><img loading=lazy src=https://image.lvbibir.cn/blog/image-20220302111512864.png alt=image-20220302111512864></p><p>提供dashboard证书</p><pre tabindex=0><code>[root@ceph-admin my-ceph]# echo UI2T50HNZUCVVYYZNDHP &gt; rgw_user_access_key
[root@ceph-admin my-ceph]# echo 11rg0WbXuh2Svexck3vJKs19u1UQINixDWIpN5Dq &gt; rgw_user_secret_key
[root@ceph-admin my-ceph]# ceph dashboard set-rgw-api-access-key -i rgw_user_access_key
Option RGW_API_ACCESS_KEY updated
[root@ceph-admin my-ceph]# ceph dashboard set-rgw-api-secret-key -i rgw_user_secret_key
Option RGW_API_SECRET_KEY updated
</code></pre><p>禁用ssl</p><pre tabindex=0><code>[root@ceph-admin my-ceph]# ceph dashboard set-rgw-api-ssl-verify False
Option RGW_API_SSL_VERIFY updated
</code></pre><p>启用rgw</p><pre tabindex=0><code>[root@ceph-admin my-ceph]# ceph dashboard set-rgw-api-host 192.168.150.101
Option RGW_API_HOST updated
[root@ceph-admin my-ceph]# ceph dashboard set-rgw-api-port 7480
Option RGW_API_PORT updated
[root@ceph-admin my-ceph]# ceph dashboard set-rgw-api-scheme http
Option RGW_API_SCHEME updated
[root@ceph-admin my-ceph]# ceph dashboard set-rgw-api-user-id rgw
Option RGW_API_USER_ID updated
[root@ceph-admin my-ceph]# systemctl restart ceph-radosgw.target
</code></pre><p>验证</p><p>目前object gateway功能已成功开启</p><p><img loading=lazy src=https://image.lvbibir.cn/blog/image-20220302112635543.png alt=image-20220302112635543></p><p><img loading=lazy src=https://image.lvbibir.cn/blog/image-20220302112655052.png alt=image-20220302112655052></p><p><img loading=lazy src=https://image.lvbibir.cn/blog/image-20220302112707308.png alt=image-20220302112707308></p><h1 id=其他>其他<a hidden class=anchor aria-hidden=true href=#其他>#</a></h1><h2 id=清除ceph集群><strong>清除ceph集群</strong><a hidden class=anchor aria-hidden=true href=#清除ceph集群>#</a></h2><p>清除安装包</p><pre tabindex=0><code>[root@ceph-admin ~]# ceph-deploy purge ceph-admin ceph-node1 ceph-node2
</code></pre><p>清除配置信息</p><pre tabindex=0><code>[root@ceph-admin ~]# ceph-deploy purgedata ceph-admin ceph-node1 ceph-node2
[root@ceph-admin ~]# ceph-deploy forgetkeys
</code></pre><p>每个节点删除残留的配置文件</p><pre tabindex=0><code>rm -rf /var/lib/ceph/osd/*
rm -rf /var/lib/ceph/mon/*
rm -rf /var/lib/ceph/mds/*
rm -rf /var/lib/ceph/bootstrap-mds/*
rm -rf /var/lib/ceph/bootstrap-osd/*
rm -rf /var/lib/ceph/bootstrap-mon/*
rm -rf /var/lib/ceph/tmp/*
rm -rf /etc/ceph/*
rm -rf /var/run/ceph/*
</code></pre><p>清理磁盘设备(/dev/mapper/ceph*)</p><pre tabindex=0><code>ls /dev/mapper/ceph-* | xargs -I% -- dmsetup remove %
</code></pre><h2 id=dashboard无法访问的问题>dashboard无法访问的问题<a hidden class=anchor aria-hidden=true href=#dashboard无法访问的问题>#</a></h2><p>在关闭dashboard的https后，出现了一个很奇怪的问题，使用chrome浏览器无法访问dashboard了，edge或者使用chrome无痕模式可以正常访问，期间尝试了各种方法包括重新配置dashboard和清理chrome浏览器的缓存和cookie等方式都没有解决问题，结果第二天起来打开环境一看自己好了（淦）</p><p>问题情况见下图</p><p><img loading=lazy src=https://image.lvbibir.cn/blog/GIF%202022-3-1%2015-21-48.gif alt="GIF 2022-3-1 15-21-48"></p><p>日志报错：</p><p><img loading=lazy src=https://image.lvbibir.cn/blog/image-20220302105649313.png alt=image-20220302105649313></p><h2 id=同步ceph配置文件>同步ceph配置文件<a hidden class=anchor aria-hidden=true href=#同步ceph配置文件>#</a></h2><pre tabindex=0><code>ceph-deploy --overwrite-conf config push ceph-node{1,2,3,4}
</code></pre><h2 id=添加mon节点和mgr节点>添加mon节点和mgr节点<a hidden class=anchor aria-hidden=true href=#添加mon节点和mgr节点>#</a></h2><pre tabindex=0><code>ceph-deploy mon create ceph-node{1,2,3,4}
ceph-deploy mgr create ceph-node{1,2,3,4}
</code></pre><p>记得修改配置文件</p><p><img loading=lazy src=http://image.lvbibir.cn/blog/image-20220420102326624.png alt=image-20220420102326624></p><p>之后同步配置文件</p><pre tabindex=0><code>ceph-deploy --overwrite-conf config push ceph-node{1,2,3,4}
</code></pre><h1 id=参考>参考<a hidden class=anchor aria-hidden=true href=#参考>#</a></h1><p><a href=https://www.cnblogs.com/kevingrace/p/9141432.html target=_blank rel=noopener style=color:#42b983 ;>https://www.cnblogs.com/kevingrace/p/9141432.html</a></p><p><a href=https://www.cnblogs.com/weijie0717/p/8378485.html target=_blank rel=noopener style=color:#42b983 ;>https://www.cnblogs.com/weijie0717/p/8378485.html</a></p><p><a href=https://www.cnblogs.com/weijie0717/p/8383938.html target=_blank rel=noopener style=color:#42b983 ;>https://www.cnblogs.com/weijie0717/p/8383938.html</a></p><p><a href=https://blog.csdn.net/qq_40017427/article/details/106235456 target=_blank rel=noopener style=color:#42b983 ;>https://blog.csdn.net/qq_40017427/article/details/106235456</a></p></div><div class=post-reward><div style=padding:0;margin:0;width:100%;font-size:16px;text-align:center><div id=QR style=opacity:0><div id=wechat style=display:inline-block><a class=fancybox rel=group><img id=wechat_qr src=https://www.lvbibir.cn/img/wechat_pay.png alt=wechat_pay></a><p>微信</p></div><div id=alipay style=display:inline-block><a class=fancybox rel=group><img id=alipay_qr src=https://www.lvbibir.cn/img/alipay.png alt=alipay></a><p>支付宝</p></div></div><button id=rewardButton onclick='var qr=document.getElementById("QR");qr.style.opacity==="0"?qr.style.opacity="1":qr.style.opacity="0"'>
<span>🧧 鼓励</span></button></div></div><footer class=post-footer><nav class=paginav><a class=prev href=https://www.lvbibir.cn/posts/tech/close-6000-port/><span class=title>« 上一页</span><br><span>关闭X服务本地监听的6000端口</span></a>
<a class=next href=https://www.lvbibir.cn/posts/tech/cloud-init-change-ssh-config/><span class=title>下一页 »</span><br><span>cloud-init自动将ssh配置文件的PasswordAuthentication参数值修改为no</span></a></nav></footer></div><div><div class=pagination__title><span class=pagination__title-h style=font-size:20px>💬评论</span><hr></div><div id=tcomment></div><script src=https://cdn.staticfile.org/twikoo/1.5.11/twikoo.all.min.js></script><script>twikoo.init({envId:"https://twikoo-lvbibir.vercel.app/",el:"#tcomment",lang:"zh-CN",region:"ap-guangzhou",path:window.TWIKOO_MAGIC_PATH||window.location.pathname})</script></div></article></main><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><footer class=footer><span>Copyright
&copy;
2020-2022
<a href=https://www.lvbibir.cn style=color:#939393>lvbibir's Blog</a>
All Rights Reserved</span>
<a href=https://beian.miit.gov.cn/ target=_blank style=color:#939393>京ICP备2021023168号-1</a>&nbsp;
<span id=busuanzi_container><link rel=stylesheet href=//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css>总访客数: <span id=busuanzi_value_site_uv></span>
总访问量: <span id=busuanzi_value_site_pv></span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg class="topSvg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg><span id=read_progress></span></span></a>
<script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>400||document.documentElement.scrollTop>400?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="📄复制";function s(){t.innerText="👌🏻已复制!",setTimeout(()=>{t.innerText="📄复制"},2e3)}t.addEventListener("click",t=>{const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>